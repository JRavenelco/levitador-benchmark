{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e2f41e6",
   "metadata": {},
   "source": [
    "# üéØ Identificaci√≥n de Par√°metros - Principio de M√≠nima Acci√≥n\n",
    "\n",
    "## Formulaci√≥n Lagrangiana del Levitador Magn√©tico + 9 Metaheur√≠sticos\n",
    "\n",
    "**Lagrangiano:** $\\mathcal{L} = \\frac{1}{2}m\\dot{y}^2 + mgy + \\frac{1}{2}L(y)i^2$\n",
    "\n",
    "**Par√°metros a identificar (5D):** $k_0, k, a, m, R$\n",
    "\n",
    "**Metaheur√≠sticos implementados:**\n",
    "1. Differential Evolution (DE/best/1)\n",
    "2. Particle Swarm Optimization (PSO)\n",
    "3. Grey Wolf Optimizer (GWO)\n",
    "4. Whale Optimization Algorithm (WOA)\n",
    "5. Sine-Cosine Algorithm (SCA)\n",
    "6. Salp Swarm Algorithm (SSA)\n",
    "7. Harris Hawks Optimization (HHO)\n",
    "8. Arithmetic Optimization Algorithm (AOA)\n",
    "9. Covariance Matrix Adaptation (CMA-ES)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c394b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import subprocess, sys, platform\n",
    "print(\"üîç Verificando GPU...\")\n",
    "try:\n",
    "    print(subprocess.check_output(['nvidia-smi'], text=True))\n",
    "except: print(\"‚ö†Ô∏è Sin GPU\")\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "!pip install -q \"numpy<2.1.0\" \"ml-dtypes>=0.5.1\"\n",
    "if IN_COLAB:\n",
    "    !pip install -q \"jax[cuda12]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "else:\n",
    "    !pip install -q jax jaxlib\n",
    "!pip install -q scipy pandas matplotlib tqdm plotly ipywidgets\n",
    "print(\"‚úÖ Dependencias instaladas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250f512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, jit, vmap\n",
    "from jax.lax import scan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json, time, os\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display, update_display\n",
    "\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706355e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_URL = \"https://github.com/JRavenelco/levitador-benchmark.git\"\n",
    "if not os.path.exists(\"levitador-benchmark\"):\n",
    "    !git clone {REPO_URL}\n",
    "    %cd levitador-benchmark\n",
    "elif os.getcwd().split(os.sep)[-1] != \"levitador-benchmark\":\n",
    "    %cd levitador-benchmark\n",
    "!ls -la data/*.txt 2>/dev/null || echo \"No data\"\n",
    "!ls -la data/sesiones_kan_pinn/*.txt 2>/dev/null || echo \"No KAN-PINN data\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6f1d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archivos disponibles para identificacion\n",
    "DATA_FILES = {\n",
    "    # === MEGA DATASET PRE-FILTRADO (RECOMENDADO) ===\n",
    "    'MEGA_CONTROLADO': 'data/mega_controlled_dataset.txt',  # 19534 muestras, 12 fuentes, solo datos controlados\n",
    "    \n",
    "    # === DATOS INDIVIDUALES ===\n",
    "    'MONIT_SWEEP': 'data/MONIT_SWEEP.txt',\n",
    "    'datos_zonas_faltantes': 'data/datos_zonas_faltantes.txt',\n",
    "    'MONIT_MAESTRO': 'data/MONIT_MAESTRO.txt',\n",
    "    'datos_levitador': 'data/datos_levitador.txt',\n",
    "    \n",
    "    # === SESIONES KAN-PINN ===\n",
    "    'chirp': 'data/sesiones_kan_pinn/dataset_chirp_20251217_210058.txt',\n",
    "    'constante': 'data/sesiones_kan_pinn/dataset_constante_20251217_205611.txt',\n",
    "    'escalon': 'data/sesiones_kan_pinn/dataset_escalon_20251217_205858.txt',\n",
    "    'multiescalon': 'data/sesiones_kan_pinn/dataset_multiescalon_20251217_210203.txt',\n",
    "    'senoidal': 'data/sesiones_kan_pinn/dataset_senoidal_20251217_205952.txt',\n",
    "}\n",
    "\n",
    "def load_data(filepath, subsample=1):\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, sep='\\\\s+', comment='#', header=None, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(filepath, sep='\\\\s+', comment='#', header=None, encoding='latin1')\n",
    "    if subsample > 1:\n",
    "        df = df.iloc[::subsample].reset_index(drop=True)\n",
    "    \n",
    "    # Extract columns: t, sp, y, i, u\n",
    "    t = df[0].values.astype(np.float32)\n",
    "    sp = df[1].values.astype(np.float32)\n",
    "    y = df[2].values.astype(np.float32)\n",
    "    i = df[3].values.astype(np.float32)\n",
    "    u = df[4].values.astype(np.float32)\n",
    "    \n",
    "    # Create validity mask (1=valid, 0=invalid/gap)\n",
    "    mask = np.ones_like(t, dtype=np.float32)\n",
    "    # Mask edges to avoid boundary derivative artifacts\n",
    "    if len(mask) > 10:\n",
    "        mask[:5] = 0\n",
    "        mask[-5:] = 0\n",
    "\n",
    "    return {'t': t, 'y': y, 'i': i, 'u': u, 'sp': sp, 'mask': mask}\n",
    "\n",
    "def filter_controlled(data):\n",
    "    '''Filtra datos donde la esfera esta levitando (y > 0.5mm y < 30mm)'''\n",
    "    mask_ctrl = (data['y'] > 0.0005) & (data['y'] < 0.030)\n",
    "    filtered = {k: v[mask_ctrl] for k, v in data.items()}\n",
    "    pct = 100 * len(filtered['t']) / (len(data['t']) + 1e-9)\n",
    "    return filtered, pct\n",
    "\n",
    "def extract_high_dynamics(data, threshold_pct=90):\n",
    "    '''Extrae segmentos con alta variacion de corriente/posicion'''\n",
    "    # Calculo aproximado de aceleracion\n",
    "    dy = np.gradient(data['y'])\n",
    "    ddy = np.gradient(dy)\n",
    "    metric = np.abs(ddy)  # Aceleracion como proxy de dinamica\n",
    "    \n",
    "    threshold = np.percentile(metric, threshold_pct)\n",
    "    mask = metric > threshold\n",
    "    \n",
    "    # Dilatar mascara para incluir contexto temporal\n",
    "    kernel = np.ones(50)  # +/- 25 muestras de contexto\n",
    "    mask_dilated = np.convolve(mask.astype(float), kernel, mode='same') > 0\n",
    "    \n",
    "    filtered = {k: v[mask_dilated] for k, v in data.items()}\n",
    "    n_selected = sum(mask_dilated)\n",
    "    pct = 100 * n_selected / len(data['t'])\n",
    "    \n",
    "    print(f\"  Zonas de alta dinamica: {n_selected}/{len(data['t'])} ({pct:.1f}%)\")\n",
    "    print(f\"  Umbral aceleracion: {threshold:.2f} m/s^2 (percentil {threshold_pct})\")\n",
    "    \n",
    "    return filtered, pct\n",
    "\n",
    "def analyze_data(data, name, show_filtered=True):\n",
    "    n_total = len(data['t'])\n",
    "    sp_range = (data['sp'].max() - data['sp'].min()) * 1000\n",
    "    y_range = (data['y'].max() - data['y'].min()) * 1000\n",
    "    i_range = data['i'].max() - data['i'].min()\n",
    "    n_setpoints = len(np.unique(np.round(data['sp'], 4)))\n",
    "    print(f\"Dataset {name}: {n_total} muestras, {n_setpoints} setpoints\")\n",
    "    print(f\"   SP: {data['sp'].min()*1000:.1f}-{data['sp'].max()*1000:.1f}mm | y: {y_range:.1f}mm | i: {i_range:.2f}A\")\n",
    "    return {'name': name, 'samples': n_total, 'setpoints': n_setpoints, \n",
    "            'sp_range': sp_range, 'y_range': y_range, 'i_range': i_range}\n",
    "\n",
    "def create_mega_dataset(file_dict, subsample=1, filter_ctrl=True):\n",
    "    '''Combina TODOS los archivos en un mega-dataset con datos controlados'''\n",
    "    all_data = {k: [] for k in ['t', 'sp', 'y', 'i', 'u', 'mask']}\n",
    "    t_offset = 0\n",
    "    stats = []\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CREANDO MEGA-DATASET CON DATOS CONTROLADOS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for name, path in file_dict.items():\n",
    "        try:\n",
    "            d = load_data(path, subsample)\n",
    "            n_original = len(d['t'])\n",
    "            \n",
    "            if filter_ctrl:\n",
    "                d, pct = filter_controlled(d)\n",
    "                print(f\"{name}: {len(d['t'])}/{n_original} muestras ({pct:.1f}% controladas)\")\n",
    "            else:\n",
    "                print(f\"{name}: {len(d['t'])} muestras\")\n",
    "            \n",
    "            if len(d['t']) > 0:\n",
    "                # Invalidar bordes de uni√≥n para evitar derivadas espurias\n",
    "                d['mask'][:5] = 0\n",
    "                d['mask'][-5:] = 0\n",
    "\n",
    "                # Resetear tiempo y agregar offset\n",
    "                d['t'] = d['t'] - d['t'][0] + t_offset\n",
    "                for k in all_data.keys():\n",
    "                    all_data[k].extend(d[k])\n",
    "                t_offset = all_data['t'][-1] + 0.1  # Gap entre datasets\n",
    "                stats.append({'name': name, 'samples': len(d['t'])})\n",
    "        except Exception as e:\n",
    "            print(f\"Error {name}: {e}\")\n",
    "    \n",
    "    mega = {k: np.array(v, dtype=np.float32) for k, v in all_data.items()}\n",
    "    print(\"=\"*60)\n",
    "    print(f\"MEGA-DATASET: {len(mega['t'])} muestras totales de {len(stats)} archivos\")\n",
    "    print(\"=\"*60)\n",
    "    return mega, stats\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ARCHIVOS DISPONIBLES PARA IDENTIFICACION\")\n",
    "print(\"=\"*60)\n",
    "for name, path in DATA_FILES.items():\n",
    "    try:\n",
    "        d = load_data(path, 1)\n",
    "        d_filt, pct = filter_controlled(d)\n",
    "        analyze_data(d, name)\n",
    "        print(f\"   -> Datos controlados: {len(d_filt['t'])} ({pct:.1f}%)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error {name}: {e}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb01f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# SELECCION DE DATOS - Modificar aqui\n",
    "# =================================================================\n",
    "# Modo 1: Un solo archivo\n",
    "# Modo 2: Combinar archivos seleccionados  \n",
    "# Modo 3: MEGA-DATASET (fusion en vivo de todos los archivos)\n",
    "# Modo 4: MEGA_CONTROLADO PRE-FILTRADO (19534 muestras, RECOMENDADO)\n",
    "# =================================================================\n",
    "\n",
    "MODE = 4  # 1=single, 2=combine, 3=fusion-live, 4=MEGA_CONTROLADO (RECOMENDADO)\n",
    "\n",
    "SELECTED_FILES = ['MONIT_SWEEP', 'datos_zonas_faltantes']  # Para modo 1 y 2\n",
    "SUBSAMPLE = 1  # Submuestreo (1=sin submuestreo, MEGA ya esta limpio)\n",
    "FILTER_CONTROLLED = True  # Filtrar solo datos donde esfera levita\n",
    "\n",
    "# === Filtro de zonas de alta dinamica ===\n",
    "USE_HIGH_DYNAMICS = False  # MEGA ya incluye alta dinamica\n",
    "DYNAMICS_PERCENTILE = 75   # Top 25% de aceleracion (75 = mas selectivo)\n",
    "\n",
    "if MODE == 4:\n",
    "    # MEGA_CONTROLADO: Dataset pre-filtrado con 19534 muestras de 12 fuentes\n",
    "    print(\"*** MODO 4: MEGA_CONTROLADO (Pre-filtrado, RECOMENDADO) ***\")\n",
    "    data = load_data(DATA_FILES['MEGA_CONTROLADO'], SUBSAMPLE)\n",
    "    DATA_NAME = 'MEGA_CONTROLADO'\n",
    "    print(f\"  Cargadas {len(data['t'])} muestras de levitacion controlada\")\n",
    "\n",
    "elif MODE == 3:\n",
    "    # MEGA-DATASET: Combina TODOS los archivos con datos controlados\n",
    "    print(\"*** MODO 3: MEGA-DATASET ***\")\n",
    "    data, mega_stats = create_mega_dataset(DATA_FILES, subsample=SUBSAMPLE, filter_ctrl=FILTER_CONTROLLED)\n",
    "    DATA_NAME = 'MEGA-DATASET'\n",
    "    \n",
    "elif MODE == 2 and len(SELECTED_FILES) > 1:\n",
    "    # Combinar archivos seleccionados\n",
    "    print(f\"*** MODO 2: Combinando {SELECTED_FILES} ***\")\n",
    "    all_data = {k: [] for k in ['t', 'sp', 'y', 'i', 'u']}\n",
    "    t_offset = 0\n",
    "    for fname in SELECTED_FILES:\n",
    "        d = load_data(DATA_FILES[fname], SUBSAMPLE)\n",
    "        if FILTER_CONTROLLED:\n",
    "            d, pct = filter_controlled(d)\n",
    "            print(f\"  {fname}: {len(d['t'])} muestras controladas ({pct:.1f}%)\")\n",
    "        d['t'] = d['t'] - d['t'][0] + t_offset\n",
    "        for k in all_data.keys():\n",
    "            all_data[k].extend(d[k])\n",
    "        t_offset = all_data['t'][-1] + 0.1\n",
    "    data = {k: np.array(v, dtype=np.float32) for k, v in all_data.items()}\n",
    "    DATA_NAME = '+'.join(SELECTED_FILES)\n",
    "    \n",
    "else:\n",
    "    # Modo 1: Un solo archivo\n",
    "    print(f\"*** MODO 1: Archivo unico ***\")\n",
    "    DATA_NAME = SELECTED_FILES[0]\n",
    "    data = load_data(DATA_FILES[DATA_NAME], SUBSAMPLE)\n",
    "    if FILTER_CONTROLLED:\n",
    "        data, pct = filter_controlled(data)\n",
    "        print(f\"  Filtrado: {len(data['t'])} muestras controladas ({pct:.1f}%)\")\n",
    "\n",
    "# === APLICAR FILTRO DE ALTA DINAMICA ===\n",
    "if USE_HIGH_DYNAMICS:\n",
    "    print(f\"\\n*** EXTRAYENDO ZONAS DE ALTA DINAMICA (percentil {DYNAMICS_PERCENTILE}) ***\")\n",
    "    n_antes = len(data['t'])\n",
    "    data, pct_dyn = extract_high_dynamics(data, threshold_pct=DYNAMICS_PERCENTILE)\n",
    "    print(f\"  Reduccion: {n_antes} -> {len(data['t'])} muestras\")\n",
    "    DATA_NAME += f\"_dyn{100-DYNAMICS_PERCENTILE}\"\n",
    "\n",
    "stats = analyze_data(data, DATA_NAME)\n",
    "n_setpoints = stats['setpoints']\n",
    "quality = 'EXCELENTE' if n_setpoints >= 15 else 'MUY BUENA' if n_setpoints >= 10 else 'BUENA' if n_setpoints >= 5 else 'BASICA'\n",
    "print(f\"\\nDataset final: {DATA_NAME}\")\n",
    "print(f\"  Muestras: {stats['samples']}, Setpoints: {n_setpoints}\")\n",
    "print(f\"  Calidad para identificacion: {quality}\")\n",
    "\n",
    "# Visualizacion\n",
    "fig, ax = plt.subplots(3, 1, figsize=(14, 7), sharex=True)\n",
    "ax[0].plot(data['t'], data['sp']*1000, 'g--', lw=1, alpha=0.7, label='Setpoint')\n",
    "ax[0].plot(data['t'], data['y']*1000, 'b-', lw=0.5, label='Posicion')\n",
    "ax[0].set_ylabel('y [mm]'); ax[0].legend(); ax[0].grid(True)\n",
    "ax[0].set_title(f'Dataset: {DATA_NAME} ({stats[\"samples\"]} muestras, {n_setpoints} setpoints)', fontweight='bold')\n",
    "ax[1].plot(data['t'], data['i'], 'r-', lw=0.5); ax[1].set_ylabel('i [A]'); ax[1].grid(True)\n",
    "ax[2].plot(data['t'], data['u'], 'purple', lw=0.5); ax[2].set_ylabel('u [V]'); ax[2].set_xlabel('t [s]'); ax[2].grid(True)\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3250aade",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_jax = jnp.array(data['t'])\n",
    "y_jax = jnp.array(data['y'])\n",
    "i_jax = jnp.array(data['i'])\n",
    "u_jax = jnp.array(data['u'])\n",
    "mask_jax = jnp.array(data['mask'])  # M√°scara de validez (0=gap, 1=valid)\n",
    "\n",
    "dt_jax = jnp.diff(t_jax, prepend=t_jax[0])\n",
    "dt_jax = dt_jax.at[0].set(dt_jax[1])\n",
    "dt_mean = float(jnp.mean(dt_jax))\n",
    "\n",
    "dy_jax = jnp.gradient(y_jax, dt_mean)\n",
    "ddy_jax = jnp.gradient(dy_jax, dt_mean)\n",
    "di_jax = jnp.gradient(i_jax, dt_mean)\n",
    "\n",
    "y0, i0 = float(y_jax[0]), float(i_jax[0])\n",
    "print(f\"‚úÖ GPU: dt={dt_mean:.4f}s, y0={y0*1000:.2f}mm, i0={i0:.3f}A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516cf5eb",
   "metadata": {},
   "source": [
    "## Modelo Fisico Lagrangiano - 6 Parametros\n",
    "\n",
    "**Inductancia:** $L(y) = k_0 + \\frac{k}{1+y/a}$\n",
    "\n",
    "**Resistencia termica:** $R(t) = R_0 + \\alpha \\cdot t$ (deriva termica de la bobina)\n",
    "\n",
    "**Parametros a identificar (6D):** $[k_0, k, a, m, R_0, \\alpha]$\n",
    "\n",
    "**Residuos Euler-Lagrange:**\n",
    "- Mecanico: $m\\ddot{y} = mg - \\frac{1}{2}i^2|\\frac{dL}{dy}|$\n",
    "- Electrico: $u = R(t)i + L\\frac{di}{dt} + i\\frac{dL}{dy}\\frac{dy}{dt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e034ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAVITY = 9.81\n",
    "\n",
    "# Referencias de Santana 2023\n",
    "M_REF = 0.009      # 9g\n",
    "R0_REF = 2.2       # 2.2 ohm\n",
    "K0_REF = 0.0035    # 3.5 mH\n",
    "K_REF = 0.032      # 32 mH (corregido - valor real de inductancia)\n",
    "A_REF = 0.0052     # 5.2 mm\n",
    "ALPHA_REF = 0.0    # Sin deriva termica inicial\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODELO DE 6 PARAMETROS CON RESISTENCIA TERMICA\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Ref: k0={K0_REF*1000:.1f}mH, k={K_REF*1000:.1f}mH, a={A_REF*1000:.1f}mm\")\n",
    "print(f\"     m={M_REF*1000:.1f}g, R0={R0_REF:.1f}ohm, alpha={ALPHA_REF}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "@jit\n",
    "def get_inductance(y, k0, k, a):\n",
    "    return k0 + k / (1.0 + y/a)\n",
    "\n",
    "@jit\n",
    "def get_dL_dy(y, k, a):\n",
    "    # Derivada analitica: -k / (a * (1 + y/a)^2)\n",
    "    return -k / (a * jnp.square(1.0 + y/a))\n",
    "\n",
    "@jit\n",
    "def dynamics_6p(state, inputs, params, g):\n",
    "    # Sistema de 6 parametros con R(t) variable\n",
    "    k0, k, a, m, r0, alpha = params\n",
    "    u, t_current = inputs\n",
    "    y, dy, i = state\n",
    "    \n",
    "    y = jnp.clip(y, 1e-6, 0.03)\n",
    "    i = jnp.clip(i, 0, 5)\n",
    "    \n",
    "    # Resistencia variable con temperatura\n",
    "    R_t = r0 + alpha * t_current\n",
    "    \n",
    "    L = get_inductance(y, k0, k, a)\n",
    "    dL = get_dL_dy(y, k, a)\n",
    "    \n",
    "    # Fuerza magnetica (atractiva hacia arriba)\n",
    "    F_mag = 0.5 * i * i * jnp.abs(dL)\n",
    "    ddy = (F_mag - m*g) / m\n",
    "    \n",
    "    # Ecuacion electrica con R(t)\n",
    "    di = (u - R_t*i - dL*dy*i) / L\n",
    "    \n",
    "    return jnp.array([dy, ddy, di])\n",
    "\n",
    "@jit\n",
    "def simulate_trajectory_6p(params, u_data, t_data, dt_data, y0, i0, g):\n",
    "    # Integrador RK4 para modelo de 6 parametros\n",
    "    state = jnp.array([y0, 0.0, i0])\n",
    "    \n",
    "    def rk4_step(state, inputs):\n",
    "        u, t_curr, dt = inputs\n",
    "        inp = (u, t_curr)\n",
    "        k1 = dynamics_6p(state, inp, params, g)\n",
    "        k2 = dynamics_6p(state + 0.5*dt*k1, inp, params, g)\n",
    "        k3 = dynamics_6p(state + 0.5*dt*k2, inp, params, g)\n",
    "        k4 = dynamics_6p(state + dt*k3, inp, params, g)\n",
    "        new_state = state + (dt/6.0)*(k1 + 2*k2 + 2*k3 + k4)\n",
    "        new_state = new_state.at[0].set(jnp.clip(new_state[0], 0, 0.03))\n",
    "        new_state = new_state.at[2].set(jnp.clip(new_state[2], 0, 5))\n",
    "        return new_state, jnp.array([new_state[0], new_state[2], new_state[1]])\n",
    "    \n",
    "    _, out = scan(rk4_step, state, (u_data, t_data, dt_data))\n",
    "    return out[:,0], out[:,1], out[:,2]  # y, i, dy\n",
    "\n",
    "# Funcion wrapper para compatibilidad\n",
    "def simulate_trajectory(params, u_data, dt_data, y0, i0, g):\n",
    "    t_data = jnp.cumsum(dt_data)\n",
    "    return simulate_trajectory_6p(params, u_data, t_data, dt_data, y0, i0, g)\n",
    "\n",
    "# Validar modelo\n",
    "print(\"Validando modelo con parametros de referencia...\")\n",
    "REF_6P = jnp.array([K0_REF, K_REF, A_REF, M_REF, R0_REF, ALPHA_REF])\n",
    "t_test = jnp.cumsum(dt_jax)\n",
    "y_test, i_test, dy_test = simulate_trajectory_6p(REF_6P, u_jax, t_test, dt_jax, y0, i0, GRAVITY)\n",
    "print(f\"  y: min={float(jnp.min(y_test))*1000:.2f}mm, max={float(jnp.max(y_test))*1000:.2f}mm\")\n",
    "print(f\"  i: min={float(jnp.min(i_test)):.3f}A, max={float(jnp.max(i_test)):.3f}A\")\n",
    "print(\"Modelo de 6 parametros con RK4 definido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# FITNESS (6 PARAMETROS) - Seleccion por modo\n",
    "# =================================================================\n",
    "# 'energy_balance'  : identifica masa con balance de potencia (transitorios)\n",
    "# 'pinn_mejorado'   : prioriza fuerza/voltaje y usa barrera log (evita tocar bounds)\n",
    "FITNESS_MODE = 'pinn_mejorado'  # 'energy_balance' | 'pinn_mejorado'\n",
    "\n",
    "# =================================================================\n",
    "# BOUNDS FISICAMENTE ANCLADOS (AMBOS MODOS USAN MASA ~9g)\n",
    "# =================================================================\n",
    "# La masa del iman es ~9g medida, R0 ~2.2 ohm medido con multimetro\n",
    "# [k0, k, a, m, R0, alpha]\n",
    "LOWER_BOUNDS_ENERGY = jnp.array([0.001, 0.010, 0.002, 0.0085, 2.0, -0.005])\n",
    "UPPER_BOUNDS_ENERGY = jnp.array([0.008, 0.080, 0.015, 0.0095, 3.0,  0.005])\n",
    "\n",
    "# Bounds MAS ESTRICTOS para pinn_mejorado (m casi fijo)\n",
    "# k0: 1-5mH, k: 10-60mH, a: 2-12mm, m: 8.9-9.1g, R0: 2.1-2.8 ohm\n",
    "LOWER_BOUNDS_PINN = jnp.array([0.001, 0.010, 0.002, 0.0089, 2.1, -0.001])\n",
    "UPPER_BOUNDS_PINN = jnp.array([0.005, 0.060, 0.012, 0.0091, 2.8,  0.001])\n",
    "\n",
    "if FITNESS_MODE == 'pinn_mejorado':\n",
    "    LOWER_BOUNDS = LOWER_BOUNDS_PINN\n",
    "    UPPER_BOUNDS = UPPER_BOUNDS_PINN\n",
    "else:\n",
    "    LOWER_BOUNDS = LOWER_BOUNDS_ENERGY\n",
    "    UPPER_BOUNDS = UPPER_BOUNDS_ENERGY\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FITNESS CONFIGURADO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  FITNESS_MODE = {FITNESS_MODE}\")\n",
    "print(f\"  k0:    {LOWER_BOUNDS[0]*1000:.2f} - {UPPER_BOUNDS[0]*1000:.2f} mH\")\n",
    "print(f\"  k:     {LOWER_BOUNDS[1]*1000:.2f} - {UPPER_BOUNDS[1]*1000:.2f} mH\")\n",
    "print(f\"  a:     {LOWER_BOUNDS[2]*1000:.2f} - {UPPER_BOUNDS[2]*1000:.2f} mm\")\n",
    "print(f\"  m:     {LOWER_BOUNDS[3]*1000:.2f} - {UPPER_BOUNDS[3]*1000:.2f} g\")\n",
    "print(f\"  R0:    {LOWER_BOUNDS[4]:.3f} - {UPPER_BOUNDS[4]:.3f} ohm\")\n",
    "print(f\"  alpha: {LOWER_BOUNDS[5]:.4f} - {UPPER_BOUNDS[5]:.4f} ohm/s\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "@jit\n",
    "def energy_balance_fitness(params, t_data, y_data, i_data, u_data, mask, dt):\n",
    "    k0, k, a, m, r0, alpha = params\n",
    "    g = GRAVITY\n",
    "\n",
    "    R_t = r0 + alpha * t_data\n",
    "    dy = jnp.gradient(y_data, dt)\n",
    "    d2y = jnp.gradient(dy, dt)\n",
    "    di = jnp.gradient(i_data, dt)\n",
    "\n",
    "    L = get_inductance(y_data, k0, k, a)\n",
    "    dLdy = get_dL_dy(y_data, k, a)\n",
    "    f_mag = 0.5 * jnp.square(i_data) * jnp.abs(dLdy)\n",
    "\n",
    "    # Newton (Weighted by mask)\n",
    "    res_newton = m * d2y - (m * g - f_mag)\n",
    "    loss_newton = jnp.sum(jnp.square(res_newton) * mask) / (jnp.sum(mask) * (0.009 * g)**2 + 1e-8)\n",
    "\n",
    "    # Potencia (Weighted by mask)\n",
    "    p_in = u_data * i_data\n",
    "    p_cu = R_t * jnp.square(i_data)\n",
    "    dw_mag = L * i_data * di + 0.5 * jnp.square(i_data) * dLdy * dy\n",
    "    de_mech = m * dy * d2y + m * g * dy\n",
    "    res_energy = p_in - (p_cu + dw_mag + de_mech)\n",
    "    loss_energy = jnp.sum(jnp.square(res_energy) * mask) / (jnp.sum(mask) * jnp.var(p_in) + 1e-8)\n",
    "\n",
    "    # Kirchhoff (Weighted by mask)\n",
    "    u_model = R_t * i_data + L * di + i_data * dLdy * dy\n",
    "    res_u = u_data - u_model\n",
    "    loss_kirchhoff = jnp.sum(jnp.square(res_u) * mask) / (jnp.sum(mask) * jnp.var(u_data) + 1e-8)\n",
    "\n",
    "    out_of_bounds = jnp.sum(jnp.maximum(0.0, LOWER_BOUNDS - params)**2 + \n",
    "                            jnp.maximum(0.0, params - UPPER_BOUNDS)**2)\n",
    "\n",
    "    return jnp.nan_to_num(loss_newton + 10.0 * loss_energy + loss_kirchhoff + 1e4 * out_of_bounds, nan=1e10)\n",
    "\n",
    "@jit\n",
    "def fitness_pinn_mejorado(params, t_data, y_data, i_data, u_data, mask, dt):\n",
    "    k0, k, a, m, r0, alpha = params\n",
    "    g = GRAVITY\n",
    "\n",
    "    R_t = r0 + alpha * t_data\n",
    "    dy = jnp.gradient(y_data, dt)\n",
    "    di = jnp.gradient(i_data, dt)\n",
    "\n",
    "    L = get_inductance(y_data, k0, k, a)\n",
    "    dLdy = get_dL_dy(y_data, k, a)\n",
    "\n",
    "    # 1) Normalizacion por varianza: iguala peso de errores electricos\n",
    "    u_model = R_t * i_data + L * di + i_data * dLdy * dy\n",
    "    loss_u = jnp.sum(jnp.square(u_data - u_model) * mask) / (jnp.var(u_data) * jnp.sum(mask) + 1e-6)\n",
    "\n",
    "    # 2) JUEZ DE HIERRO: Balance de Fuerza (si F_mag != mg, penalizacion enorme)\n",
    "    f_mag = 0.5 * jnp.square(i_data) * jnp.abs(dLdy)\n",
    "    loss_f = jnp.sum(jnp.square(m * g - f_mag) * mask) / ((m * g)**2 * jnp.sum(mask) + 1e-12)\n",
    "\n",
    "    # 3) Penalizacion de Frontera: evita chocar con limites (barrera log)\n",
    "    dist_min = jnp.min(params - LOWER_BOUNDS)\n",
    "    dist_max = jnp.min(UPPER_BOUNDS - params)\n",
    "    penalty = -jnp.log(dist_min + 1e-6) - jnp.log(dist_max + 1e-6)\n",
    "\n",
    "    # Peso 100x a la FUERZA para que el iman \"flote\" correctamente\n",
    "    return jnp.nan_to_num(loss_u + 100.0 * loss_f + 0.1 * penalty, nan=1e10)\n",
    "\n",
    "FITNESS_FN = energy_balance_fitness if FITNESS_MODE == 'energy_balance' else fitness_pinn_mejorado\n",
    "print(\"Fitness listo: FITNESS_FN definido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e47d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# VISUALIZACION DE RESIDUALES - \"Detector de Mentiras\"\n",
    "# =================================================================\n",
    "def plot_residuals(params, t, y, i, u, dt):\n",
    "    '''Visualiza donde falla el modelo vs datos reales'''\n",
    "    k0, k, a, m, r0, alpha = params\n",
    "\n",
    "    # Recalcular dinamica\n",
    "    R_t = r0 + alpha * t\n",
    "    dy = jnp.gradient(y, dt)\n",
    "    d2y = jnp.gradient(dy, dt)\n",
    "    di = jnp.gradient(i, dt)\n",
    "\n",
    "    L = get_inductance(y, k0, k, a)\n",
    "    dLdy = get_dL_dy(y, k, a)\n",
    "\n",
    "    # Voltaje modelo vs real\n",
    "    u_model = R_t * i + L * di + i * dLdy * dy\n",
    "\n",
    "    # Fuerza magnetica\n",
    "    f_mag = 0.5 * jnp.square(i) * jnp.abs(dLdy)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "    # 1. Voltaje: modelo vs real\n",
    "    axes[0,0].plot(t, u, 'b-', lw=0.8, alpha=0.6, label='u real')\n",
    "    axes[0,0].plot(t, np.array(u_model), 'r--', lw=1, label='u modelo')\n",
    "    axes[0,0].set_xlabel('t [s]'); axes[0,0].set_ylabel('u [V]')\n",
    "    axes[0,0].set_title('Ley de Kirchhoff: u_real vs u_modelo', fontweight='bold')\n",
    "    axes[0,0].legend(); axes[0,0].grid(True)\n",
    "\n",
    "    # 2. Residuo de voltaje\n",
    "    res_u = u - np.array(u_model)\n",
    "    axes[0,1].plot(t, res_u, 'purple', lw=0.5)\n",
    "    axes[0,1].axhline(0, color='k', linestyle='--', alpha=0.5)\n",
    "    axes[0,1].set_xlabel('t [s]'); axes[0,1].set_ylabel('Residuo [V]')\n",
    "    axes[0,1].set_title(f'Residuo Electrico (std={np.std(res_u):.3f}V)', fontweight='bold')\n",
    "    axes[0,1].grid(True)\n",
    "\n",
    "    # 3. Balance de fuerzas\n",
    "    axes[1,0].plot(t, np.array(f_mag)*1000, 'g-', lw=1, label='F_mag [mN]')\n",
    "    axes[1,0].axhline(y=m*9.81*1000, color='r', linestyle='-', lw=2, label=f'Peso mg={m*9.81*1000:.2f}mN')\n",
    "    axes[1,0].set_xlabel('t [s]'); axes[1,0].set_ylabel('Fuerza [mN]')\n",
    "    axes[1,0].set_title('Balance de Fuerzas (Accion Mecanica)', fontweight='bold')\n",
    "    axes[1,0].legend(); axes[1,0].grid(True)\n",
    "\n",
    "    # 4. Inductancia vs posicion\n",
    "    y_range = jnp.linspace(0.001, 0.020, 100)\n",
    "    L_curve = get_inductance(y_range, k0, k, a)\n",
    "    axes[1,1].plot(y_range*1000, np.array(L_curve)*1000, 'b-', lw=2)\n",
    "    axes[1,1].scatter(np.array(y)*1000, np.array(L)*1000, c='r', s=1, alpha=0.3, label='Datos')\n",
    "    axes[1,1].set_xlabel('y [mm]'); axes[1,1].set_ylabel('L [mH]')\n",
    "    axes[1,1].set_title(f'Curva L(y): k0={k0*1000:.2f}mH, k={k*1000:.1f}mH, a={a*1000:.2f}mm', fontweight='bold')\n",
    "    axes[1,1].legend(); axes[1,1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('residuals_diagnostic.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "    # Metricas\n",
    "    print(\"\n",
    "DIAGNOSTICO DE RESIDUALES:\")\n",
    "    print(f\"  Voltaje: RMSE={np.sqrt(np.mean(res_u**2)):.4f}V, std={np.std(res_u):.4f}V\")\n",
    "    print(f\"  F_mag promedio: {np.mean(np.array(f_mag))*1000:.2f} mN\")\n",
    "    print(f\"  Peso (mg): {m*9.81*1000:.2f} mN\")\n",
    "    print(f\"  Ratio F_mag/mg: {np.mean(np.array(f_mag))/(m*9.81):.2%}\")\n",
    "\n",
    "print(\"Funcion plot_residuals() definida para diagnostico\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4b700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# VALIDACION DE BALANCE DE POTENCIA - Prueba definitiva\n",
    "# =================================================================\n",
    "def plot_power_validation(params, t, y, i, u, dt):\n",
    "    '''\n",
    "    GRAFICA DE BALANCE DE POTENCIA\n",
    "    Esta es la prueba definitiva de que la identificacion es fisicamente consistente.\n",
    "    Si la masa es incorrecta, los picos de P_out no coincidiran con P_in.\n",
    "    '''\n",
    "    k0, k, a, m, r0, alpha = params\n",
    "    \n",
    "    # Derivadas\n",
    "    R_t = r0 + alpha * t\n",
    "    dy = np.gradient(y, dt)\n",
    "    d2y = np.gradient(dy, dt)\n",
    "    di = np.gradient(i, dt)\n",
    "    \n",
    "    # Inductancia\n",
    "    L = k0 + k / (1.0 + y/a)\n",
    "    dLdy = -k / (a * np.square(1.0 + y/a))\n",
    "    \n",
    "    # === POTENCIAS ===\n",
    "    p_in = u * i                                    # Potencia electrica entrada\n",
    "    p_cu = R_t * np.square(i)                       # Perdida por calor (Joule)\n",
    "    p_mag = L * i * di + 0.5 * np.square(i) * dLdy * dy  # Variacion energia magnetica\n",
    "    p_mech = m * dy * d2y + m * 9.81 * dy           # Variacion energia mecanica\n",
    "    \n",
    "    p_out = p_cu + p_mag + p_mech                   # Potencia total calculada\n",
    "    \n",
    "    # Error de potencia\n",
    "    error_power = p_in - p_out\n",
    "    rmse_power = np.sqrt(np.mean(error_power**2))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "    \n",
    "    # 1. Balance de potencia total\n",
    "    axes[0,0].plot(t, p_in, 'b-', lw=0.8, alpha=0.7, label='P_in (electrica)')\n",
    "    axes[0,0].plot(t, p_out, 'r--', lw=1, label='P_out (modelo)')\n",
    "    axes[0,0].fill_between(t, p_in, p_out, color='red', alpha=0.2, label='Error')\n",
    "    axes[0,0].set_xlabel('t [s]'); axes[0,0].set_ylabel('Potencia [W]')\n",
    "    axes[0,0].set_title(f'Balance de Potencia (Masa ID: {m*1000:.2f}g, RMSE={rmse_power:.4f}W)', fontweight='bold')\n",
    "    axes[0,0].legend(); axes[0,0].grid(True)\n",
    "    \n",
    "    # 2. Componentes de potencia\n",
    "    axes[0,1].plot(t, p_cu, 'orange', lw=0.8, label='P_cu (Joule)')\n",
    "    axes[0,1].plot(t, p_mag, 'green', lw=0.8, label='P_mag (magnetica)')\n",
    "    axes[0,1].plot(t, p_mech, 'purple', lw=0.8, label='P_mech (mecanica)')\n",
    "    axes[0,1].set_xlabel('t [s]'); axes[0,1].set_ylabel('Potencia [W]')\n",
    "    axes[0,1].set_title('Componentes de Potencia', fontweight='bold')\n",
    "    axes[0,1].legend(); axes[0,1].grid(True)\n",
    "    \n",
    "    # 3. Error de potencia en el tiempo\n",
    "    axes[1,0].plot(t, error_power, 'red', lw=0.5)\n",
    "    axes[1,0].axhline(0, color='k', linestyle='--', alpha=0.5)\n",
    "    axes[1,0].fill_between(t, 0, error_power, alpha=0.3, color='red')\n",
    "    axes[1,0].set_xlabel('t [s]'); axes[1,0].set_ylabel('Error [W]')\n",
    "    axes[1,0].set_title(f'Error de Balance (std={np.std(error_power):.4f}W)', fontweight='bold')\n",
    "    axes[1,0].grid(True)\n",
    "    \n",
    "    # 4. Histograma del error\n",
    "    axes[1,1].hist(error_power, bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[1,1].axvline(0, color='r', linestyle='--', lw=2)\n",
    "    axes[1,1].set_xlabel('Error de Potencia [W]')\n",
    "    axes[1,1].set_ylabel('Frecuencia')\n",
    "    axes[1,1].set_title(f'Distribucion del Error (mean={np.mean(error_power):.4f}W)', fontweight='bold')\n",
    "    axes[1,1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('power_validation.png', dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    # Metricas de balance\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"VALIDACION DE BALANCE DE POTENCIA\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"  Masa identificada: {m*1000:.4f} g\")\n",
    "    print(f\"  P_in promedio: {np.mean(p_in):.4f} W\")\n",
    "    print(f\"  P_out promedio: {np.mean(p_out):.4f} W\")\n",
    "    print(f\"  Error RMSE: {rmse_power:.6f} W\")\n",
    "    print(f\"  Error relativo: {100*rmse_power/np.mean(np.abs(p_in)):.2f}%\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Veredicto\n",
    "    if rmse_power/np.mean(np.abs(p_in)) < 0.1:\n",
    "        print(\"VEREDICTO: Balance de energia CONSISTENTE\")\n",
    "    elif rmse_power/np.mean(np.abs(p_in)) < 0.3:\n",
    "        print(\"VEREDICTO: Balance de energia ACEPTABLE\")\n",
    "    else:\n",
    "        print(\"VEREDICTO: Balance de energia INCONSISTENTE - revisar parametros\")\n",
    "\n",
    "print(\"Funcion plot_power_validation() definida para validacion energetica\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64842f21",
   "metadata": {},
   "source": [
    "## üß¨ 9 Algoritmos Metaheur√≠sticos con Visualizaci√≥n 3D en Tiempo Real\n",
    "Cada optimizador muestra la evoluci√≥n de la poblaci√≥n en el espacio (k0, k, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82faf9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# üéØ OPTIMIZADOR CON VISUALIZACI√ìN 3D EN TIEMPO REAL (PLOTLY)\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "def run_optimizer_interactive(name, optimizer_step_fn, fitness_fn, bounds, pop_size=100, max_iter=200, seed=42, ref=None):\n",
    "    # Ejecuta optimizador con visualizacion 3D interactiva\n",
    "    key = random.PRNGKey(seed)\n",
    "    n = bounds.shape[0]\n",
    "    ranges = bounds[:,1] - bounds[:,0]\n",
    "    \n",
    "    # Inicializar poblaci√≥n\n",
    "    key, sk = random.split(key)\n",
    "    pop = random.uniform(sk, (pop_size, n)) * ranges + bounds[:,0]\n",
    "    if ref is not None:\n",
    "        key, sk = random.split(key)\n",
    "        seeded = ref + random.normal(sk, (pop_size//4, n))*0.1*ranges\n",
    "        pop = pop.at[:pop_size//4].set(jnp.clip(seeded, bounds[:,0], bounds[:,1]))\n",
    "    \n",
    "    fit = fitness_fn(pop)\n",
    "    best_idx = jnp.argmin(fit)\n",
    "    best, best_fit = pop[best_idx], fit[best_idx]\n",
    "    hist = {'best': [], 'pop_history': []}\n",
    "    \n",
    "    # Crear figura 3D interactiva\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=np.array(pop[:,0])*1000, y=np.array(pop[:,1])*1000, z=np.array(pop[:,2])*1000,\n",
    "        mode='markers', marker=dict(size=4, color=np.log10(np.array(fit)+1e-10), colorscale='Viridis', showscale=True),\n",
    "        name='Poblaci√≥n'))\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[K0_REF*1000], y=[K0_REF*1000], z=[A_REF*1000],\n",
    "        mode='markers', marker=dict(size=10, color='red', symbol='diamond'), name='Referencia'))\n",
    "    fig.update_layout(\n",
    "        template=\"plotly_dark\",\n",
    "        title=f\"{name} - Gen 0 | Fitness: {float(best_fit):.2e}\",\n",
    "        scene=dict(\n",
    "            xaxis=dict(title='k0 [mH]', range=[bounds[0,0]*1000, bounds[0,1]*1000]),\n",
    "            yaxis=dict(title='k [mH]', range=[bounds[1,0]*1000, bounds[1,1]*1000]),\n",
    "            zaxis=dict(title='a [mm]', range=[bounds[2,0]*1000, bounds[2,1]*1000])),\n",
    "        width=800, height=600)\n",
    "    \n",
    "    display_id = f\"opt_{name}_{int(time.time())}\"\n",
    "    display(fig, display_id=display_id)\n",
    "    \n",
    "    # Bucle de optimizaci√≥n\n",
    "    for gen in range(max_iter):\n",
    "        key, sk = random.split(key)\n",
    "        pop, fit, best, best_fit = optimizer_step_fn(pop, fit, best, best_fit, bounds, sk, gen, max_iter)\n",
    "        hist['best'].append(float(best_fit))\n",
    "        \n",
    "        # Actualizar visualizaci√≥n cada 5 generaciones\n",
    "        if gen % 5 == 0:\n",
    "            with fig.batch_update():\n",
    "                fig.data[0].x = np.array(pop[:,0])*1000\n",
    "                fig.data[0].y = np.array(pop[:,1])*1000\n",
    "                fig.data[0].z = np.array(pop[:,2])*1000\n",
    "                fig.data[0].marker.color = np.log10(np.array(fit)+1e-10)\n",
    "                fig.layout.title.text = f\"{name} - Gen {gen} | Fitness: {float(best_fit):.2e} | m={float(best[3])*1000:.1f}g\"\n",
    "            update_display(fig, display_id=display_id)\n",
    "    \n",
    "    # Actualizaci√≥n final\n",
    "    with fig.batch_update():\n",
    "        fig.layout.title.text = f\"‚úÖ {name} COMPLETO | Fitness: {float(best_fit):.2e}\"\n",
    "    update_display(fig, display_id=display_id)\n",
    "    \n",
    "    return best, best_fit, hist\n",
    "\n",
    "print(\"‚úÖ Framework de optimizaci√≥n interactiva definido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a657e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# üß¨ DEFINICI√ìN DE 9 METAHEUR√çSTICOS\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "# 1. Differential Evolution (DE/best/1)\n",
    "@partial(jit, static_argnums=(6,7))\n",
    "def de_step(pop, fit, best, best_fit, bounds, key, gen, max_iter, F=0.7, CR=0.85):\n",
    "    n = pop.shape[1]\n",
    "    k1, k2, k3 = random.split(key, 3)\n",
    "    a_idx = random.randint(k1, (len(pop),), 0, len(pop))\n",
    "    b_idx = random.randint(k2, (len(pop),), 0, len(pop))\n",
    "    mut = best + F*(pop[a_idx] - pop[b_idx])\n",
    "    trial = jnp.where(random.uniform(k3, pop.shape) < CR, mut, pop)\n",
    "    trial = jnp.clip(trial, bounds[:,0], bounds[:,1])\n",
    "    trial_fit = fitness_fn(trial)\n",
    "    improved = trial_fit < fit\n",
    "    pop = jnp.where(improved[:,None], trial, pop)\n",
    "    fit = jnp.where(improved, trial_fit, fit)\n",
    "    idx = jnp.argmin(fit)\n",
    "    best = jnp.where(fit[idx] < best_fit, pop[idx], best)\n",
    "    best_fit = jnp.minimum(best_fit, fit[idx])\n",
    "    return pop, fit, best, best_fit\n",
    "\n",
    "# 2. Particle Swarm Optimization (PSO)\n",
    "def pso_init(pop, bounds, key):\n",
    "    vel = random.uniform(key, pop.shape, minval=-0.1, maxval=0.1) * (bounds[:,1] - bounds[:,0])\n",
    "    return {'vel': vel, 'pbest': pop.copy(), 'pbest_fit': jnp.full(len(pop), jnp.inf)}\n",
    "\n",
    "pso_state = None\n",
    "@partial(jit, static_argnums=(6,7))\n",
    "def pso_step(pop, fit, best, best_fit, bounds, key, gen, max_iter, w=0.7, c1=1.5, c2=1.5):\n",
    "    global pso_state\n",
    "    if pso_state is None or gen == 0:\n",
    "        pso_state = pso_init(pop, bounds, key)\n",
    "    vel, pbest, pbest_fit = pso_state['vel'], pso_state['pbest'], pso_state['pbest_fit']\n",
    "    k1, k2 = random.split(key)\n",
    "    r1, r2 = random.uniform(k1, pop.shape), random.uniform(k2, pop.shape)\n",
    "    vel = w*vel + c1*r1*(pbest - pop) + c2*r2*(best - pop)\n",
    "    pop = jnp.clip(pop + vel, bounds[:,0], bounds[:,1])\n",
    "    fit = fitness_fn(pop)\n",
    "    improved = fit < pbest_fit\n",
    "    pbest = jnp.where(improved[:,None], pop, pbest)\n",
    "    pbest_fit = jnp.where(improved, fit, pbest_fit)\n",
    "    pso_state = {'vel': vel, 'pbest': pbest, 'pbest_fit': pbest_fit}\n",
    "    idx = jnp.argmin(fit)\n",
    "    best = jnp.where(fit[idx] < best_fit, pop[idx], best)\n",
    "    best_fit = jnp.minimum(best_fit, fit[idx])\n",
    "    return pop, fit, best, best_fit\n",
    "\n",
    "# 3. Grey Wolf Optimizer (GWO)\n",
    "@partial(jit, static_argnums=(6,7))\n",
    "def gwo_step(pop, fit, best, best_fit, bounds, key, gen, max_iter):\n",
    "    sorted_idx = jnp.argsort(fit)\n",
    "    alpha, beta, delta = pop[sorted_idx[0]], pop[sorted_idx[1]], pop[sorted_idx[2]]\n",
    "    a = 2.0 * (1.0 - gen/max_iter)\n",
    "    k1, k2, k3 = random.split(key, 3)\n",
    "    r1, r2 = random.uniform(k1, pop.shape), random.uniform(k2, pop.shape)\n",
    "    A1, C1 = 2*a*r1 - a, 2*r2\n",
    "    D_alpha = jnp.abs(C1*alpha - pop)\n",
    "    X1 = alpha - A1*D_alpha\n",
    "    r1, r2 = random.uniform(k2, pop.shape), random.uniform(k3, pop.shape)\n",
    "    A2, C2 = 2*a*r1 - a, 2*r2\n",
    "    X2 = beta - A2*jnp.abs(C2*beta - pop)\n",
    "    r1, r2 = random.uniform(k3, pop.shape), random.uniform(k1, pop.shape)\n",
    "    A3, C3 = 2*a*r1 - a, 2*r2\n",
    "    X3 = delta - A3*jnp.abs(C3*delta - pop)\n",
    "    pop = jnp.clip((X1 + X2 + X3)/3, bounds[:,0], bounds[:,1])\n",
    "    fit = fitness_fn(pop)\n",
    "    idx = jnp.argmin(fit)\n",
    "    best = jnp.where(fit[idx] < best_fit, pop[idx], best)\n",
    "    best_fit = jnp.minimum(best_fit, fit[idx])\n",
    "    return pop, fit, best, best_fit\n",
    "\n",
    "# 4. Whale Optimization Algorithm (WOA)\n",
    "@partial(jit, static_argnums=(6,7))\n",
    "def woa_step(pop, fit, best, best_fit, bounds, key, gen, max_iter):\n",
    "    a = 2.0 * (1.0 - gen/max_iter)\n",
    "    k1, k2, k3 = random.split(key, 3)\n",
    "    r, l, p = random.uniform(k1, pop.shape), random.uniform(k2, pop.shape)*2 - 1, random.uniform(k3, (len(pop),1))\n",
    "    A, C = 2*a*r - a, 2*random.uniform(k2, pop.shape)\n",
    "    b = 1.0\n",
    "    D = jnp.abs(best - pop)\n",
    "    spiral = D * jnp.exp(b*l) * jnp.cos(2*jnp.pi*l) + best\n",
    "    encircle = best - A*jnp.abs(C*best - pop)\n",
    "    pop = jnp.where(p < 0.5, encircle, spiral)\n",
    "    pop = jnp.clip(pop, bounds[:,0], bounds[:,1])\n",
    "    fit = fitness_fn(pop)\n",
    "    idx = jnp.argmin(fit)\n",
    "    best = jnp.where(fit[idx] < best_fit, pop[idx], best)\n",
    "    best_fit = jnp.minimum(best_fit, fit[idx])\n",
    "    return pop, fit, best, best_fit\n",
    "\n",
    "# 5. Sine-Cosine Algorithm (SCA)\n",
    "@partial(jit, static_argnums=(6,7))\n",
    "def sca_step(pop, fit, best, best_fit, bounds, key, gen, max_iter):\n",
    "    a = 2.0 * (1.0 - gen/max_iter)\n",
    "    k1, k2, k3, k4 = random.split(key, 4)\n",
    "    r1 = a * random.uniform(k1, pop.shape)\n",
    "    r2 = 2*jnp.pi*random.uniform(k2, pop.shape)\n",
    "    r3 = 2*random.uniform(k3, pop.shape)\n",
    "    r4 = random.uniform(k4, (len(pop),1))\n",
    "    update_sin = pop + r1*jnp.sin(r2)*jnp.abs(r3*best - pop)\n",
    "    update_cos = pop + r1*jnp.cos(r2)*jnp.abs(r3*best - pop)\n",
    "    pop = jnp.where(r4 < 0.5, update_sin, update_cos)\n",
    "    pop = jnp.clip(pop, bounds[:,0], bounds[:,1])\n",
    "    fit = fitness_fn(pop)\n",
    "    idx = jnp.argmin(fit)\n",
    "    best = jnp.where(fit[idx] < best_fit, pop[idx], best)\n",
    "    best_fit = jnp.minimum(best_fit, fit[idx])\n",
    "    return pop, fit, best, best_fit\n",
    "\n",
    "# 6. Salp Swarm Algorithm (SSA)\n",
    "@partial(jit, static_argnums=(6,7))\n",
    "def ssa_step(pop, fit, best, best_fit, bounds, key, gen, max_iter):\n",
    "    c1 = 2 * jnp.exp(-((4*gen/max_iter)**2))\n",
    "    k1, k2, k3 = random.split(key, 3)\n",
    "    c2, c3 = random.uniform(k1, pop.shape), random.uniform(k2, pop.shape)\n",
    "    ranges = bounds[:,1] - bounds[:,0]\n",
    "    leader_update = best + c1*((ranges)*c2 + bounds[:,0]) * jnp.where(c3 < 0.5, 1, -1)\n",
    "    n_leaders = len(pop)//2\n",
    "    new_pop = pop.at[:n_leaders].set(jnp.clip(leader_update[:n_leaders], bounds[:,0], bounds[:,1]))\n",
    "    for i in range(n_leaders, len(pop)):\n",
    "        new_pop = new_pop.at[i].set((new_pop[i] + new_pop[i-1])/2)\n",
    "    pop = jnp.clip(new_pop, bounds[:,0], bounds[:,1])\n",
    "    fit = fitness_fn(pop)\n",
    "    idx = jnp.argmin(fit)\n",
    "    best = jnp.where(fit[idx] < best_fit, pop[idx], best)\n",
    "    best_fit = jnp.minimum(best_fit, fit[idx])\n",
    "    return pop, fit, best, best_fit\n",
    "\n",
    "# 7. Harris Hawks Optimization (HHO)\n",
    "@partial(jit, static_argnums=(6,7))\n",
    "def hho_step(pop, fit, best, best_fit, bounds, key, gen, max_iter):\n",
    "    E0 = 2*random.uniform(key, (len(pop),1)) - 1\n",
    "    E = 2*E0*(1 - gen/max_iter)\n",
    "    k1, k2, k3 = random.split(key, 3)\n",
    "    q, r = random.uniform(k1, (len(pop),1)), random.uniform(k2, pop.shape)\n",
    "    Xm = jnp.mean(pop, axis=0)\n",
    "    rand_idx = random.randint(k3, (len(pop),), 0, len(pop))\n",
    "    explore = pop[rand_idx] - r*jnp.abs(pop[rand_idx] - 2*r*pop)\n",
    "    exploit = best - E*jnp.abs(best - pop)\n",
    "    pop = jnp.where(jnp.abs(E) >= 1, explore, exploit)\n",
    "    pop = jnp.clip(pop, bounds[:,0], bounds[:,1])\n",
    "    fit = fitness_fn(pop)\n",
    "    idx = jnp.argmin(fit)\n",
    "    best = jnp.where(fit[idx] < best_fit, pop[idx], best)\n",
    "    best_fit = jnp.minimum(best_fit, fit[idx])\n",
    "    return pop, fit, best, best_fit\n",
    "\n",
    "# 8. Arithmetic Optimization Algorithm (AOA)\n",
    "@partial(jit, static_argnums=(6,7))\n",
    "def aoa_step(pop, fit, best, best_fit, bounds, key, gen, max_iter):\n",
    "    MOA = 0.2 + (gen/max_iter)*0.8\n",
    "    MOP = 1 - ((gen/max_iter)**(1/5))\n",
    "    k1, k2, k3 = random.split(key, 3)\n",
    "    r1, r2, r3 = random.uniform(k1, pop.shape), random.uniform(k2, (len(pop),1)), random.uniform(k3, pop.shape)\n",
    "    ranges = bounds[:,1] - bounds[:,0]\n",
    "    mul = best / (MOP + 1e-10) * ((ranges)*r1 + bounds[:,0])\n",
    "    div = best * MOP * ((ranges)*r1 + bounds[:,0])\n",
    "    add = best - MOP * ((ranges)*r1 + bounds[:,0])\n",
    "    sub = best + MOP * ((ranges)*r1 + bounds[:,0])\n",
    "    arith = jnp.where(r3 < 0.5, mul, div)\n",
    "    update = jnp.where(r3 < 0.5, add, sub)\n",
    "    pop = jnp.where(r2 < MOA, arith, update)\n",
    "    pop = jnp.clip(pop, bounds[:,0], bounds[:,1])\n",
    "    fit = fitness_fn(pop)\n",
    "    idx = jnp.argmin(fit)\n",
    "    best = jnp.where(fit[idx] < best_fit, pop[idx], best)\n",
    "    best_fit = jnp.minimum(best_fit, fit[idx])\n",
    "    return pop, fit, best, best_fit\n",
    "\n",
    "# 9. Simplified CMA-ES\n",
    "@partial(jit, static_argnums=(6,7))\n",
    "def cmaes_step(pop, fit, best, best_fit, bounds, key, gen, max_iter):\n",
    "    mu = len(pop)//4\n",
    "    sorted_idx = jnp.argsort(fit)[:mu]\n",
    "    elite = pop[sorted_idx]\n",
    "    mean = jnp.mean(elite, axis=0)\n",
    "    sigma = 0.3 * (1 - gen/max_iter) * (bounds[:,1] - bounds[:,0])\n",
    "    new_pop = mean + random.normal(key, pop.shape) * sigma\n",
    "    pop = jnp.clip(new_pop, bounds[:,0], bounds[:,1])\n",
    "    fit = fitness_fn(pop)\n",
    "    idx = jnp.argmin(fit)\n",
    "    best = jnp.where(fit[idx] < best_fit, pop[idx], best)\n",
    "    best_fit = jnp.minimum(best_fit, fit[idx])\n",
    "    return pop, fit, best, best_fit\n",
    "\n",
    "OPTIMIZERS = {\n",
    "    '1. DE (Differential Evolution)': de_step,\n",
    "    '2. PSO (Particle Swarm)': pso_step,\n",
    "    '3. GWO (Grey Wolf)': gwo_step,\n",
    "    '4. WOA (Whale)': woa_step,\n",
    "    '5. SCA (Sine-Cosine)': sca_step,\n",
    "    '6. SSA (Salp Swarm)': ssa_step,\n",
    "    '7. HHO (Harris Hawks)': hho_step,\n",
    "    '8. AOA (Arithmetic)': aoa_step,\n",
    "    '9. CMA-ES': cmaes_step,\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ {len(OPTIMIZERS)} metaheur√≠sticos definidos:\")\n",
    "for name in OPTIMIZERS: print(f\"   ‚Ä¢ {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171832bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# CONFIGURACION DE OPTIMIZACION - FITNESS SELECCIONADO\n",
    "# =================================================================\n",
    "# [k0, k, a, m, R0, alpha]\n",
    "\n",
    "BOUNDS = jnp.stack([LOWER_BOUNDS, UPPER_BOUNDS], axis=1)\n",
    "REF = REF_6P  # Referencia de 6 parametros\n",
    "\n",
    "# Tiempo acumulado para fitness\n",
    "t_data = jnp.cumsum(dt_jax)\n",
    "\n",
    "# Crear funcion fitness seleccionada\n",
    "fitness_single = partial(FITNESS_FN, t_data=t_data, y_data=y_jax, \n",
    "                         i_data=i_jax, u_data=u_jax, mask=mask_jax, dt=dt_mean)\n",
    "fitness_fn = jit(vmap(fitness_single, in_axes=0))\n",
    "\n",
    "print(\"Configuracion de optimizacion:\")\n",
    "print(f\"  Parametros: 6 (k0, k, a, m, R0, alpha)\")\n",
    "print(f\"  Muestras: {len(y_jax)}\")\n",
    "print(f\"  dt medio: {dt_mean:.4f}s\")\n",
    "print(f\"  Fitness: {FITNESS_MODE}\")\n",
    "print(f\"  Optimizadores: {len(OPTIMIZERS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff86a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# SELECCION DE OPTIMIZADOR - 6 PARAMETROS\n",
    "# =================================================================\n",
    "SELECTED_OPTIMIZER = '1. DE (Differential Evolution)'  # Cambiar por cualquier otro\n",
    "POP_SIZE = 100\n",
    "MAX_ITER = 200\n",
    "\n",
    "print(f\"Ejecutando: {SELECTED_OPTIMIZER}\")\n",
    "print(f\"  Poblacion: {POP_SIZE}, Iteraciones: {MAX_ITER}\")\n",
    "\n",
    "t0 = time.time()\n",
    "best_params, best_fit, history = run_optimizer_interactive(\n",
    "    SELECTED_OPTIMIZER, \n",
    "    OPTIMIZERS[SELECTED_OPTIMIZER], \n",
    "    fitness_fn, BOUNDS, \n",
    "    pop_size=POP_SIZE, max_iter=MAX_ITER, ref=REF)\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "print(f\"\\nTiempo: {elapsed:.1f}s\")\n",
    "print(f\"Mejor fitness: {float(best_fit):.6e}\")\n",
    "print(\"=\"*60)\n",
    "print(\"PARAMETROS IDENTIFICADOS (6D)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  k0    = {float(best_params[0])*1000:.4f} mH  (inductancia base)\")\n",
    "print(f\"  k     = {float(best_params[1])*1000:.4f} mH  (coef. inductancia)\")\n",
    "print(f\"  a     = {float(best_params[2])*1000:.4f} mm  (parametro geometrico)\")\n",
    "print(f\"  m     = {float(best_params[3])*1000:.4f} g   (masa)\")\n",
    "print(f\"  R0    = {float(best_params[4]):.4f} ohm (resistencia base)\")\n",
    "print(f\"  alpha = {float(best_params[5]):.6f} ohm/s (deriva termica)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verificar si algun parametro choco con limites\n",
    "print(\"\\nVERIFICACION DE LIMITES:\")\n",
    "param_names = ['k0', 'k', 'a', 'm', 'R0', 'alpha']\n",
    "for i, (name, val, lo, hi) in enumerate(zip(param_names, best_params, LOWER_BOUNDS, UPPER_BOUNDS)):\n",
    "    at_lower = abs(float(val) - float(lo)) < 1e-6\n",
    "    at_upper = abs(float(val) - float(hi)) < 1e-6\n",
    "    if at_lower:\n",
    "        print(f\"  WARNING: {name} choco con limite INFERIOR ({float(lo):.4f})\")\n",
    "    elif at_upper:\n",
    "        print(f\"  WARNING: {name} choco con limite SUPERIOR ({float(hi):.4f})\")\n",
    "    else:\n",
    "        print(f\"  OK: {name} dentro de limites\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6333c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# DIAGNOSTICO DE RESIDUALES POST-OPTIMIZACION\n",
    "# =================================================================\n",
    "print(\"Ejecutando diagnostico de residuales...\")\n",
    "plot_residuals(best_params, np.array(t_data), np.array(y_jax), np.array(i_jax), np.array(u_jax), dt_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c13883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# VALIDACION DE BALANCE DE POTENCIA - PRUEBA DEFINITIVA\n",
    "# =================================================================\n",
    "# Esta grafica es la prueba de que la masa identificada es FISICAMENTE CONSISTENTE\n",
    "# Si la masa es incorrecta, P_out no coincidira con P_in durante transitorios\n",
    "print(\"Ejecutando validacion de balance de potencia...\")\n",
    "plot_power_validation(best_params, np.array(t_data), np.array(y_jax), np.array(i_jax), np.array(u_jax), dt_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d285c96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# COMPARATIVA VS SANTANA (2023) - RECUADRO ¬±15%\n",
    "# =================================================================\n",
    "def plot_comparativa_santana(params_id):\n",
    "    labels = ['k0 [mH]', 'k [mH]', 'a [mm]', 'm [g]', 'R0 [ohm]']\n",
    "    ref = [K0_REF*1000, K_REF*1000, A_REF*1000, M_REF*1000, R0_REF]\n",
    "    ident = [float(params_id[0])*1000, float(params_id[1])*1000, float(params_id[2])*1000,\n",
    "             float(params_id[3])*1000, float(params_id[4])]\n",
    "    \n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.bar(x - width/2, ref, width, label='Referencia Santana', color='#2ecc71', alpha=0.6)\n",
    "    ax.bar(x + width/2, ident, width, label='Identificado Actual', color='#e74c3c', alpha=0.8)\n",
    "    \n",
    "    # Recuadro de exito: ¬±15% de referencia\n",
    "    for i in range(len(ref)):\n",
    "        ax.add_patch(plt.Rectangle((i-0.4, ref[i]*0.85), 0.8, ref[i]*0.30,\n",
    "                                   fill=False, edgecolor='blue', linestyle='--', alpha=0.3))\n",
    "    \n",
    "    ax.set_ylabel('Valor')\n",
    "    ax.set_title('Diferencia: Identificacion vs Referencia Fisica (¬±15%)')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('comparativa_santana.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "plot_comparativa_santana(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc48ad",
   "metadata": {},
   "source": [
    "## üìä Comparaci√≥n de Todos los Optimizadores\n",
    "Ejecuta todos los metaheur√≠sticos y compara su rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc90760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# üèÜ COMPARACI√ìN DE TODOS LOS OPTIMIZADORES\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "RUN_ALL = False  # Cambiar a True para ejecutar todos\n",
    "\n",
    "if RUN_ALL:\n",
    "    results_all = {}\n",
    "    for name, step_fn in OPTIMIZERS.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üöÄ {name}\")\n",
    "        print('='*60)\n",
    "        t0 = time.time()\n",
    "        pso_state = None  # Reset PSO state\n",
    "        best, fit, hist = run_optimizer_interactive(name, step_fn, fitness_fn, BOUNDS, \n",
    "                                                     pop_size=80, max_iter=100, ref=REF)\n",
    "        results_all[name] = {\n",
    "            'best_params': np.array(best),\n",
    "            'best_fit': float(fit),\n",
    "            'time': time.time() - t0,\n",
    "            'history': hist['best']\n",
    "        }\n",
    "    \n",
    "    # Tabla comparativa\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä RESUMEN COMPARATIVO\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Optimizador':<35} {'Fitness':>12} {'Tiempo':>8} {'k0 [mH]':>10} {'a [mm]':>10}\")\n",
    "    print(\"-\"*80)\n",
    "    sorted_results = sorted(results_all.items(), key=lambda x: x[1]['best_fit'])\n",
    "    for name, r in sorted_results:\n",
    "        print(f\"{name:<35} {r['best_fit']:>12.4e} {r['time']:>7.1f}s {r['best_params'][0]*1000:>10.4f} {r['best_params'][2]*1000:>10.4f}\")\n",
    "    \n",
    "    # Gr√°fico comparativo\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    for name, r in results_all.items():\n",
    "        ax[0].semilogy(r['history'], label=name.split('.')[1].strip(), lw=1.5)\n",
    "    ax[0].set_xlabel('Generaci√≥n'); ax[0].set_ylabel('Fitness'); ax[0].legend(fontsize=8); ax[0].grid(True)\n",
    "    ax[0].set_title('Convergencia de Optimizadores', fontweight='bold')\n",
    "    \n",
    "    names = [n.split('.')[1].strip()[:10] for n in sorted_results]\n",
    "    fits = [r['best_fit'] for _, r in sorted_results]\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(names)))\n",
    "    ax[1].barh(names, fits, color=colors)\n",
    "    ax[1].set_xlabel('Fitness (menor es mejor)'); ax[1].set_xscale('log')\n",
    "    ax[1].set_title('Ranking de Optimizadores', fontweight='bold')\n",
    "    plt.tight_layout(); plt.savefig('optimizer_comparison.png', dpi=150); plt.show()\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Cambia RUN_ALL = True para ejecutar todos los optimizadores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b620029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizacion de resultados - 6 PARAMETROS\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Convergence\n",
    "axes[0,0].semilogy(history['best'], 'b-', lw=2, label='Best Fitness')\n",
    "axes[0,0].set_xlabel('Generacion'); axes[0,0].set_ylabel('Fitness'); axes[0,0].legend(); axes[0,0].grid(True)\n",
    "axes[0,0].set_title(f'Convergencia - {SELECTED_OPTIMIZER}', fontweight='bold')\n",
    "\n",
    "# Parameter bar chart - 6 params\n",
    "params_labels = ['k0\\n[mH]', 'k\\n[mH]', 'a\\n[mm]', 'm\\n[g]', 'R0\\n[ohm]', 'alpha\\nx1000']\n",
    "params_values = [float(best_params[0])*1000, float(best_params[1])*1000, float(best_params[2])*1000, \n",
    "                 float(best_params[3])*1000, float(best_params[4]), float(best_params[5])*1000]\n",
    "ref_values = [K0_REF*1000, K_REF*1000, A_REF*1000, M_REF*1000, R0_REF, ALPHA_REF*1000]\n",
    "x = np.arange(len(params_labels))\n",
    "axes[0,1].bar(x - 0.2, params_values, 0.4, label='Identificado', color='steelblue')\n",
    "axes[0,1].bar(x + 0.2, ref_values, 0.4, label='Referencia', color='coral', alpha=0.7)\n",
    "axes[0,1].set_xticks(x); axes[0,1].set_xticklabels(params_labels)\n",
    "axes[0,1].legend(); axes[0,1].grid(True, axis='y')\n",
    "axes[0,1].set_title('Parametros Identificados vs Referencia (6D)', fontweight='bold')\n",
    "\n",
    "# Position comparison usando simulate_trajectory_6p\n",
    "t_sim = jnp.cumsum(dt_jax)\n",
    "y_opt, i_opt, _ = simulate_trajectory_6p(best_params, u_jax, t_sim, dt_jax, y0, i0, GRAVITY)\n",
    "axes[1,0].plot(data['t'], data['y']*1000, 'b-', lw=0.8, label='Experimental', alpha=0.5)\n",
    "axes[1,0].plot(data['t'], np.array(y_opt)*1000, 'r-', lw=1.5, label='Simulado')\n",
    "axes[1,0].set_xlabel('t [s]'); axes[1,0].set_ylabel('y [mm]'); axes[1,0].legend(); axes[1,0].grid(True)\n",
    "axes[1,0].set_title('Comparacion de Posicion', fontweight='bold')\n",
    "\n",
    "# Current comparison\n",
    "axes[1,1].plot(data['t'], data['i'], 'b-', lw=0.8, label='Experimental', alpha=0.5)\n",
    "axes[1,1].plot(data['t'], np.array(i_opt), 'r-', lw=1.5, label='Simulado')\n",
    "axes[1,1].set_xlabel('t [s]'); axes[1,1].set_ylabel('i [A]'); axes[1,1].legend(); axes[1,1].grid(True)\n",
    "axes[1,1].set_title('Comparacion de Corriente', fontweight='bold')\n",
    "\n",
    "plt.tight_layout(); plt.savefig('results_6params.png', dpi=150); plt.show()\n",
    "\n",
    "# Calcular metricas\n",
    "mse_y = np.mean((data['y'] - np.array(y_opt))**2)\n",
    "mse_i = np.mean((data['i'] - np.array(i_opt))**2)\n",
    "print(\"\\nMetricas de ajuste:\")\n",
    "print(f\"  MSE posicion: {mse_y:.6e} m2\")\n",
    "print(f\"  MSE corriente: {mse_i:.6e} A2\")\n",
    "print(f\"  RMSE posicion: {np.sqrt(mse_y)*1000:.4f} mm\")\n",
    "print(f\"  RMSE corriente: {np.sqrt(mse_i):.4f} A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13701c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n 3D interactiva del resultado final\n",
    "fig_3d = go.Figure()\n",
    "\n",
    "# Punto √≥ptimo encontrado\n",
    "fig_3d.add_trace(go.Scatter3d(\n",
    "    x=[float(best_params[0])*1000], y=[float(best_params[1])*1000], z=[float(best_params[2])*1000],\n",
    "    mode='markers+text', marker=dict(size=15, color='lime', symbol='diamond'),\n",
    "    text=['√ìptimo'], textposition='top center', name='Par√°metros Identificados'))\n",
    "\n",
    "# Punto de referencia\n",
    "fig_3d.add_trace(go.Scatter3d(\n",
    "    x=[K0_REF*1000], y=[K0_REF*1000], z=[A_REF*1000],\n",
    "    mode='markers+text', marker=dict(size=12, color='red', symbol='cross'),\n",
    "    text=['Referencia'], textposition='bottom center', name='Referencia Santana'))\n",
    "\n",
    "# L√≠mites del espacio de b√∫squeda\n",
    "fig_3d.update_layout(\n",
    "    template=\"plotly_dark\",\n",
    "    title=f\"Resultado Final: k0={float(best_params[0])*1000:.3f}mH, k={float(best_params[1])*1000:.3f}mH, a={float(best_params[2])*1000:.3f}mm\",\n",
    "    scene=dict(\n",
    "        xaxis=dict(title='k0 [mH]', range=[BOUNDS[0,0]*1000, BOUNDS[0,1]*1000]),\n",
    "        yaxis=dict(title='k [mH]', range=[BOUNDS[1,0]*1000, BOUNDS[1,1]*1000]),\n",
    "        zaxis=dict(title='a [mm]', range=[BOUNDS[2,0]*1000, BOUNDS[2,1]*1000])),\n",
    "    width=800, height=600)\n",
    "fig_3d.show()\n",
    "\n",
    "print(\"‚úÖ Visualizaci√≥n 3D interactiva generada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cd0636",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"üìä RESULTADOS FINALES - PRINCIPIO DE M√çNIMA ACCI√ìN\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüéØ Par√°metros Identificados:\")\n",
    "print(f\"   k0 = {float(best_params[0])*1000:.4f} mH  (Inductancia base)\")\n",
    "print(f\"   k  = {float(best_params[1])*1000:.4f} mH  (Coef. inductancia)\")\n",
    "print(f\"   a  = {float(best_params[2])*1000:.4f} mm  (Par√°metro geom√©trico)\")\n",
    "print(f\"   m  = {float(best_params[3])*1000:.4f} g   (Masa)\")\n",
    "print(f\"   R0 = {float(best_params[4]):.4f} Œ©    (Resistencia base)\")\n",
    "print(f\"   alpha = {float(best_params[5]):.6f} Œ©/s (Deriva termica)\")\n",
    " \n",
    "print(f\"\\nüìê Comparaci√≥n con Referencia (Santana 2023):\")\n",
    "print(f\"   k0: {float(best_params[0])*1000:.4f} vs {K0_REF*1000:.4f} mH (Œî={abs(float(best_params[0])-K0_REF)*1000:.4f})\")\n",
    "print(f\"   a:  {float(best_params[2])*1000:.4f} vs {A_REF*1000:.4f} mm (Œî={abs(float(best_params[2])-A_REF)*1000:.4f})\")\n",
    "print(f\"   m:  {float(best_params[3])*1000:.4f} vs {M_REF*1000:.4f} g  (Œî={abs(float(best_params[3])-M_REF)*1000:.4f})\")\n",
    "print(f\"   R0: {float(best_params[4]):.4f} vs {R0_REF:.4f} Œ©  (Œî={abs(float(best_params[4])-R0_REF):.4f})\")\n",
    "print(f\"   alpha: {float(best_params[5]):.6f} vs {ALPHA_REF:.6f} Œ©/s (Œî={abs(float(best_params[5])-ALPHA_REF):.6f})\")\n",
    " \n",
    "print(f\"\\n‚úÖ Fitness final: {float(best_fit):.6e}\")\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    'params': {'k0': float(best_params[0]), 'k': float(best_params[1]), 'a': float(best_params[2]), \n",
    "               'm': float(best_params[3]), 'R0': float(best_params[4]), 'alpha': float(best_params[5])},\n",
    "    'fitness': float(best_fit),\n",
    "    'reference': {'k0': K0_REF, 'k': K_REF, 'a': A_REF, 'm': M_REF, 'R0': R0_REF, 'alpha': ALPHA_REF},\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "with open('lagrangian_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(f\"\\nüíæ Resultados guardados en 'lagrangian_results.json'\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
