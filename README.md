# ğŸ§² Levitador MagnÃ©tico Benchmark

**Problema de optimizaciÃ³n real para algoritmos bio-inspirados y metaheurÃ­sticas.**

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![DOI](https://img.shields.io/badge/DOI-pending-lightgrey.svg)]()

---

## ğŸ“‹ DescripciÃ³n

Este benchmark proporciona un **problema de optimizaciÃ³n del mundo real** basado en un sistema de levitaciÃ³n magnÃ©tica. El objetivo es identificar los parÃ¡metros fÃ­sicos de un electroimÃ¡n que minimizan el error entre un modelo dinÃ¡mico (gemelo digital) y datos experimentales reales.

A diferencia de funciones de prueba sintÃ©ticas (Rosenbrock, Rastrigin, etc.), este problema:

- âœ… Proviene de un **sistema fÃ­sico real**
- âœ… Tiene **restricciones fÃ­sicas naturales**
- âœ… Incluye **datos experimentales** para validaciÃ³n
- âœ… Es **multimodal** y presenta retos de convergencia

### ğŸ†• Nuevo: Framework Modular de OptimizaciÃ³n

El repositorio ahora incluye un **framework modular** con 8 algoritmos bio-inspirados implementados:
- Random Search (baseline)
- Differential Evolution
- Genetic Algorithm
- Grey Wolf Optimizer
- Artificial Bee Colony
- Honey Badger Algorithm
- Shrimp Optimization Algorithm
- Tianji Horse Racing Strategy

---

## ğŸ¯ El Problema de OptimizaciÃ³n

### Modelo FÃ­sico

El sistema consiste en una esfera de acero suspendida por un electroimÃ¡n. La inductancia del electroimÃ¡n varÃ­a con la distancia segÃºn:

$$L(y) = k_0 + \frac{k}{1 + y/a}$$

Donde:
| ParÃ¡metro | DescripciÃ³n | Unidad |
|-----------|-------------|--------|
| $k_0$ | Inductancia base | H |
| $k$ | Coeficiente de inductancia | H |
| $a$ | ParÃ¡metro geomÃ©trico | m |
| $y$ | PosiciÃ³n de la esfera | m |

### Objetivo

Encontrar $[k_0, k, a]$ que minimicen el **Error CuadrÃ¡tico Medio (MSE)** entre:
- La trayectoria simulada por el modelo
- Los datos experimentales reales

### Espacio de BÃºsqueda

| Variable | LÃ­mite Inferior | LÃ­mite Superior |
|----------|-----------------|-----------------|
| $k_0$ | 0.0001 | 0.1 |
| $k$ | 0.0001 | 0.1 |
| $a$ | 0.0001 | 0.05 |

---

## ğŸš€ InstalaciÃ³n

### Requisitos
- Python 3.8+
- NumPy, SciPy, Pandas
- Matplotlib (para visualizaciÃ³n)
- PyYAML (para configuraciones)

### InstalaciÃ³n rÃ¡pida

```bash
# Clonar el repositorio
git clone https://github.com/JRavenelco/levitador-benchmark.git
cd levitador-benchmark

# Instalar dependencias
pip install -r requirements.txt
```

---

## ğŸ’» Uso

### OpciÃ³n 1: Script de Benchmark (Recomendado)

El script de benchmark permite comparar mÃºltiples algoritmos fÃ¡cilmente:

```bash
# Ejecutar benchmark completo con configuraciÃ³n por defecto
python scripts/run_benchmark.py --config config/default.yaml

# Test rÃ¡pido con pocos trials
python scripts/run_benchmark.py --config config/quick_test.yaml

# Ejecutar solo un algoritmo especÃ­fico
python scripts/run_benchmark.py --config config/default.yaml --optimizer GreyWolfOptimizer

# ComparaciÃ³n completa (30 trials por algoritmo)
python scripts/run_benchmark.py --config config/full_comparison.yaml
```

**Salida del benchmark:**
- Resultados en `results/` (JSON con mÃ©tricas)
- GrÃ¡ficas de convergencia
- Box plots comparativos
- MÃ©tricas de rendimiento
- ComparaciÃ³n de tiempos de ejecuciÃ³n

### OpciÃ³n 2: Uso ProgramÃ¡tico (Python)

#### Ejemplo BÃ¡sico

```python
from levitador_benchmark import LevitadorBenchmark
from src.optimization import GreyWolfOptimizer

# Crear instancia del problema
problema = LevitadorBenchmark()

# Crear y ejecutar optimizador
optimizer = GreyWolfOptimizer(problema, pop_size=30, max_iter=100, random_seed=42)
best_solution, best_fitness = optimizer.optimize()

print(f"Mejor soluciÃ³n: k0={best_solution[0]:.6f}, k={best_solution[1]:.6f}, a={best_solution[2]:.6f}")
print(f"Error MSE: {best_fitness:.6e}")
```

#### Comparar MÃºltiples Algoritmos

```python
from levitador_benchmark import LevitadorBenchmark
from src.optimization import (
    DifferentialEvolution, GreyWolfOptimizer, 
    ArtificialBeeColony, HoneyBadgerAlgorithm
)

problema = LevitadorBenchmark(random_seed=42)

algorithms = {
    'DE': DifferentialEvolution(problema, pop_size=30, max_iter=50, random_seed=42),
    'GWO': GreyWolfOptimizer(problema, pop_size=30, max_iter=50, random_seed=42),
    'ABC': ArtificialBeeColony(problema, pop_size=30, max_iter=50, random_seed=42),
    'HBA': HoneyBadgerAlgorithm(problema, pop_size=30, max_iter=50, random_seed=42),
}

results = {}
for name, algo in algorithms.items():
    print(f"\nRunning {name}...")
    best_sol, best_fit = algo.optimize()
    results[name] = best_fit
    print(f"  Fitness: {best_fit:.6e}")

# Mostrar ranking
for name in sorted(results, key=results.get):
    print(f"{name}: {results[name]:.6e}")
```

### OpciÃ³n 3: Jupyter Notebook (Interactivo)

Abre el notebook de demostraciÃ³n:

```bash
jupyter notebook notebooks/parameter_identification_demo.ipynb
```

El notebook incluye:
- Ejemplos de uso de cada algoritmo
- VisualizaciÃ³n de convergencia
- ComparaciÃ³n estadÃ­stica
- AnÃ¡lisis de resultados

---

## ğŸ“ Estructura del Repositorio

```
levitador-benchmark/
â”œâ”€â”€ README.md                           # Este archivo
â”œâ”€â”€ LICENSE                             # Licencia MIT
â”œâ”€â”€ requirements.txt                    # Dependencias
â”œâ”€â”€ levitador_benchmark.py              # Clase principal del benchmark
â”œâ”€â”€ example_optimization.py             # Ejemplos legacy (compatibilidad)
â”‚
â”œâ”€â”€ src/                                # CÃ³digo fuente modular
â”‚   â”œâ”€â”€ optimization/                   # Algoritmos de optimizaciÃ³n
â”‚   â”‚   â”œâ”€â”€ base_optimizer.py          # Clase base abstracta
â”‚   â”‚   â”œâ”€â”€ random_search.py           # Random Search
â”‚   â”‚   â”œâ”€â”€ differential_evolution.py  # Differential Evolution
â”‚   â”‚   â”œâ”€â”€ genetic_algorithm.py       # Genetic Algorithm
â”‚   â”‚   â”œâ”€â”€ grey_wolf.py               # Grey Wolf Optimizer
â”‚   â”‚   â”œâ”€â”€ artificial_bee_colony.py   # Artificial Bee Colony
â”‚   â”‚   â”œâ”€â”€ honey_badger.py            # Honey Badger Algorithm
â”‚   â”‚   â”œâ”€â”€ shrimp.py                  # Shrimp Optimizer
â”‚   â”‚   â””â”€â”€ tianji.py                  # Tianji Horse Racing
â”‚   â”‚
â”‚   â”œâ”€â”€ visualization/                  # Utilidades de visualizaciÃ³n
â”‚   â”‚   â””â”€â”€ plots.py                   # Funciones de grÃ¡ficas
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                         # Utilidades generales
â”‚   â”‚   â””â”€â”€ config_loader.py           # Cargador de configuraciones YAML
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                          # MÃ³dulo de datos
â”‚   â””â”€â”€ models/                        # MÃ³dulo de modelos
â”‚
â”œâ”€â”€ config/                            # Configuraciones YAML
â”‚   â”œâ”€â”€ default.yaml                   # ConfiguraciÃ³n por defecto
â”‚   â”œâ”€â”€ quick_test.yaml               # Test rÃ¡pido
â”‚   â””â”€â”€ full_comparison.yaml          # ComparaciÃ³n completa
â”‚
â”œâ”€â”€ scripts/                           # Scripts ejecutables
â”‚   â””â”€â”€ run_benchmark.py              # Script principal de benchmark
â”‚
â”œâ”€â”€ notebooks/                         # Jupyter notebooks
â”‚   â””â”€â”€ parameter_identification_demo.ipynb
â”‚
â”œâ”€â”€ data/                              # Datos experimentales
â”‚   â””â”€â”€ datos_levitador.txt           # Datos del levitador real
â”‚
â”œâ”€â”€ tests/                             # Tests unitarios
â”‚   â””â”€â”€ test_benchmark.py             # Tests del benchmark
â”‚
â””â”€â”€ docs/                              # DocumentaciÃ³n adicional
    â”œâ”€â”€ DOE_experimentos.md
    â””â”€â”€ formato_datos.md
```

---

## ğŸ”§ ConfiguraciÃ³n (YAML)

Los algoritmos se configuran mediante archivos YAML. Ejemplo:

```yaml
# config/default.yaml
benchmark:
  data_path: "data/datos_levitador.txt"
  random_seed: 42
  verbose: true

optimizers:
  GreyWolfOptimizer:
    pop_size: 30
    max_iter: 100
    random_seed: 42
    verbose: true
  
  DifferentialEvolution:
    pop_size: 30
    max_iter: 100
    F: 0.8
    CR: 0.9
    random_seed: 42
    verbose: true

benchmark_settings:
  n_trials: 10
  save_history: true
  output_dir: "results"
```

---

## ğŸ“Š Algoritmos Implementados

### 1. Random Search
BÃºsqueda aleatoria (baseline).
- **Clase:** `RandomSearch`
- **ParÃ¡metros:** `n_iterations`

### 2. Differential Evolution (DE)
EvoluciÃ³n Diferencial clÃ¡sica (DE/rand/1/bin).
- **Clase:** `DifferentialEvolution`
- **ParÃ¡metros:** `pop_size`, `max_iter`, `F`, `CR`
- **Referencia:** Storn & Price (1997)

### 3. Genetic Algorithm (GA)
Algoritmo genÃ©tico con selecciÃ³n por torneo y BLX-alpha.
- **Clase:** `GeneticAlgorithm`
- **ParÃ¡metros:** `pop_size`, `generations`, `crossover_prob`, `mutation_prob`

### 4. Grey Wolf Optimizer (GWO)
Inspirado en la jerarquÃ­a y caza de lobos grises.
- **Clase:** `GreyWolfOptimizer`
- **ParÃ¡metros:** `pop_size`, `max_iter`
- **Referencia:** Mirjalili et al. (2014)

### 5. Artificial Bee Colony (ABC)
Basado en el comportamiento de abejas melÃ­feras.
- **Clase:** `ArtificialBeeColony`
- **ParÃ¡metros:** `pop_size`, `max_iter`, `limit`
- **Referencia:** Karaboga (2005)

### 6. Honey Badger Algorithm (HBA)
Inspirado en el comportamiento del tejÃ³n de miel.
- **Clase:** `HoneyBadgerAlgorithm`
- **ParÃ¡metros:** `pop_size`, `max_iter`, `beta`
- **Referencia:** Hashim et al. (2022)

### 7. Shrimp Optimization Algorithm (SOA)
Basado en el comportamiento del camarÃ³n mantis.
- **Clase:** `ShrimpOptimizer`
- **ParÃ¡metros:** `pop_size`, `max_iter`

### 8. Tianji Horse Racing Strategy
Estrategia china antigua aplicada a optimizaciÃ³n.
- **Clase:** `TianjiOptimizer`
- **ParÃ¡metros:** `pop_size`, `max_iter`

---

## ğŸ“ˆ Resultados de Referencia

Valores de referencia obtenidos experimentalmente:

| ParÃ¡metro | Valor Estimado |
|-----------|----------------|
| $k_0$ | 0.0363 H |
| $k$ | 0.0035 H |
| $a$ | 0.0052 m |

Los algoritmos bien sintonizados deberÃ­an converger a soluciones cercanas con MSE < 1e-8.

---

## ğŸ§ª Tests

Ejecutar tests unitarios:

```bash
# Instalar pytest si no estÃ¡ instalado
pip install pytest

# Ejecutar tests
pytest tests/test_benchmark.py -v
```

---

## ğŸ“š Citar este Trabajo

```bibtex
@software{levitador_benchmark,
  author = {Santana-RamÃ­rez, JosÃ© de JesÃºs},
  title = {Levitador MagnÃ©tico Benchmark: Problema de OptimizaciÃ³n Real para MetaheurÃ­sticas},
  year = {2024},
  url = {https://github.com/JRavenelco/levitador-benchmark},
  note = {Universidad AutÃ³noma de QuerÃ©taro},
  orcid = {0000-0002-6183-7379}
}
```

---

## ğŸ¤ Contribuciones

Â¡Las contribuciones son bienvenidas! Para contribuir:

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/nueva-caracteristica`)
3. Commit tus cambios (`git commit -m 'Agregar nueva caracterÃ­stica'`)
4. Push a la rama (`git push origin feature/nueva-caracteristica`)
5. Abre un Pull Request

### Agregar un Nuevo Algoritmo

Para agregar un nuevo optimizador:

1. Crea un archivo en `src/optimization/mi_algoritmo.py`
2. Hereda de `BaseOptimizer`
3. Implementa el mÃ©todo `optimize()`
4. Agrega el algoritmo a `src/optimization/__init__.py`
5. Agrega configuraciÃ³n en `config/default.yaml`
6. Actualiza la documentaciÃ³n

Ejemplo:

```python
from .base_optimizer import BaseOptimizer
import numpy as np

class MiAlgoritmo(BaseOptimizer):
    def __init__(self, problema, param1=10, **kwargs):
        super().__init__(problema, **kwargs)
        self.param1 = param1
    
    def optimize(self):
        # Tu implementaciÃ³n aquÃ­
        best_solution = ...
        best_fitness = ...
        return best_solution, best_fitness
```

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver [LICENSE](LICENSE) para mÃ¡s detalles.

---

## ğŸ“§ Contacto

- **Autor:** JosÃ© de JesÃºs Santana RamÃ­rez
- **ORCID:** [0000-0002-6183-7379](https://orcid.org/0000-0002-6183-7379)
- **InstituciÃ³n:** Doctorado en IngenierÃ­a, Universidad AutÃ³noma de QuerÃ©taro
- **Email:** jesus.santana@uaq.mx

---

## ğŸ“ Reconocimientos

Este trabajo es parte de la investigaciÃ³n doctoral en la Universidad AutÃ³noma de QuerÃ©taro sobre control y optimizaciÃ³n de sistemas no lineales.
