# ğŸ§² Levitador MagnÃ©tico Benchmark

**Problema de optimizaciÃ³n real para algoritmos bio-inspirados y metaheurÃ­sticas.**

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![DOI](https://img.shields.io/badge/DOI-pending-lightgrey.svg)]()

---

## ğŸ“‹ DescripciÃ³n

Este benchmark proporciona un **problema de optimizaciÃ³n del mundo real** basado en un sistema de levitaciÃ³n magnÃ©tica. El objetivo es identificar los parÃ¡metros fÃ­sicos de un electroimÃ¡n que minimizan el error entre un modelo dinÃ¡mico (gemelo digital) y datos experimentales reales.

A diferencia de funciones de prueba sintÃ©ticas (Rosenbrock, Rastrigin, etc.), este problema:

- âœ… Proviene de un **sistema fÃ­sico real**
- âœ… Tiene **restricciones fÃ­sicas naturales**
- âœ… Incluye **datos experimentales** para validaciÃ³n
- âœ… Es **multimodal** y presenta retos de convergencia

---

## ğŸ¯ El Problema de OptimizaciÃ³n

### Modelo FÃ­sico

El sistema consiste en una esfera de acero suspendida por un electroimÃ¡n. La inductancia del electroimÃ¡n varÃ­a con la distancia segÃºn:

$$L(y) = k_0 + \frac{k}{1 + y/a}$$

Donde:
| ParÃ¡metro | DescripciÃ³n | Unidad |
|-----------|-------------|--------|
| $k_0$ | Inductancia base | H |
| $k$ | Coeficiente de inductancia | H |
| $a$ | ParÃ¡metro geomÃ©trico | m |
| $y$ | PosiciÃ³n de la esfera | m |

### Objetivo

Encontrar $[k_0, k, a]$ que minimicen el **Error CuadrÃ¡tico Medio (MSE)** entre:
- La trayectoria simulada por el modelo
- Los datos experimentales reales

### Espacio de BÃºsqueda

| Variable | LÃ­mite Inferior | LÃ­mite Superior |
|----------|-----------------|-----------------|
| $k_0$ | 0.0001 | 0.1 |
| $k$ | 0.0001 | 0.1 |
| $a$ | 0.0001 | 0.05 |

---

## ğŸš€ InstalaciÃ³n

### Requisitos
- Python 3.8+
- NumPy
- SciPy
- Pandas (para cargar datos)
- Matplotlib (opcional, para visualizaciÃ³n)

### InstalaciÃ³n rÃ¡pida

```bash
# Clonar el repositorio
git clone https://github.com/JRavenelco/levitador-benchmark.git
cd levitador-benchmark

# Instalar dependencias
pip install numpy scipy pandas matplotlib
```

---

## ğŸ—ï¸ Arquitectura Modular

El repositorio incluye un framework modular completo para ejecutar y comparar mÃºltiples algoritmos de optimizaciÃ³n:

```
levitador-benchmark/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ optimization/          # Algoritmos de optimizaciÃ³n
â”‚   â”‚   â”œâ”€â”€ base_optimizer.py  # Clase base abstracta
â”‚   â”‚   â”œâ”€â”€ random_search.py
â”‚   â”‚   â”œâ”€â”€ differential_evolution.py
â”‚   â”‚   â”œâ”€â”€ genetic_algorithm.py
â”‚   â”‚   â”œâ”€â”€ grey_wolf_optimizer.py
â”‚   â”‚   â”œâ”€â”€ artificial_bee_colony.py
â”‚   â”‚   â”œâ”€â”€ honey_badger.py
â”‚   â”‚   â”œâ”€â”€ shrimp_optimizer.py
â”‚   â”‚   â””â”€â”€ tianji_optimizer.py
â”‚   â”œâ”€â”€ visualization/         # Utilidades de visualizaciÃ³n
â”‚   â”‚   â”œâ”€â”€ convergence_plot.py
â”‚   â”‚   â””â”€â”€ comparison_plots.py
â”‚   â””â”€â”€ utils/                 # Utilidades generales
â”‚       â””â”€â”€ config_loader.py
â”œâ”€â”€ config/                    # Configuraciones YAML
â”‚   â”œâ”€â”€ default.yaml
â”‚   â”œâ”€â”€ quick_test.yaml
â”‚   â””â”€â”€ full_comparison.yaml
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run_benchmark.py       # Script principal de benchmark
â””â”€â”€ notebooks/
    â””â”€â”€ parameter_identification_demo.ipynb
```

### Algoritmos Disponibles

| Algoritmo | Clase | Referencia |
|-----------|-------|------------|
| **Random Search** | `RandomSearch` | Baseline algorithm |
| **Differential Evolution** | `DifferentialEvolution` | Storn & Price (1997) |
| **Genetic Algorithm** | `GeneticAlgorithm` | Holland (1975) |
| **Grey Wolf Optimizer** | `GreyWolfOptimizer` | Mirjalili et al. (2014) |
| **Artificial Bee Colony** | `ArtificialBeeColony` | Karaboga (2005) |
| **Honey Badger Algorithm** | `HoneyBadgerAlgorithm` | Hashim et al. (2022) |
| **Shrimp Optimizer** | `ShrimpOptimizer` | Novel algorithm |
| **Tianji Horse Racing** | `TianjiOptimizer` | Ancient Chinese strategy |

---

## ğŸ’» Uso

### OpciÃ³n 1: CLI - Script de Benchmark

La forma mÃ¡s rÃ¡pida de comparar algoritmos es usar el script CLI:

```bash
# EjecuciÃ³n rÃ¡pida (pocos algoritmos, pocas iteraciones)
python scripts/run_benchmark.py --config config/quick_test.yaml

# ComparaciÃ³n completa (todos los algoritmos, muchas iteraciones)
python scripts/run_benchmark.py --config config/full_comparison.yaml

# EjecuciÃ³n personalizada
python scripts/run_benchmark.py --algorithms DE GA GWO --trials 10
```

**Salidas generadas:**
- ğŸ“Š GrÃ¡ficas de convergencia
- ğŸ“¦ Boxplots de comparaciÃ³n
- â±ï¸ ComparaciÃ³n de tiempos de ejecuciÃ³n
- ğŸ“„ EstadÃ­sticas en JSON
- ğŸ’¾ Resultados crudos en NPZ

### OpciÃ³n 2: Python API - Uso ProgramÃ¡tico

#### Ejemplo BÃ¡sico

```python
from levitador_benchmark import LevitadorBenchmark

# 1. Crear instancia del problema
problema = LevitadorBenchmark()

# 2. Evaluar una soluciÃ³n candidata
solucion = [0.036, 0.0035, 0.005]  # [k0, k, a]
error = problema.fitness_function(solucion)

print(f"Error MSE: {error:.6e}")
```

#### Usando Algoritmos del Framework

```python
from levitador_benchmark import LevitadorBenchmark
from src.optimization import DifferentialEvolution, GreyWolfOptimizer

# Crear problema
problema = LevitadorBenchmark(random_seed=42)

# OpciÃ³n 1: Differential Evolution
de = DifferentialEvolution(
    problema, 
    pop_size=30, 
    max_iter=100, 
    F=0.8, 
    CR=0.9,
    random_seed=42
)
best_sol, best_fitness = de.optimize()
print(f"DE - Best fitness: {best_fitness:.6e}")

# OpciÃ³n 2: Grey Wolf Optimizer
gwo = GreyWolfOptimizer(
    problema,
    pop_size=30,
    max_iter=100,
    random_seed=42
)
best_sol, best_fitness = gwo.optimize()
print(f"GWO - Best fitness: {best_fitness:.6e}")

# Acceder al historial de convergencia
convergence = gwo.get_convergence_curve()
```

#### Comparando MÃºltiples Algoritmos

```python
from src.optimization import (
    DifferentialEvolution, GeneticAlgorithm,
    GreyWolfOptimizer, ArtificialBeeColony
)
from src.visualization import plot_convergence

# Configurar problema
problema = LevitadorBenchmark(random_seed=42)

# Ejecutar algoritmos
algorithms = {
    'DE': DifferentialEvolution(problema, pop_size=30, max_iter=50, random_seed=42),
    'GA': GeneticAlgorithm(problema, pop_size=30, generations=50, random_seed=42),
    'GWO': GreyWolfOptimizer(problema, pop_size=30, max_iter=50, random_seed=42),
    'ABC': ArtificialBeeColony(problema, pop_size=30, max_iter=50, random_seed=42)
}

results = {}
histories = {}

for name, algo in algorithms.items():
    print(f"Running {name}...")
    best_sol, best_fit = algo.optimize()
    results[name] = best_fit
    histories[name] = algo.get_convergence_curve()
    print(f"  {name}: {best_fit:.6e}")

# Visualizar convergencia
plot_convergence(histories, save_path='comparison.png')
```

#### Usando Configuraciones YAML

```python
from src.utils import load_config
from src.optimization import ALGORITHM_REGISTRY

# Cargar configuraciÃ³n
config = load_config('config/default.yaml')

# Obtener configuraciÃ³n de un algoritmo
de_config = config['algorithms']['DifferentialEvolution']

# Crear optimizador desde configuraciÃ³n
problema = LevitadorBenchmark()
optimizer = DifferentialEvolution(problema, **de_config)
best_sol, best_fit = optimizer.optimize()
```

#### OpciÃ³n 3: Demo Interactivo - Jupyter Notebook

Para una experiencia interactiva con explicaciones paso a paso:

```bash
jupyter notebook notebooks/parameter_identification_demo.ipynb
```

---

## âš™ï¸ ConfiguraciÃ³n

El framework usa archivos YAML para configurar experimentos. Tres configuraciones predefinidas estÃ¡n disponibles:

### `config/quick_test.yaml`
ConfiguraciÃ³n rÃ¡pida para pruebas y depuraciÃ³n:
- 2 ensayos por algoritmo
- Poblaciones pequeÃ±as (15 individuos)
- Pocas iteraciones (20)
- Solo algoritmos principales (DE, GA, RandomSearch)

### `config/default.yaml`
ConfiguraciÃ³n balanceada para uso general:
- 5 ensayos por algoritmo
- Poblaciones medianas (30 individuos)
- Iteraciones moderadas (100)
- Todos los algoritmos habilitados

### `config/full_comparison.yaml`
ConfiguraciÃ³n completa para investigaciÃ³n:
- 10 ensayos por algoritmo
- Poblaciones grandes (50 individuos)
- Muchas iteraciones (200)
- Todos los algoritmos habilitados

### Estructura de ConfiguraciÃ³n

```yaml
benchmark:
  data_path: "data/datos_levitador.txt"
  random_seed: 42
  noise_level: 1e-5

optimization:
  n_trials: 5
  save_results: true
  output_dir: "results"

algorithms:
  DifferentialEvolution:
    enabled: true
    pop_size: 30
    max_iter: 100
    F: 0.8
    CR: 0.9
    random_seed: 42
    verbose: false

visualization:
  plot_convergence: true
  plot_boxplot: true
  save_plots: true
  plot_dir: "plots"
  dpi: 300
```

### Crear ConfiguraciÃ³n Personalizada

```yaml
# my_config.yaml
benchmark:
  data_path: "data/datos_levitador.txt"
  random_seed: 123

algorithms:
  DifferentialEvolution:
    enabled: true
    pop_size: 50
    max_iter: 150
  
  GreyWolfOptimizer:
    enabled: true
    pop_size: 40
    max_iter: 120
```

Ejecutar con configuraciÃ³n personalizada:

```bash
python scripts/run_benchmark.py --config my_config.yaml
```

---

## ğŸ”„ Compatibilidad Hacia AtrÃ¡s

El archivo original `example_optimization.py` se mantiene funcional para compatibilidad:

```python
from example_optimization import (
    RandomSearch, DifferentialEvolution, GeneticAlgorithm,
    GreyWolfOptimizer, ArtificialBeeColony, HoneyBadgerAlgorithm
)

# Uso idÃ©ntico al original
problema = LevitadorBenchmark()
algo = DifferentialEvolution(problema, pop_size=30, max_iter=100)
best_sol, best_fit = algo.optimize()
```

### Con Datos Experimentales Reales

```python
problema = LevitadorBenchmark("data/datos_levitador.txt")
```

### Control de Reproducibilidad

```python
# Usar semilla para resultados reproducibles
problema = LevitadorBenchmark(random_seed=42)

# Configurar nivel de ruido para datos sintÃ©ticos
problema = LevitadorBenchmark(noise_level=1e-4, random_seed=42)
```

### IntegraciÃ³n con Algoritmos de OptimizaciÃ³n

#### EvoluciÃ³n Diferencial (SciPy)

```python
from scipy.optimize import differential_evolution
from levitador_benchmark import LevitadorBenchmark

problema = LevitadorBenchmark()

resultado = differential_evolution(
    problema.fitness_function,
    problema.bounds,
    strategy='best1bin',
    maxiter=100,
    popsize=20,
    disp=True
)

print(f"Mejor soluciÃ³n: {resultado.x}")
print(f"Error final: {resultado.fun:.6e}")
```

#### Algoritmo GenÃ©tico (DEAP)

```python
from deap import base, creator, tools, algorithms
from levitador_benchmark import LevitadorBenchmark
import numpy as np

problema = LevitadorBenchmark()

# ConfiguraciÃ³n DEAP
creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
creator.create("Individual", list, fitness=creator.FitnessMin)

toolbox = base.Toolbox()

# Generador de individuos
def create_individual():
    return [np.random.uniform(lb, ub) for lb, ub in problema.bounds]

toolbox.register("individual", tools.initIterate, creator.Individual, create_individual)
toolbox.register("population", tools.initRepeat, list, toolbox.individual)
toolbox.register("evaluate", lambda ind: (problema.fitness_function(ind),))
toolbox.register("mate", tools.cxBlend, alpha=0.5)
toolbox.register("mutate", tools.mutGaussian, mu=0, sigma=0.01, indpb=0.2)
toolbox.register("select", tools.selTournament, tournsize=3)

# Ejecutar
pop = toolbox.population(n=50)
result = algorithms.eaSimple(pop, toolbox, cxpb=0.7, mutpb=0.2, ngen=50, verbose=True)
```

#### Enjambre de PartÃ­culas (PySwarms)

```python
import pyswarms as ps
from levitador_benchmark import LevitadorBenchmark
import numpy as np

problema = LevitadorBenchmark()
lb, ub = problema.get_bounds_array()

# FunciÃ³n wrapper para PySwarms (espera matriz de partÃ­culas)
def fitness_swarm(particles):
    return np.array([problema.fitness_function(p) for p in particles])

# Configurar PSO
options = {'c1': 0.5, 'c2': 0.3, 'w': 0.9}
optimizer = ps.single.GlobalBestPSO(
    n_particles=30,
    dimensions=3,
    options=options,
    bounds=(lb, ub)
)

# Ejecutar
best_cost, best_pos = optimizer.optimize(fitness_swarm, iters=100)
print(f"Mejor posiciÃ³n: {best_pos}")
print(f"Mejor costo: {best_cost:.6e}")
```

---

## ğŸ“Š VisualizaciÃ³n de Resultados

```python
from levitador_benchmark import LevitadorBenchmark

problema = LevitadorBenchmark()
mejor_solucion = [0.0363, 0.0035, 0.0052]

# Generar grÃ¡fica comparativa
problema.visualize_solution(mejor_solucion, save_path="resultado.png")
```


---

## ğŸ“ Estructura del Repositorio

```
levitador-benchmark/
â”œâ”€â”€ README.md                    # Este archivo
â”œâ”€â”€ LICENSE                      # Licencia MIT
â”œâ”€â”€ requirements.txt             # Dependencias del proyecto
â”œâ”€â”€ levitador_benchmark.py       # Clase principal del benchmark
â”œâ”€â”€ example_optimization.py      # Ejemplos de algoritmos
â”œâ”€â”€ tutorial_metaheuristicas.ipynb  # Notebook tutorial interactivo
â”œâ”€â”€ data/
â”‚   â””â”€â”€ datos_levitador.txt      # Datos experimentales reales
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ formato_datos.md         # DescripciÃ³n del formato de datos
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_benchmark.py        # Tests unitarios (pytest)
â””â”€â”€ videos/                      # Videos explicativos
    â”œâ”€â”€ 01_problema_fisico.mp4
    â”œâ”€â”€ 02_funcion_fitness.mp4
    â””â”€â”€ 03_como_optimizar.mp4
```

---

## ğŸ”¬ Detalles FÃ­sicos

### Ecuaciones del Sistema

El modelo dinÃ¡mico se basa en las ecuaciones de **Euler-Lagrange**:

**EcuaciÃ³n MecÃ¡nica (Newton):**
$$m\ddot{y} = \frac{1}{2}\frac{\partial L}{\partial y}i^2 + mg$$

**EcuaciÃ³n ElÃ©ctrica (Kirchhoff):**
$$L(y)\frac{di}{dt} + \frac{\partial L}{\partial y}\dot{y}i + Ri = u$$

### Constantes del Sistema

| Constante | Valor | DescripciÃ³n |
|-----------|-------|-------------|
| $m$ | 0.018 kg | Masa de la esfera |
| $g$ | 9.81 m/sÂ² | AceleraciÃ³n gravitacional |
| $R$ | 2.72 Î© | Resistencia de la bobina |

---

## ğŸ“ˆ Resultados de Referencia

Valores de referencia obtenidos experimentalmente:

| ParÃ¡metro | Valor Estimado |
|-----------|----------------|
| $k_0$ | 0.0363 H |
| $k$ | 0.0035 H |
| $a$ | 0.0052 m |

Los algoritmos bien sintonizados deberÃ­an converger a soluciones cercanas con MSE < 1e-8.

---

## ğŸ”¬ DiseÃ±o de Experimentos (DOE)

El repositorio incluye un DOE estructurado para generar datos experimentales diversos.

### Experimentos Disponibles

| Fase | Experimentos | DescripciÃ³n |
|------|--------------|-------------|
| **1** | E01, E02, E07, E08, E11 | CaracterizaciÃ³n bÃ¡sica (escalones, senoidales) |
| **2** | E03-E06, E09-E10 | CaracterizaciÃ³n extendida (rampas, pulsos) |
| **3** | V01-V06 | ValidaciÃ³n (repeticiones) |
| **4** | E12 | Robustez (PRBS) |

### Ejecutar Experimentos

```bash
# Listar experimentos disponibles
python experimentos_doe.py --listar

# Ejecutar en modo simulaciÃ³n (sin hardware)
python experimentos_doe.py --fase 1 --simular

# Ejecutar experimento especÃ­fico
python experimentos_doe.py --experimento E01

# Ejecutar todos los experimentos
python experimentos_doe.py --todos
```

### DocumentaciÃ³n Completa

Ver [docs/DOE_experimentos.md](docs/DOE_experimentos.md) para:
- DefiniciÃ³n de factores y niveles
- Protocolo experimental
- MÃ©tricas a calcular
- AnÃ¡lisis posterior

---

## ğŸ¤ Contribuciones

Â¡Las contribuciones son bienvenidas! Si usas este benchmark en tu investigaciÃ³n:

1. Reporta tus resultados abriendo un Issue
2. Comparte mejoras al cÃ³digo via Pull Request
3. Cita este trabajo en tus publicaciones

---

## ğŸ“š Citar este Trabajo

```bibtex
@software{levitador_benchmark,
  author = {Santana-RamÃ­rez, JosÃ© de JesÃºs},
  title = {Levitador MagnÃ©tico Benchmark: Problema de OptimizaciÃ³n Real para MetaheurÃ­sticas},
  year = {2024},
  url = {https://github.com/JRavenelco/levitador-benchmark},
  note = {Universidad AutÃ³noma de QuerÃ©taro},
  orcid = {0000-0002-6183-7379}
}
```

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver [LICENSE](LICENSE) para mÃ¡s detalles.

---

## ğŸ“§ Contacto

- **Autor:** JosÃ© de JesÃºs Santana RamÃ­rez
- **ORCID:** [0000-0002-6183-7379](https://orcid.org/0000-0002-6183-7379)
- **InstituciÃ³n:** Doctorado en IngenierÃ­a, Universidad AutÃ³noma de QuerÃ©taro
- **Email:** jesus.santana@uaq.mx

---

## ğŸ§  KAN-PINN: Observador Neuronal con FÃ­sica

### DescripciÃ³n

AdemÃ¡s de la optimizaciÃ³n de parÃ¡metros, este proyecto incluye un **observador de estado basado en KAN-PINN** (Kolmogorov-Arnold Networks + Physics-Informed Neural Networks) para estimar la posiciÃ³n de la esfera sin sensor directo.

### Arquitectura

```
Entradas: [i, L_est, u]
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  KAN Layer 1: 3 â†’ 32        â”‚  B-splines + Residual
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  KAN Layer 2: 32 â†’ 32       â”‚  B-splines + Residual
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  KAN Layer 3: 32 â†’ 1        â”‚  B-splines + Residual
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
Salida: y (posiciÃ³n estimada)
```

### PÃ©rdida FÃ­sica (PINN)

La red se entrena minimizando:

$$\mathcal{L} = \mathcal{L}_{datos} + \lambda \mathcal{L}_{fÃ­sica}$$

Donde la pÃ©rdida fÃ­sica impone la consistencia con el modelo de inductancia:

$$L(y) = k_0 + \frac{k}{1 + y/a}$$

### Resultados del Entrenamiento

| MÃ©trica | Valor |
|---------|-------|
| CorrelaciÃ³n | 0.589 |
| MAE | 2.88 mm |
| Datasets | 5 (~13k muestras) |

### Uso del Observador

```python
from pinn.kan_observador import KANObservador
import torch

# Cargar modelo entrenado
model = KANObservador(hidden=32, depth=2, num_knots=8)
checkpoint = torch.load('pinn/kan_observador_*.pt')
model.load_state_dict(checkpoint['model_state'])
model.eval()

# Inferencia
X = torch.tensor([[i, L_est, u]])  # [corriente, inductancia, voltaje]
y_estimado = model(X)
```

### ValidaciÃ³n con MetaheurÃ­sticos

Los parÃ¡metros $[k_0, k, a]$ identificados por metaheurÃ­sticos pueden usarse para:
1. **Validar** el modelo fÃ­sico del KAN-PINN
2. **Comparar** estimaciÃ³n KAN vs fÃ³rmula analÃ­tica
3. **Mejorar** la pÃ©rdida fÃ­sica con parÃ¡metros mÃ¡s precisos

---

## ğŸ¬ Videos Explicativos

### 1. El Problema FÃ­sico
![Problema FÃ­sico](videos/01_problema_fisico.gif)

### 2. FunciÃ³n de Fitness (MSE)
![FunciÃ³n Fitness](videos/02_funcion_fitness.gif)

### 3. Arquitectura KAN-PINN
![Arquitectura KAN](videos/03_arquitectura_kan.gif)

### 4. Algoritmos MetaheurÃ­sticos
![MetaheurÃ­sticos](videos/04_metaheuristicos.gif)

*Animaciones generadas con Manim*

---

