# ğŸ§² Levitador MagnÃ©tico Benchmark

**Problema de optimizaciÃ³n real para algoritmos bio-inspirados y metaheurÃ­sticas con pipeline de dos fases para identificaciÃ³n de parÃ¡metros y observaciÃ³n KAN-PINN.**

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![DOI](https://img.shields.io/badge/DOI-pending-lightgrey.svg)]()

---

## ğŸ“‹ DescripciÃ³n

Este benchmark proporciona un **problema de optimizaciÃ³n del mundo real** basado en un sistema de levitaciÃ³n magnÃ©tica. El repositorio incluye un pipeline completo de dos fases:

1. **Fase 1: IdentificaciÃ³n de ParÃ¡metros FÃ­sicos** - OptimizaciÃ³n con metaheurÃ­sticas para identificar parÃ¡metros del sistema (inductancia y resistencia)
2. **Fase 2: Entrenamiento KAN-PINN** - Red neuronal informada por fÃ­sica (Physics-Informed) para observaciÃ³n sensorless de posiciÃ³n

A diferencia de funciones de prueba sintÃ©ticas (Rosenbrock, Rastrigin, etc.), este problema:

- âœ… Proviene de un **sistema fÃ­sico real**
- âœ… Tiene **restricciones fÃ­sicas naturales**
- âœ… Incluye **datos experimentales** para validaciÃ³n
- âœ… Es **multimodal** y presenta retos de convergencia
- âœ… Integra **estimaciÃ³n de resistencia sin sensor de temperatura**
- âœ… Permite **entrenamiento de observadores neuronales**

---

## ğŸ¯ Pipeline de Dos Fases

### Fase 1: IdentificaciÃ³n de ParÃ¡metros FÃ­sicos

**Objetivo:** Identificar los parÃ¡metros fÃ­sicos del sistema usando metaheurÃ­sticas.

**ParÃ¡metros a optimizar:**
- `K0`: Numerador de inductancia [H]
- `A`: ParÃ¡metro geomÃ©trico [m]  
- `R0`: Resistencia base [Î©]
- `Î±`: Coeficiente de temperatura [1/Â°C]

**Modelo FÃ­sico:**

Inductancia (funciÃ³n no lineal de la posiciÃ³n):
```
L(y) = K0 / (1 + y/A)
```

Resistencia (estimada sin sensor de temperatura):
```
R(t) â‰ˆ R0 * (1 + Î±*Î”T(t))
```

Donde Î”T(t) se aproxima mediante calentamiento Joule: Î”T âˆ âˆ« iÂ²(t) dt

**Ecuaciones del sistema:**
- MecÃ¡nica: `mÂ·Ã¿ = (1/2)Â·(âˆ‚L/âˆ‚y)Â·iÂ² + mÂ·g`
- ElÃ©ctrica: `L(y)Â·(di/dt) + (âˆ‚L/âˆ‚y)Â·áºÂ·i + R(t)Â·i = u`

**EstimaciÃ³n de R(t) vÃ­a Ley de Kirchhoff:**

Sin sensor de temperatura, la resistencia se estima usando:
```
R_est(t) = (u(t) - dÏ†Ì‚(t)/dt) / i(t)
```

donde `Ï†Ì‚(t) = L(y(t)) Â· i(t)` es el flujo magnÃ©tico estimado.

**FunciÃ³n de Fitness:**

La funciÃ³n objetivo minimiza el error cuadrÃ¡tico medio (MSE) entre las trayectorias simuladas y reales:

```python
MSE_total = 0.8 * MSE_posiciÃ³n + 0.2 * MSE_corriente
```

CaracterÃ­sticas del fitness:
- **SimulaciÃ³n dinÃ¡mica**: Integra las ecuaciones diferenciales del sistema con los parÃ¡metros candidatos
- **PonderaciÃ³n balanceada**: Prioriza el ajuste de posiciÃ³n (80%) sobre corriente (20%)
- **Suavizado adaptativo**: Aplica filtros Savitzky-Golay para reducir ruido experimental
- **Submuestreo configurable**: Acelera la optimizaciÃ³n 10-50x sin pÃ©rdida significativa de precisiÃ³n
- **DetecciÃ³n de fallos**: Retorna penalizaciÃ³n alta (1e10) si la simulaciÃ³n diverge o viola restricciones fÃ­sicas

**MÃ©todos de OptimizaciÃ³n (MetaheurÃ­sticas):**

Los algoritmos metaheurÃ­sticos exploran el espacio de parÃ¡metros de forma inteligente:

1. **EvoluciÃ³n Diferencial (DE)**: Usa vectores diferencia entre miembros de la poblaciÃ³n para generar nuevos candidatos. Excelente balance exploraciÃ³n-explotaciÃ³n.

2. **Grey Wolf Optimizer (GWO)**: Simula la jerarquÃ­a de caza de lobos grises con lÃ­deres alfa, beta y delta guiando la bÃºsqueda.

3. **Artificial Bee Colony (ABC)**: Inspirado en el comportamiento de abejas melÃ­feras. Divide la poblaciÃ³n en exploradoras, trabajadoras y observadoras.

4. **Algoritmo Honey Badger (HBA)**: Modela el comportamiento de bÃºsqueda del tejÃ³n de miel, alternando entre excavaciÃ³n intensa y exploraciÃ³n.

5. **Shrimp Optimizer (SOA)**: Basado en el comportamiento adaptativo de camarones en diferentes condiciones ambientales.

6. **Tianji Optimizer**: Inspirado en la estrategia china antigua de carreras de caballos, enfocado en aprovechar ventajas locales.

7. **Algoritmo GenÃ©tico (GA)**: EvoluciÃ³n artificial con selecciÃ³n por torneo, cruce BLX-Î± y mutaciÃ³n gaussiana.

8. **Random Search**: BÃºsqueda aleatoria como baseline de comparaciÃ³n.

**CaracterÃ­sticas Avanzadas:**

- **EvaluaciÃ³n en paralelo**: Usa mÃºltiples nÃºcleos CPU para evaluar poblaciones
- **MÃºltiples trials**: Ejecuta cada algoritmo varias veces para anÃ¡lisis estadÃ­stico robusto
- **DiagnÃ³stico de residuales**: Analiza la calidad del ajuste mediante residuales de posiciÃ³n y corriente
- **ComparaciÃ³n automÃ¡tica**: Genera reportes comparativos con valores teÃ³ricos de referencia

### Fase 2: Entrenamiento KAN-PINN (Observador Sensorless)

**Objetivo:** Entrenar una red neuronal KAN (Kolmogorov-Arnold Network) informada por fÃ­sica para estimar la posiciÃ³n sin sensor directo.

**Arquitectura de dos etapas:**

1. **Etapa 1 - Observador de Flujo:**
   - Entrada: (u, i)
   - Salida: Ï†Ì‚ (flujo estimado)
   - PÃ©rdida: MSE + Kirchhoff (u = RÂ·i + dÏ†/dt)

2. **Etapa 2 - Predictor de PosiciÃ³n:**
   - Entrada: (u, i, Ï†Ì‚)
   - Salida: Å· (posiciÃ³n estimada)
   - PÃ©rdida: MSE + PINN (Ï†Ì‚ = L*(Å·)Â·i) usando K0*, A* de Fase 1

**CaracterÃ­sticas clave:**
- Usa capa HiPPO-LegS para captura temporal
- KAN con B-splines y conexiones residuales
- Curriculum learning para peso PINN
- Sin data leakage entre etapas

---

## ğŸš€ InstalaciÃ³n

### Requisitos
- Python 3.8+
- NumPy, SciPy, Pandas
- Matplotlib (visualizaciÃ³n)
- PyYAML (configuraciÃ³n)
- PyTorch >= 1.12 (opcional, solo para KAN-PINN)

### InstalaciÃ³n rÃ¡pida

```bash
# Clonar el repositorio
git clone https://github.com/JRavenelco/levitador-benchmark.git
cd levitador-benchmark

# Instalar dependencias bÃ¡sicas
pip install numpy scipy pandas matplotlib pyyaml

# Para KAN-PINN (Fase 2), instalar PyTorch:
pip install torch
```

### âš¡ Quick Start - Benchmark Completo

Para ejecutar rÃ¡pidamente un benchmark completo de todos los algoritmos:

```bash
# Ejecutar benchmark completo (todos los algoritmos, 5 trials)
python scripts/run_full_optimization.py

# Ver resultados generados
ls -l results/optimization_comparison/
cat results/optimization_comparison/BENCHMARK_REPORT.md
```

Este script compara automÃ¡ticamente 8 algoritmos metaheurÃ­sticos y genera reportes detallados con visualizaciones. Ver [secciÃ³n completa](#-benchmark-completo-de-optimizaciÃ³n) para mÃ¡s detalles.

---

## ğŸ—ï¸ Arquitectura Modular

El repositorio incluye un framework modular completo para el pipeline de dos fases:

```
levitador-benchmark/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ benchmarks/             # Benchmarks de optimizaciÃ³n
â”‚   â”‚   â”œâ”€â”€ parameter_benchmark.py   # Fase 1: IdentificaciÃ³n de parÃ¡metros
â”‚   â”‚   â””â”€â”€ kanpinn_benchmark.py     # Fase 2: Hyperparams KAN-PINN
â”‚   â”œâ”€â”€ kan_pinn/               # MÃ³dulo KAN-PINN (requiere PyTorch)
â”‚   â”‚   â”œâ”€â”€ hippo_layer.py      # Capa HiPPO-LegS
â”‚   â”‚   â”œâ”€â”€ kan_layer.py        # Capa KAN con B-splines
â”‚   â”‚   â”œâ”€â”€ flux_observer.py    # Etapa 1: Observador de flujo
â”‚   â”‚   â”œâ”€â”€ position_predictor.py  # Etapa 2: Predictor de posiciÃ³n
â”‚   â”‚   â”œâ”€â”€ physics_loss.py     # PÃ©rdidas fÃ­sicas
â”‚   â”‚   â””â”€â”€ trainer.py          # Entrenador con curriculum learning
â”‚   â”œâ”€â”€ optimization/           # Algoritmos de optimizaciÃ³n
â”‚   â”‚   â”œâ”€â”€ base_optimizer.py   # Clase base abstracta
â”‚   â”‚   â”œâ”€â”€ random_search.py
â”‚   â”‚   â”œâ”€â”€ differential_evolution.py
â”‚   â”‚   â”œâ”€â”€ genetic_algorithm.py
â”‚   â”‚   â”œâ”€â”€ grey_wolf_optimizer.py
â”‚   â”‚   â”œâ”€â”€ artificial_bee_colony.py
â”‚   â”‚   â”œâ”€â”€ honey_badger.py
â”‚   â”‚   â”œâ”€â”€ shrimp_optimizer.py
â”‚   â”‚   â””â”€â”€ tianji_optimizer.py
â”‚   â”œâ”€â”€ visualization/          # Utilidades de visualizaciÃ³n
â”‚   â”‚   â”œâ”€â”€ convergence_plot.py
â”‚   â”‚   â””â”€â”€ comparison_plots.py
â”‚   â””â”€â”€ utils/                  # Utilidades generales
â”‚       â””â”€â”€ config_loader.py
â”œâ”€â”€ config/                     # Configuraciones YAML
â”‚   â”œâ”€â”€ pipeline_config.yaml    # Pipeline completo (Fase 1 + 2)
â”‚   â”œâ”€â”€ kanpinn_default.yaml    # Config KAN-PINN
â”‚   â”œâ”€â”€ default.yaml            # Config optimizaciÃ³n estÃ¡ndar
â”‚   â”œâ”€â”€ quick_test.yaml
â”‚   â””â”€â”€ full_comparison.yaml
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ optimize_parameters.py  # Script Fase 1
â”‚   â”œâ”€â”€ train_kanpinn.py        # Script Fase 2
â”‚   â”œâ”€â”€ pipeline_identificacion_kanpinn.py  # Orquestador completo
â”‚   â””â”€â”€ run_benchmark.py        # Benchmark original
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ datos_levitador.txt     # Datos experimentales
â”‚   â””â”€â”€ sesiones_kan_pinn/      # Datasets para KAN-PINN
â””â”€â”€ notebooks/
    â””â”€â”€ KAN_SENSORLESS_REAL.ipynb  # Demo KAN-PINN
```

### Algoritmos Disponibles

Los siguientes algoritmos metaheurÃ­sticos estÃ¡n implementados y optimizados para la identificaciÃ³n de parÃ¡metros:

| Algoritmo | Clase | Referencia | CaracterÃ­sticas Clave |
|-----------|-------|------------|----------------------|
| **Differential Evolution** | `DifferentialEvolution` | Storn & Price (1997) | MutaciÃ³n basada en diferencias vectoriales, excelente para espacios continuos |
| **Grey Wolf Optimizer** | `GreyWolfOptimizer` | Mirjalili et al. (2014) | JerarquÃ­a de liderazgo, balance exploraciÃ³n-explotaciÃ³n |
| **Artificial Bee Colony** | `ArtificialBeeColony` | Karaboga (2005) | MÃºltiples roles (exploradoras, trabajadoras, observadoras) |
| **Honey Badger Algorithm** | `HoneyBadgerAlgorithm` | Hashim et al. (2022) | BÃºsqueda adaptativa con alternancia excavaciÃ³n/exploraciÃ³n |
| **Shrimp Optimizer** | `ShrimpOptimizer` | Novel algorithm | Comportamiento adaptativo multi-fase |
| **Tianji Horse Racing** | `TianjiOptimizer` | Ancient Chinese strategy | Estrategia de aprovechamiento de ventajas locales |
| **Genetic Algorithm** | `GeneticAlgorithm` | Holland (1975) | SelecciÃ³n por torneo, cruce BLX-Î±, mutaciÃ³n gaussiana |
| **Random Search** | `RandomSearch` | Baseline algorithm | BÃºsqueda aleatoria uniforme (referencia de comparaciÃ³n) |

**Notas de ImplementaciÃ³n:**

Todos los algoritmos comparten la interfaz comÃºn `BaseOptimizer` que proporciona:
- GestiÃ³n automÃ¡tica de lÃ­mites (bounds enforcement)
- Registro de historial de convergencia
- Contador de evaluaciones de fitness
- Soporte para semillas aleatorias (reproducibilidad)
- Modo verbose para depuraciÃ³n

**Recomendaciones de Uso:**

- **Para convergencia rÃ¡pida**: Differential Evolution (DE) o Grey Wolf Optimizer (GWO)
- **Para robustez**: Artificial Bee Colony (ABC) o Honey Badger (HBA)  
- **Para exploraciÃ³n exhaustiva**: Usar mÃºltiples algoritmos y comparar resultados
- **Para problemas de alta dimensionalidad**: DE o SOA
- **Para baseline/comparaciÃ³n**: Random Search


---

## ğŸ’» Uso del Pipeline

### Pipeline Completo: Fase 1 + Fase 2

```bash
# Ejecutar pipeline completo (identificaciÃ³n + entrenamiento)
python scripts/pipeline_identificacion_kanpinn.py --config config/pipeline_config.yaml

# Solo Fase 1 (identificaciÃ³n de parÃ¡metros)
python scripts/pipeline_identificacion_kanpinn.py --phase1-only

# Solo Fase 2 (entrenamiento KAN-PINN con parÃ¡metros existentes)
python scripts/pipeline_identificacion_kanpinn.py --phase2-only \
    --use-params results/parameter_identification/parametros_optimos.json
```

### Fase 1: IdentificaciÃ³n de ParÃ¡metros

```bash
# EjecuciÃ³n con configuraciÃ³n completa
python scripts/optimize_parameters.py --config config/pipeline_config.yaml

# EjecuciÃ³n rÃ¡pida con algoritmos especÃ­ficos
python scripts/optimize_parameters.py --algorithms DE GWO ABC --trials 10

# EjecuciÃ³n personalizada
python scripts/optimize_parameters.py \
    --data data/datos_levitador.txt \
    --algorithms DE GWO HBA SOA Tianji GA RandomSearch \
    --trials 5 \
    --output results/my_optimization
```

**Salidas generadas:**
- ğŸ“„ `parametros_optimos.json` - ParÃ¡metros Ã³ptimos [K0, A, R0, Î±]
- ğŸ“„ `optimization_results.json` - EstadÃ­sticas de todos los algoritmos
- ğŸ“Š `convergence_*.png` - Curvas de convergencia por algoritmo
- ğŸ“Š `comparison_boxplot.png` - ComparaciÃ³n de rendimiento
- ğŸ“Š `best_solution.png` - VisualizaciÃ³n de la mejor soluciÃ³n

### Fase 2: Entrenamiento KAN-PINN

```bash
# Entrenar con configuraciÃ³n por defecto
python scripts/train_kanpinn.py --config config/kanpinn_default.yaml

# Usar parÃ¡metros de Fase 1
python scripts/train_kanpinn.py \
    --config config/kanpinn_default.yaml \
    --use-params results/parameter_identification/parametros_optimos.json

# Entrenar solo una etapa
python scripts/train_kanpinn.py --stage 1  # Solo observador de flujo
python scripts/train_kanpinn.py --stage 2  # Solo predictor de posiciÃ³n
```

**Nota:** Fase 2 requiere PyTorch. La implementaciÃ³n completa estÃ¡ basada en el notebook `KAN_SENSORLESS_REAL.ipynb`.

### Python API - Fase 1

```python
from src.benchmarks import ParameterBenchmark
from src.optimization import DifferentialEvolution, GreyWolfOptimizer

# Crear problema de identificaciÃ³n de parÃ¡metros
problema = ParameterBenchmark(
    data_path='data/datos_levitador.txt',
    subsample_factor=20,  # Submuestreo para velocidad
    verbose=True
)

print(f"Optimizing {problema.dim} parameters: {problema.variable_names}")
print(f"Bounds: {problema.bounds}")

# Usar Differential Evolution
de = DifferentialEvolution(
    problema,
    pop_size=30,
    max_iter=100,
    F=0.8,
    CR=0.9,
    random_seed=42
)

best_sol, best_fitness = de.optimize()
print(f"Best parameters: K0={best_sol[0]:.6f}, A={best_sol[1]:.6f}, "
      f"R0={best_sol[2]:.4f}, Î±={best_sol[3]:.6f}")
print(f"Best fitness: {best_fitness:.6e}")

# Visualizar soluciÃ³n
problema.visualize_solution(best_sol, save_path='results/solution.png')

# Estimar curva de resistencia
R_curve = problema.estimate_resistance_curve(best_sol[0], best_sol[1])
print(f"R(t) range: [{R_curve.min():.3f}, {R_curve.max():.3f}] Î©")
```

### Entendiendo el Proceso de OptimizaciÃ³n MetaheurÃ­stica

**Â¿CÃ³mo funcionan los metaheurÃ­sticos en este problema?**

1. **InicializaciÃ³n**: Cada algoritmo crea una poblaciÃ³n de soluciones candidatas `Î¸ = [K0, A, R0, Î±]` dentro de los lÃ­mites fÃ­sicos definidos.

2. **EvaluaciÃ³n**: Para cada candidato:
   - Se simula el sistema dinÃ¡mico completo usando las EDOs
   - Se compara la trayectoria simulada con los datos experimentales
   - Se calcula el MSE como medida de calidad (fitness)

3. **EvoluciÃ³n/BÃºsqueda**: Los algoritmos usan diferentes estrategias bio-inspiradas:
   - **DE**: Combina vectores diferencia para generar mutantes
   - **GWO**: Sigue a los mejores "lobos" (soluciones) del grupo
   - **ABC**: Abejas exploradoras buscan nuevas fuentes de alimento (soluciones)
   - **Otros**: Cada algoritmo implementa su propia metÃ¡fora de bÃºsqueda

4. **Convergencia**: El proceso se repite hasta:
   - Alcanzar un MSE suficientemente bajo (< 1e-7)
   - Completar el nÃºmero mÃ¡ximo de iteraciones
   - Detectar estancamiento (sin mejora significativa)

**Ejemplo de Salida de Convergencia:**

```
Iteration 10/100: Best fitness = 3.45e-06
Iteration 20/100: Best fitness = 1.23e-06  
Iteration 30/100: Best fitness = 4.56e-07
Iteration 40/100: Best fitness = 2.31e-07
Iteration 50/100: Best fitness = 8.92e-08  âœ“ Target reached!

Final parameters:
  K0 = 0.036234 H   (theoretical: 0.0363)
  A  = 0.005123 m   (theoretical: 0.0052)
  R0 = 2.718 Î©      (estimated)
  Î±  = 0.00387 /Â°C  (estimated)
```

**Ventajas de Usar MÃºltiples Algoritmos:**

- Diferentes algoritmos tienen fortalezas en diferentes regiones del espacio de bÃºsqueda
- La comparaciÃ³n permite identificar el mÃ©todo mÃ¡s robusto para este problema especÃ­fico
- Los resultados estadÃ­sticos (media, desviaciÃ³n) revelan la estabilidad del algoritmo
- El anÃ¡lisis de convergencia muestra quÃ© algoritmos requieren mÃ¡s evaluaciones

### Python API - Compatibilidad con Benchmark Original

El benchmark original (`LevitadorBenchmark`) sigue funcionando para problemas simples:

```python
from levitador_benchmark import LevitadorBenchmark

# Problema original (3 parÃ¡metros: k0, k, a)
problema = LevitadorBenchmark()

# Evaluar una soluciÃ³n candidata
solucion = [0.036, 0.0035, 0.005]  # [k0, k, a]
error = problema.fitness_function(solucion)

print(f"Error MSE: {error:.6e}")
```

---

## ğŸš€ Benchmark Completo de OptimizaciÃ³n

### EjecuciÃ³n RÃ¡pida

Para ejecutar un benchmark completo comparando todos los algoritmos metaheurÃ­sticos disponibles:

```bash
# Ejecutar benchmark completo con configuraciÃ³n por defecto
python scripts/run_full_optimization.py

# Ejecutar con configuraciÃ³n personalizada
python scripts/run_full_optimization.py --config config/full_optimization.yaml

# Ejecutar con mÃ¡s trials para mejor anÃ¡lisis estadÃ­stico
python scripts/run_full_optimization.py --trials 10

# Ejecutar con semilla diferente para reproducibilidad
python scripts/run_full_optimization.py --seed 123
```

### Â¿QuÃ© hace este script?

El script `run_full_optimization.py` ejecuta un benchmark exhaustivo que:

1. **Carga datos experimentales** de `data/datos_levitador.txt`
2. **Ejecuta todos los algoritmos disponibles**:
   - Differential Evolution (DE)
   - Grey Wolf Optimizer (GWO)
   - Artificial Bee Colony (ABC)
   - Honey Badger Algorithm (HBA)
   - Shrimp Optimizer (SOA)
   - Tianji Optimizer (Tianji)
   - Genetic Algorithm (GA)
   - Random Search (Random)

3. **Configura cada algoritmo con parÃ¡metros optimizados**:
   - `pop_size`: 50 individuos
   - `max_iter`: 200 iteraciones
   - ParÃ¡metros especÃ­ficos bien ajustados

4. **Ejecuta mÃºltiples trials** (default: 5) por algoritmo para estadÃ­sticas robustas

5. **Compara con valores teÃ³ricos de referencia**:
   - kâ‚€ = 0.0363 H
   - k = 0.0035 H
   - a = 0.0052 m

6. **Genera reportes y visualizaciones**:
   - ğŸ“Š Curvas de convergencia comparativas
   - ğŸ“¦ Boxplot de rendimiento
   - ğŸ“‹ Tabla de comparaciÃ³n con valores teÃ³ricos
   - ğŸ“„ Reporte detallado en markdown (`BENCHMARK_REPORT.md`)

### Resultados Generados

Todos los resultados se guardan en `results/optimization_comparison/`:

```
results/optimization_comparison/
â”œâ”€â”€ BENCHMARK_REPORT.md          # Reporte completo en markdown
â”œâ”€â”€ optimization_results.json     # Resultados en formato JSON
â”œâ”€â”€ convergence_curves.png        # Curvas de convergencia
â”œâ”€â”€ performance_boxplot.png       # Boxplot comparativo
â””â”€â”€ comparison_table.png          # Tabla con valores teÃ³ricos
```

### InterpretaciÃ³n de Resultados

El reporte incluye:

1. **Ranking de algoritmos** - Ordenados por mejor MSE obtenido
2. **EstadÃ­sticas detalladas** - Media, desviaciÃ³n estÃ¡ndar, mejor, peor
3. **ComparaciÃ³n con teÃ³ricos** - Errores porcentuales para cada parÃ¡metro
4. **Criterios de Ã©xito**:
   - âœ… MSE < 1e-7
   - âœ… ParÃ¡metros dentro del 10% de valores teÃ³ricos

### Ejemplo de Salida

```
ğŸ† BEST ALGORITHM:
   DE (DifferentialEvolution)
   MSE: 2.345678e-08
   kâ‚€ = 0.036234 H  (theoretical: 0.0363)
   k  = 0.003487 H  (theoretical: 0.0035)
   a  = 0.005123 m  (theoretical: 0.0052)

âœ“ SUCCESS CRITERIA:
   MSE < 1e-07: âœ… PASS
   Parameters within 10%: âœ… PASS
```

### InterpretaciÃ³n de Resultados de MetaheurÃ­sticos

**MÃ©tricas Clave:**

1. **MSE (Mean Squared Error)**: Medida principal de calidad del ajuste
   - Excelente: MSE < 1e-7
   - Bueno: 1e-7 < MSE < 1e-6
   - Aceptable: 1e-6 < MSE < 1e-5
   - Requiere ajuste: MSE > 1e-5

2. **Convergencia**: Iteraciones necesarias para alcanzar el Ã³ptimo
   - Convergencia rÃ¡pida: < 30 iteraciones
   - Convergencia normal: 30-80 iteraciones
   - Convergencia lenta: > 80 iteraciones

3. **Robustez**: Consistencia entre mÃºltiples trials
   - DesviaciÃ³n estÃ¡ndar baja (< 10% de la media) indica alta robustez
   - DesviaciÃ³n estÃ¡ndar alta sugiere sensibilidad a inicializaciÃ³n

4. **ComparaciÃ³n con Valores TeÃ³ricos**:
   - Los parÃ¡metros K0 y A pueden validarse con valores de referencia
   - R0 y Î± son estimados (no hay mediciÃ³n directa de temperatura)
   - Error porcentual < 10% indica identificaciÃ³n exitosa

**DiagnÃ³stico de Problemas Comunes:**

| SÃ­ntoma | Posible Causa | SoluciÃ³n |
|---------|---------------|----------|
| MSE estancado en valor alto | MÃ­nimo local, poblaciÃ³n pequeÃ±a | Aumentar `pop_size`, cambiar algoritmo |
| Convergencia muy lenta | ParÃ¡metros conservadores | Ajustar F, CR (DE) o tasas de mutaciÃ³n |
| Resultados inconsistentes | Sensibilidad a ruido en datos | Aumentar `smoothing_window`, validar datos |
| ParÃ¡metros fuera de rango fÃ­sico | Bounds incorrectos | Revisar lÃ­mites en configuraciÃ³n |
| SimulaciÃ³n falla (fitness = 1e10) | ParÃ¡metros causan inestabilidad numÃ©rica | Ajustar tolerancias ODE, revidar bounds |

**Visualizaciones Generadas:**

1. **Curvas de Convergencia** (`convergence_*.png`): Muestra la evoluciÃ³n del mejor fitness vs. iteraciones
   - LÃ­nea descendente suave indica bÃºsqueda eficiente
   - LÃ­nea con muchas mesetas sugiere dificultad en escapar mÃ­nimos locales

2. **Boxplot de ComparaciÃ³n** (`comparison_boxplot.png`): Compara distribuciÃ³n de fitness entre algoritmos
   - Caja mÃ¡s baja = mejor desempeÃ±o promedio
   - Caja mÃ¡s pequeÃ±a = mayor robustez

3. **VisualizaciÃ³n de SoluciÃ³n** (`best_solution.png`): Compara trayectorias simuladas vs. reales
   - SuperposiciÃ³n cercana indica buen ajuste
   - Divergencias revelan limitaciones del modelo o ruido en datos

### ConfiguraciÃ³n Personalizada

Puedes crear tu propia configuraciÃ³n editando `config/full_optimization.yaml`:

```yaml
# Ajustar nÃºmero de trials
benchmark:
  n_trials: 10  # MÃ¡s trials = mejor estadÃ­stica

# Ajustar parÃ¡metros de optimizaciÃ³n
optimization:
  pop_size: 100    # MÃ¡s individuos = mejor exploraciÃ³n
  max_iter: 300    # MÃ¡s iteraciones = mejor convergencia

# Habilitar/deshabilitar algoritmos
algorithms:
  DifferentialEvolution:
    enabled: true
    pop_size: 50
    max_iter: 200
  
  RandomSearch:
    enabled: false  # Deshabilitar si no es necesario
```

---

## ğŸ’» Uso del Benchmark Original (3 parÃ¡metros)

### OpciÃ³n 1: CLI - Script de Benchmark

La forma mÃ¡s rÃ¡pida de comparar algoritmos es usar el script CLI:

```bash
# EjecuciÃ³n rÃ¡pida (pocos algoritmos, pocas iteraciones)
python scripts/run_benchmark.py --config config/quick_test.yaml

# ComparaciÃ³n completa (todos los algoritmos, muchas iteraciones)
python scripts/run_benchmark.py --config config/full_comparison.yaml

# EjecuciÃ³n personalizada
python scripts/run_benchmark.py --algorithms DE GA GWO --trials 10
```

**Salidas generadas:**
- ğŸ“Š GrÃ¡ficas de convergencia
- ğŸ“¦ Boxplots de comparaciÃ³n
- â±ï¸ ComparaciÃ³n de tiempos de ejecuciÃ³n
- ğŸ“„ EstadÃ­sticas en JSON
- ğŸ’¾ Resultados crudos en NPZ

### OpciÃ³n 2: Python API - Uso ProgramÃ¡tico

#### Ejemplo BÃ¡sico

```python
from levitador_benchmark import LevitadorBenchmark

# 1. Crear instancia del problema
problema = LevitadorBenchmark()

# 2. Evaluar una soluciÃ³n candidata
solucion = [0.036, 0.0035, 0.005]  # [k0, k, a]
error = problema.fitness_function(solucion)

print(f"Error MSE: {error:.6e}")
```

#### Usando Algoritmos del Framework

```python
from levitador_benchmark import LevitadorBenchmark
from src.optimization import DifferentialEvolution, GreyWolfOptimizer

# Crear problema
problema = LevitadorBenchmark(random_seed=42)

# OpciÃ³n 1: Differential Evolution
de = DifferentialEvolution(
    problema, 
    pop_size=30, 
    max_iter=100, 
    F=0.8, 
    CR=0.9,
    random_seed=42
)
best_sol, best_fitness = de.optimize()
print(f"DE - Best fitness: {best_fitness:.6e}")

# OpciÃ³n 2: Grey Wolf Optimizer
gwo = GreyWolfOptimizer(
    problema,
    pop_size=30,
    max_iter=100,
    random_seed=42
)
best_sol, best_fitness = gwo.optimize()
print(f"GWO - Best fitness: {best_fitness:.6e}")

# Acceder al historial de convergencia
convergence = gwo.get_convergence_curve()
```

#### Comparando MÃºltiples Algoritmos

```python
from src.optimization import (
    DifferentialEvolution, GeneticAlgorithm,
    GreyWolfOptimizer, ArtificialBeeColony
)
from src.visualization import plot_convergence

# Configurar problema
problema = LevitadorBenchmark(random_seed=42)

# Ejecutar algoritmos
algorithms = {
    'DE': DifferentialEvolution(problema, pop_size=30, max_iter=50, random_seed=42),
    'GA': GeneticAlgorithm(problema, pop_size=30, generations=50, random_seed=42),
    'GWO': GreyWolfOptimizer(problema, pop_size=30, max_iter=50, random_seed=42),
    'ABC': ArtificialBeeColony(problema, pop_size=30, max_iter=50, random_seed=42)
}

results = {}
histories = {}

for name, algo in algorithms.items():
    print(f"Running {name}...")
    best_sol, best_fit = algo.optimize()
    results[name] = best_fit
    histories[name] = algo.get_convergence_curve()
    print(f"  {name}: {best_fit:.6e}")

# Visualizar convergencia
plot_convergence(histories, save_path='comparison.png')
```

#### Usando Configuraciones YAML

```python
from src.utils import load_config
from src.optimization import ALGORITHM_REGISTRY

# Cargar configuraciÃ³n
config = load_config('config/default.yaml')

# Obtener configuraciÃ³n de un algoritmo
de_config = config['algorithms']['DifferentialEvolution']

# Crear optimizador desde configuraciÃ³n
problema = LevitadorBenchmark()
optimizer = DifferentialEvolution(problema, **de_config)
best_sol, best_fit = optimizer.optimize()
```

#### OpciÃ³n 3: Demo Interactivo - Jupyter Notebook

Para una experiencia interactiva con explicaciones paso a paso:

```bash
jupyter notebook notebooks/parameter_identification_demo.ipynb
```

---

## âš™ï¸ ConfiguraciÃ³n

El framework usa archivos YAML para configurar experimentos. Tres configuraciones predefinidas estÃ¡n disponibles:

### `config/quick_test.yaml`
ConfiguraciÃ³n rÃ¡pida para pruebas y depuraciÃ³n:
- 2 ensayos por algoritmo
- Poblaciones pequeÃ±as (15 individuos)
- Pocas iteraciones (20)
- Solo algoritmos principales (DE, GA, RandomSearch)

### `config/default.yaml`
ConfiguraciÃ³n balanceada para uso general:
- 5 ensayos por algoritmo
- Poblaciones medianas (30 individuos)
- Iteraciones moderadas (100)
- Todos los algoritmos habilitados

### `config/full_comparison.yaml`
ConfiguraciÃ³n completa para investigaciÃ³n:
- 10 ensayos por algoritmo
- Poblaciones grandes (50 individuos)
- Muchas iteraciones (200)
- Todos los algoritmos habilitados

### Estructura de ConfiguraciÃ³n

```yaml
benchmark:
  data_path: "data/datos_levitador.txt"
  random_seed: 42
  noise_level: 1e-5

optimization:
  n_trials: 5
  save_results: true
  output_dir: "results"

algorithms:
  DifferentialEvolution:
    enabled: true
    pop_size: 30
    max_iter: 100
    F: 0.8
    CR: 0.9
    random_seed: 42
    verbose: false

visualization:
  plot_convergence: true
  plot_boxplot: true
  save_plots: true
  plot_dir: "plots"
  dpi: 300
```

### Crear ConfiguraciÃ³n Personalizada

```yaml
# my_config.yaml
benchmark:
  data_path: "data/datos_levitador.txt"
  random_seed: 123

algorithms:
  DifferentialEvolution:
    enabled: true
    pop_size: 50
    max_iter: 150
  
  GreyWolfOptimizer:
    enabled: true
    pop_size: 40
    max_iter: 120
```

Ejecutar con configuraciÃ³n personalizada:

```bash
python scripts/run_benchmark.py --config my_config.yaml
```

### Mejores PrÃ¡cticas para OptimizaciÃ³n MetaheurÃ­stica

**1. ConfiguraciÃ³n de PoblaciÃ³n e Iteraciones:**

La relaciÃ³n entre poblaciÃ³n y nÃºmero de iteraciones afecta el presupuesto total de evaluaciones:

```
Evaluaciones Totales â‰ˆ pop_size Ã— max_iter
```

Recomendaciones por complejidad del problema:
- **Problema simple (3 parÃ¡metros)**: `pop_size=30`, `max_iter=50-100`
- **Problema moderado (4 parÃ¡metros + R(t))**: `pop_size=50`, `max_iter=100-200`
- **Problema complejo (muchos parÃ¡metros)**: `pop_size=100`, `max_iter=200-500`

**2. Ajuste de HiperparÃ¡metros por Algoritmo:**

| Algoritmo | ParÃ¡metro CrÃ­tico | Valor Recomendado | Efecto |
|-----------|-------------------|-------------------|---------|
| DE | F (mutation factor) | 0.5-0.9 | Mayor F â†’ mÃ¡s exploraciÃ³n |
| DE | CR (crossover rate) | 0.7-0.95 | Mayor CR â†’ mÃ¡s diversidad |
| GWO | a (linearly decreased) | 2â†’0 | Controla exploraciÃ³n vs explotaciÃ³n |
| ABC | limit (abandonment) | pop_size Ã— dim | Mayor limit â†’ mÃ¡s persistencia |
| GA | crossover_prob | 0.7-0.9 | Mayor prob â†’ mÃ¡s recombinaciÃ³n |
| GA | mutation_prob | 0.1-0.3 | Mayor prob â†’ mÃ¡s diversidad |

**3. Estrategias de AceleraciÃ³n:**

Para problemas con datos experimentales largos (>10,000 muestras):

- **Submuestreo**: `subsample_factor=10-50` reduce tiempo ~10-50x
- **EvaluaciÃ³n paralela**: AutomÃ¡tica si mÃºltiples nÃºcleos disponibles
- **Early stopping**: Configurar tolerancia de convergencia

```python
problema = ParameterBenchmark(
    data_path='data/datos_levitador.txt',
    subsample_factor=20,  # Usa solo 1 de cada 20 muestras
    verbose=True
)
```

**4. Reproducibilidad:**

Siempre usar semillas aleatorias para experimentos reproducibles:

```python
optimizer = DifferentialEvolution(
    problema,
    pop_size=30,
    max_iter=100,
    random_seed=42  # â† Garantiza resultados reproducibles
)
```

Para mÃºltiples trials con diferentes semillas:
```python
for trial in range(5):
    seed = base_seed + trial
    optimizer = DifferentialEvolution(problema, random_seed=seed)
    best_sol, best_fit = optimizer.optimize()
```

**5. ValidaciÃ³n de Resultados:**

DespuÃ©s de la optimizaciÃ³n, siempre:

1. **Verificar convergencia**: Revisar curva de convergencia para detectar estancamiento
2. **Validar fÃ­sicamente**: Los parÃ¡metros deben estar en rangos razonables
3. **Comparar mÃºltiples runs**: Ejecutar 5-10 trials para evaluar robustez
4. **Visualizar ajuste**: Comparar trayectorias simuladas vs. reales
5. **Analizar residuales**: Verificar que los errores sean aleatorios, no sistemÃ¡ticos

**6. Debugging de OptimizaciÃ³n:**

Si el algoritmo no converge:

```python
# Activar modo verbose para ver progreso detallado
optimizer = DifferentialEvolution(problema, verbose=True)

# Revisar historial de convergencia
history = optimizer.get_convergence_curve()
print(f"Mejora final: {history[0]} â†’ {history[-1]}")

# Verificar que fitness se evalÃºa correctamente
test_solution = [0.036, 0.005, 2.5, 0.004]  # Valores razonables
fitness = problema.fitness_function(test_solution)
print(f"Test fitness: {fitness}")  # Debe ser finito, no 1e10
```

---

## ğŸ”„ Compatibilidad Hacia AtrÃ¡s

El archivo original `example_optimization.py` se mantiene funcional para compatibilidad:

```python
from example_optimization import (
    RandomSearch, DifferentialEvolution, GeneticAlgorithm,
    GreyWolfOptimizer, ArtificialBeeColony, HoneyBadgerAlgorithm
)

# Uso idÃ©ntico al original
problema = LevitadorBenchmark()
algo = DifferentialEvolution(problema, pop_size=30, max_iter=100)
best_sol, best_fit = algo.optimize()
```

### Con Datos Experimentales Reales

```python
problema = LevitadorBenchmark("data/datos_levitador.txt")
```

### Control de Reproducibilidad

```python
# Usar semilla para resultados reproducibles
problema = LevitadorBenchmark(random_seed=42)

# Configurar nivel de ruido para datos sintÃ©ticos
problema = LevitadorBenchmark(noise_level=1e-4, random_seed=42)
```

### IntegraciÃ³n con Algoritmos de OptimizaciÃ³n

#### EvoluciÃ³n Diferencial (SciPy)

```python
from scipy.optimize import differential_evolution
from levitador_benchmark import LevitadorBenchmark

problema = LevitadorBenchmark()

resultado = differential_evolution(
    problema.fitness_function,
    problema.bounds,
    strategy='best1bin',
    maxiter=100,
    popsize=20,
    disp=True
)

print(f"Mejor soluciÃ³n: {resultado.x}")
print(f"Error final: {resultado.fun:.6e}")
```

#### Algoritmo GenÃ©tico (DEAP)

```python
from deap import base, creator, tools, algorithms
from levitador_benchmark import LevitadorBenchmark
import numpy as np

problema = LevitadorBenchmark()

# ConfiguraciÃ³n DEAP
creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
creator.create("Individual", list, fitness=creator.FitnessMin)

toolbox = base.Toolbox()

# Generador de individuos
def create_individual():
    return [np.random.uniform(lb, ub) for lb, ub in problema.bounds]

toolbox.register("individual", tools.initIterate, creator.Individual, create_individual)
toolbox.register("population", tools.initRepeat, list, toolbox.individual)
toolbox.register("evaluate", lambda ind: (problema.fitness_function(ind),))
toolbox.register("mate", tools.cxBlend, alpha=0.5)
toolbox.register("mutate", tools.mutGaussian, mu=0, sigma=0.01, indpb=0.2)
toolbox.register("select", tools.selTournament, tournsize=3)

# Ejecutar
pop = toolbox.population(n=50)
result = algorithms.eaSimple(pop, toolbox, cxpb=0.7, mutpb=0.2, ngen=50, verbose=True)
```

#### Enjambre de PartÃ­culas (PySwarms)

```python
import pyswarms as ps
from levitador_benchmark import LevitadorBenchmark
import numpy as np

problema = LevitadorBenchmark()
lb, ub = problema.get_bounds_array()

# FunciÃ³n wrapper para PySwarms (espera matriz de partÃ­culas)
def fitness_swarm(particles):
    return np.array([problema.fitness_function(p) for p in particles])

# Configurar PSO
options = {'c1': 0.5, 'c2': 0.3, 'w': 0.9}
optimizer = ps.single.GlobalBestPSO(
    n_particles=30,
    dimensions=3,
    options=options,
    bounds=(lb, ub)
)

# Ejecutar
best_cost, best_pos = optimizer.optimize(fitness_swarm, iters=100)
print(f"Mejor posiciÃ³n: {best_pos}")
print(f"Mejor costo: {best_cost:.6e}")
```

---

## ğŸ“Š VisualizaciÃ³n de Resultados

```python
from levitador_benchmark import LevitadorBenchmark

problema = LevitadorBenchmark()
mejor_solucion = [0.0363, 0.0035, 0.0052]

# Generar grÃ¡fica comparativa
problema.visualize_solution(mejor_solucion, save_path="resultado.png")
```


---

## ğŸ“ Estructura del Repositorio

```
levitador-benchmark/
â”œâ”€â”€ README.md                    # Este archivo
â”œâ”€â”€ LICENSE                      # Licencia MIT
â”œâ”€â”€ requirements.txt             # Dependencias del proyecto
â”œâ”€â”€ levitador_benchmark.py       # Clase principal del benchmark
â”œâ”€â”€ example_optimization.py      # Ejemplos de algoritmos
â”œâ”€â”€ tutorial_metaheuristicas.ipynb  # Notebook tutorial interactivo
â”œâ”€â”€ data/
â”‚   â””â”€â”€ datos_levitador.txt      # Datos experimentales reales
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ formato_datos.md         # DescripciÃ³n del formato de datos
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_benchmark.py        # Tests unitarios (pytest)
â””â”€â”€ videos/                      # Videos explicativos
    â”œâ”€â”€ 01_problema_fisico.mp4
    â”œâ”€â”€ 02_funcion_fitness.mp4
    â””â”€â”€ 03_como_optimizar.mp4
```

---

## ğŸ”¬ Detalles FÃ­sicos

### Ecuaciones del Sistema

El modelo dinÃ¡mico se basa en las ecuaciones de **Euler-Lagrange**:

**EcuaciÃ³n MecÃ¡nica (Newton):**
$$m\ddot{y} = \frac{1}{2}\frac{\partial L}{\partial y}i^2 + mg$$

**EcuaciÃ³n ElÃ©ctrica (Kirchhoff):**
$$L(y)\frac{di}{dt} + \frac{\partial L}{\partial y}\dot{y}i + Ri = u$$

### Constantes del Sistema

| Constante | Valor | DescripciÃ³n |
|-----------|-------|-------------|
| $m$ | 0.018 kg | Masa de la esfera |
| $g$ | 9.81 m/sÂ² | AceleraciÃ³n gravitacional |
| $R$ | 2.72 Î© | Resistencia de la bobina |

---

## ğŸ“ˆ Resultados de Referencia

Valores de referencia obtenidos experimentalmente:

| ParÃ¡metro | Valor Estimado |
|-----------|----------------|
| $k_0$ | 0.0363 H |
| $k$ | 0.0035 H |
| $a$ | 0.0052 m |

Los algoritmos bien sintonizados deberÃ­an converger a soluciones cercanas con MSE < 1e-8.

---

## ğŸ”¬ DiseÃ±o de Experimentos (DOE)

El repositorio incluye un DOE estructurado para generar datos experimentales diversos.

### Experimentos Disponibles

| Fase | Experimentos | DescripciÃ³n |
|------|--------------|-------------|
| **1** | E01, E02, E07, E08, E11 | CaracterizaciÃ³n bÃ¡sica (escalones, senoidales) |
| **2** | E03-E06, E09-E10 | CaracterizaciÃ³n extendida (rampas, pulsos) |
| **3** | V01-V06 | ValidaciÃ³n (repeticiones) |
| **4** | E12 | Robustez (PRBS) |

### Ejecutar Experimentos

```bash
# Listar experimentos disponibles
python experimentos_doe.py --listar

# Ejecutar en modo simulaciÃ³n (sin hardware)
python experimentos_doe.py --fase 1 --simular

# Ejecutar experimento especÃ­fico
python experimentos_doe.py --experimento E01

# Ejecutar todos los experimentos
python experimentos_doe.py --todos
```

### DocumentaciÃ³n Completa

Ver [docs/DOE_experimentos.md](docs/DOE_experimentos.md) para:
- DefiniciÃ³n de factores y niveles
- Protocolo experimental
- MÃ©tricas a calcular
- AnÃ¡lisis posterior

---

## ğŸ¤ Contribuciones

Â¡Las contribuciones son bienvenidas! Si usas este benchmark en tu investigaciÃ³n:

1. Reporta tus resultados abriendo un Issue
2. Comparte mejoras al cÃ³digo via Pull Request
3. Cita este trabajo en tus publicaciones

---

## ğŸ“š Citar este Trabajo

```bibtex
@software{levitador_benchmark,
  author = {Santana-RamÃ­rez, JosÃ© de JesÃºs},
  title = {Levitador MagnÃ©tico Benchmark: Problema de OptimizaciÃ³n Real para MetaheurÃ­sticas},
  year = {2024},
  url = {https://github.com/JRavenelco/levitador-benchmark},
  note = {Universidad AutÃ³noma de QuerÃ©taro},
  orcid = {0000-0002-6183-7379}
}
```

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver [LICENSE](LICENSE) para mÃ¡s detalles.

---

## ğŸ“§ Contacto

- **Autor:** JosÃ© de JesÃºs Santana RamÃ­rez
- **ORCID:** [0000-0002-6183-7379](https://orcid.org/0000-0002-6183-7379)
- **InstituciÃ³n:** Doctorado en IngenierÃ­a, Universidad AutÃ³noma de QuerÃ©taro
- **Email:** jesus.santana@uaq.mx

---

## ğŸ§  KAN-PINN: Observador Neuronal con FÃ­sica

### DescripciÃ³n

AdemÃ¡s de la optimizaciÃ³n de parÃ¡metros, este proyecto incluye un **observador de estado basado en KAN-PINN** (Kolmogorov-Arnold Networks + Physics-Informed Neural Networks) para estimar la posiciÃ³n de la esfera sin sensor directo.

### Arquitectura

```
Entradas: [i, L_est, u]
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  KAN Layer 1: 3 â†’ 32        â”‚  B-splines + Residual
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  KAN Layer 2: 32 â†’ 32       â”‚  B-splines + Residual
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  KAN Layer 3: 32 â†’ 1        â”‚  B-splines + Residual
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
Salida: y (posiciÃ³n estimada)
```

### PÃ©rdida FÃ­sica (PINN)

La red se entrena minimizando:

$$\mathcal{L} = \mathcal{L}_{datos} + \lambda \mathcal{L}_{fÃ­sica}$$

Donde la pÃ©rdida fÃ­sica impone la consistencia con el modelo de inductancia:

$$L(y) = k_0 + \frac{k}{1 + y/a}$$

### Resultados del Entrenamiento

| MÃ©trica | Valor |
|---------|-------|
| CorrelaciÃ³n | 0.589 |
| MAE | 2.88 mm |
| Datasets | 5 (~13k muestras) |

### Uso del Observador

```python
from pinn.kan_observador import KANObservador
import torch

# Cargar modelo entrenado
model = KANObservador(hidden=32, depth=2, num_knots=8)
checkpoint = torch.load('pinn/kan_observador_*.pt')
model.load_state_dict(checkpoint['model_state'])
model.eval()

# Inferencia
X = torch.tensor([[i, L_est, u]])  # [corriente, inductancia, voltaje]
y_estimado = model(X)
```

### ValidaciÃ³n con MetaheurÃ­sticos

Los parÃ¡metros $[k_0, k, a]$ identificados por metaheurÃ­sticos pueden usarse para:
1. **Validar** el modelo fÃ­sico del KAN-PINN
2. **Comparar** estimaciÃ³n KAN vs fÃ³rmula analÃ­tica
3. **Mejorar** la pÃ©rdida fÃ­sica con parÃ¡metros mÃ¡s precisos

---

## ğŸ¬ Videos Explicativos

### 1. El Problema FÃ­sico
![Problema FÃ­sico](videos/01_problema_fisico.gif)

### 2. FunciÃ³n de Fitness (MSE)
![FunciÃ³n Fitness](videos/02_funcion_fitness.gif)

### 3. Arquitectura KAN-PINN
![Arquitectura KAN](videos/03_arquitectura_kan.gif)

### 4. Algoritmos MetaheurÃ­sticos
![MetaheurÃ­sticos](videos/04_metaheuristicos.gif)

*Animaciones generadas con Manim*

---


---

## ğŸ—ºï¸ Mapa Mental: Arquitectura del Pipeline

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                  LEVITADOR MAGNÃ‰TICO - PIPELINE DE DOS FASES               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ENTRADA: Datos Experimentales (t, y, i, u)                                â”‚
â”‚  â–ª datos_levitador.txt (identificaciÃ³n parÃ¡metros)                         â”‚
â”‚  â–ª sesiones_kan_pinn/*.txt (entrenamiento KAN-PINN)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ                       FASE 1: IDENTIFICACIÃ“N DE PARÃMETROS                â”ƒ
â”ƒ                                                                            â”ƒ
â”ƒ  Objetivo: Identificar Î¸ = [K0, A, R0, Î±]                                 â”ƒ
â”ƒ                                                                            â”ƒ
â”ƒ  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”ƒ
â”ƒ  â”‚  MODELOS FÃSICOS                                                     â”‚ â”ƒ
â”ƒ  â”‚                                                                      â”‚ â”ƒ
â”ƒ  â”‚  â–ª Inductancia:  L(y) = K0 / (1 + y/A)                              â”‚ â”ƒ
â”ƒ  â”‚                  âˆ‚L/âˆ‚y = -K0 / (AÂ·(1 + y/A)Â²)                       â”‚ â”ƒ
â”ƒ  â”‚                                                                      â”‚ â”ƒ
â”ƒ  â”‚  â–ª Resistencia (sin sensor de temperatura):                         â”‚ â”ƒ
â”ƒ  â”‚                  R(t) â‰ˆ R0Â·(1 + Î±Â·Î”T(t))                            â”‚ â”ƒ
â”ƒ  â”‚                  Î”T(t) âˆ âˆ« iÂ²(t) dt (Joule heating)                 â”‚ â”ƒ
â”ƒ  â”‚                                                                      â”‚ â”ƒ
â”ƒ  â”‚  â–ª EstimaciÃ³n vÃ­a Kirchhoff:                                        â”‚ â”ƒ
â”ƒ  â”‚                  R_est(t) = (u(t) - dÏ†Ì‚/dt) / i(t)                   â”‚ â”ƒ
â”ƒ  â”‚                  donde Ï†Ì‚ = L(y)Â·i                                   â”‚ â”ƒ
â”ƒ  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”ƒ
â”ƒ                                                                            â”ƒ
â”ƒ  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”ƒ
â”ƒ  â”‚  ECUACIONES DINÃMICAS                                                â”‚ â”ƒ
â”ƒ  â”‚                                                                      â”‚ â”ƒ
â”ƒ  â”‚  â–ª MecÃ¡nica:    mÂ·Ã¿ = (1/2)Â·(âˆ‚L/âˆ‚y)Â·iÂ² + mÂ·g                        â”‚ â”ƒ
â”ƒ  â”‚  â–ª ElÃ©ctrica:   L(y)Â·(di/dt) + (âˆ‚L/âˆ‚y)Â·áºÂ·i + R(t)Â·i = u            â”‚ â”ƒ
â”ƒ  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”ƒ
â”ƒ                                                                            â”ƒ
â”ƒ  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”ƒ
â”ƒ  â”‚  METAHEURÃSTICOS (ParameterBenchmark)                               â”‚ â”ƒ
â”ƒ  â”‚                                                                      â”‚ â”ƒ
â”ƒ  â”‚  â–ª Differential Evolution (DE)     â–ª Honey Badger (HBA)            â”‚ â”ƒ
â”ƒ  â”‚  â–ª Grey Wolf Optimizer (GWO)       â–ª Shrimp Optimizer (SOA)        â”‚ â”ƒ
â”ƒ  â”‚  â–ª Artificial Bee Colony (ABC)     â–ª Tianji Optimizer              â”‚ â”ƒ
â”ƒ  â”‚  â–ª Genetic Algorithm (GA)          â–ª Random Search                 â”‚ â”ƒ
â”ƒ  â”‚                                                                      â”‚ â”ƒ
â”ƒ  â”‚  Fitness: MSE(y_simulada(Î¸), y_real)                                â”‚ â”ƒ
â”ƒ  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”ƒ
â”ƒ                                                                            â”ƒ
â”ƒ  SALIDA: parametros_optimos.json â†’ [K0*, A*, R0*, Î±*]                     â”ƒ
â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›
                                     â”‚
                                     â–¼
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ                   FASE 2: ENTRENAMIENTO KAN-PINN (Sensorless)             â”ƒ
â”ƒ                                                                            â”ƒ
â”ƒ  Objetivo: Entrenar observador neuronal para estimar posiciÃ³n sin sensor  â”ƒ
â”ƒ                                                                            â”ƒ
â”ƒ  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”ƒ
â”ƒ  â”‚  ETAPA 1: OBSERVADOR DE FLUJO (FluxObserver)                        â”‚ â”ƒ
â”ƒ  â”‚                                                                      â”‚ â”ƒ
â”ƒ  â”‚    Entrada: (u, i)                                                  â”‚ â”ƒ
â”ƒ  â”‚              â”‚                                                       â”‚ â”ƒ
â”ƒ  â”‚              â–¼                                                       â”‚ â”ƒ
â”ƒ  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚ â”ƒ
â”ƒ  â”‚         â”‚ HiPPO-8 â”‚  (captura temporal online)                      â”‚ â”ƒ
â”ƒ  â”‚         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                                 â”‚ â”ƒ
â”ƒ  â”‚              â”‚                                                       â”‚ â”ƒ
â”ƒ  â”‚              â–¼                                                       â”‚ â”ƒ
â”ƒ  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚ â”ƒ
â”ƒ  â”‚         â”‚  KAN    â”‚  (B-splines + residual)                        â”‚ â”ƒ
â”ƒ  â”‚         â”‚ 3 â†’ 32  â”‚                                                 â”‚ â”ƒ
â”ƒ  â”‚         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                                 â”‚ â”ƒ
â”ƒ  â”‚              â”‚                                                       â”‚ â”ƒ
â”ƒ  â”‚              â–¼                                                       â”‚ â”ƒ
â”ƒ  â”‚    Salida: Ï†Ì‚ (flujo estimado)                                      â”‚ â”ƒ
â”ƒ  â”‚                                                                      â”‚ â”ƒ
â”ƒ  â”‚    PÃ©rdida: L = w_dataÂ·MSE(Ï†Ì‚, Ï†) + w_kirchÂ·|u - RÂ·i - dÏ†Ì‚/dt|Â²     â”‚ â”ƒ
â”ƒ  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”ƒ
â”ƒ                                                                            â”ƒ
â”ƒ  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”ƒ
â”ƒ  â”‚  ETAPA 2: PREDICTOR DE POSICIÃ“N (PositionPredictor)                â”‚ â”ƒ
â”ƒ  â”‚                                                                      â”‚ â”ƒ
â”ƒ  â”‚    Entrada: (u, i, Ï†Ì‚)  â† flujo de Etapa 1                          â”‚ â”ƒ
â”ƒ  â”‚              â”‚                                                       â”‚ â”ƒ
â”ƒ  â”‚              â–¼                                                       â”‚ â”ƒ
â”ƒ  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚ â”ƒ
â”ƒ  â”‚         â”‚  KAN    â”‚  (sin HiPPO, usa Ï†Ì‚ directamente)               â”‚ â”ƒ
â”ƒ  â”‚         â”‚ 3 â†’ 32  â”‚                                                 â”‚ â”ƒ
â”ƒ  â”‚         â”‚  â†’ 32   â”‚                                                 â”‚ â”ƒ
â”ƒ  â”‚         â”‚  â†’ 1    â”‚                                                 â”‚ â”ƒ
â”ƒ  â”‚         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                                 â”‚ â”ƒ
â”ƒ  â”‚              â”‚                                                       â”‚ â”ƒ
â”ƒ  â”‚              â–¼                                                       â”‚ â”ƒ
â”ƒ  â”‚    Salida: Å· (posiciÃ³n estimada)                                   â”‚ â”ƒ
â”ƒ  â”‚                                                                      â”‚ â”ƒ
â”ƒ  â”‚    PÃ©rdida PINN (usando K0*, A* de Fase 1):                        â”‚ â”ƒ
â”ƒ  â”‚         L = w_dataÂ·MSE(Å·, y) + w_pinnÂ·|Ï†Ì‚ - L*(Å·)Â·i|Â²               â”‚ â”ƒ
â”ƒ  â”‚                                                                      â”‚ â”ƒ
â”ƒ  â”‚    Curriculum Learning: w_pinn va de 0.1 â†’ 5.0                     â”‚ â”ƒ
â”ƒ  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”ƒ
â”ƒ                                                                            â”ƒ
â”ƒ  SALIDA: Modelos entrenados (.pt) + predicciones + mÃ©tricas               â”ƒ
â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RESULTADO FINAL:                                                           â”‚
â”‚  â–ª ParÃ¡metros fÃ­sicos identificados: [K0*, A*, R0*, Î±*]                    â”‚
â”‚  â–ª Observador de posiciÃ³n sensorless entrenado                             â”‚
â”‚  â–ª EstimaciÃ³n de R(t) sin sensor de temperatura                            â”‚
â”‚  â–ª Visualizaciones y mÃ©tricas de convergencia                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

CARACTERÃSTICAS CLAVE:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â–ª NO hay sensor de temperatura â†’ R(t) se estima vÃ­a Kirchhoff
â–ª NO hay data leakage â†’ Etapa 2 usa Ï†Ì‚ de Etapa 1 (no y_sensor)
â–ª Restricciones fÃ­sicas garantizadas: K0 > 0, A > 0, R0 > 0
â–ª Submuestreo configurable para optimizaciÃ³n rÃ¡pida
â–ª PÃ©rdidas fÃ­sicas: Kirchhoff (Etapa 1) + PINN Euler-Lagrange (Etapa 2)
â–ª 8 algoritmos metaheurÃ­sticos disponibles
â–ª Framework modular y extensible
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---
