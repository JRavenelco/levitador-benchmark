{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83e\uddf2 Levitador Magn\u00e9tico Benchmark Tutorial\n",
    "\n",
    "## Comprehensive Guide with Visualizations\n",
    "\n",
    "**Author:** Jos\u00e9 de Jes\u00fas Santana Ram\u00edrez  \n",
    "**Institution:** Universidad Aut\u00f3noma de Quer\u00e9taro  \n",
    "**Version:** 1.0  \n",
    "**Date:** December 2024\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udcda Table of Contents\n",
    "\n",
    "1. [Introduction to the Physical System](#section-1)\n",
    "2. [Understanding the Benchmark](#section-2)\n",
    "3. [Loading and Visualizing Data](#section-3)\n",
    "4. [Parameter Space Exploration](#section-4)\n",
    "5. [Fitness Landscape Visualization](#section-5)\n",
    "6. [Comparing Different Solutions](#section-6)\n",
    "7. [Running Optimization Examples](#section-7)\n",
    "8. [Analyzing Results](#section-8)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section-1'></a>\n",
    "## 1. \ud83c\udfaf Introduction to the Physical System\n",
    "\n",
    "### What is a Magnetic Levitator?\n",
    "\n",
    "The magnetic levitator is a physical system where a steel sphere is suspended by an electromagnet. The system is inherently **unstable** and requires active control to maintain the sphere at a desired position.\n",
    "\n",
    "### The Mathematical Model\n",
    "\n",
    "The inductance of the electromagnet varies with the distance to the sphere:\n",
    "\n",
    "$$L(y) = k_0 + \\frac{k}{1 + y/a}$$\n",
    "\n",
    "Where:\n",
    "- $k_0$ : Base inductance [H]\n",
    "- $k$ : Inductance coefficient [H]\n",
    "- $a$ : Geometric parameter [m]\n",
    "- $y$ : Sphere position [m]\n",
    "\n",
    "### The Optimization Problem\n",
    "\n",
    "**Goal:** Find the parameters $[k_0, k, a]$ that minimize the Mean Squared Error (MSE) between:\n",
    "- Simulated trajectory from the digital twin model\n",
    "- Real experimental data from the physical system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from levitador_benchmark import LevitadorBenchmark\n",
    "import warnings\n",
    "# Filter specific warnings that are expected in numerical optimization\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib')\n",
    "\n",
    "# Configure plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"\u2713 Libraries imported successfully\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section-2'></a>\n",
    "## 2. \ud83d\udd0d Understanding the Benchmark\n",
    "\n",
    "The `LevitadorBenchmark` class provides a standardized interface for testing optimization algorithms on a real-world problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the benchmark instance\n",
    "# Using real experimental data if available, otherwise synthetic data\n",
    "try:\n",
    "    benchmark = LevitadorBenchmark(\"data/datos_levitador.txt\", random_seed=42)\n",
    "    print(\"\u2713 Using real experimental data\")\n",
    "except:\n",
    "    benchmark = LevitadorBenchmark(random_seed=42)\n",
    "    print(\"\u2713 Using synthetic data\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BENCHMARK PROPERTIES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Problem dimension: {benchmark.dim}\")\n",
    "print(f\"Number of data points: {len(benchmark.t_real)}\")\n",
    "print(f\"Time span: {benchmark.t_real[0]:.3f} - {benchmark.t_real[-1]:.3f} seconds\")\n",
    "print(f\"\\nParameter bounds:\")\n",
    "for i, (name, (lb, ub)) in enumerate(zip(benchmark.variable_names, benchmark.bounds)):\n",
    "    print(f\"  {name:3s}: [{lb:.4f}, {ub:.4f}]\")\n",
    "print(f\"\\nReference solution: {benchmark.reference_solution}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section-3'></a>\n",
    "## 3. \ud83d\udcca Loading and Visualizing Data\n",
    "\n",
    "Let's visualize the experimental data that serves as ground truth for our optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the experimental data\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "fig.suptitle('Experimental Data from Magnetic Levitator', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Position vs Time\n",
    "axes[0, 0].plot(benchmark.t_real * 1000, benchmark.y_real * 1000, 'b-', linewidth=1.5)\n",
    "axes[0, 0].set_xlabel('Time [ms]', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Position [mm]', fontsize=11)\n",
    "axes[0, 0].set_title('Sphere Position vs Time', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Current vs Time\n",
    "axes[0, 1].plot(benchmark.t_real * 1000, benchmark.i_real, 'r-', linewidth=1.5)\n",
    "axes[0, 1].set_xlabel('Time [ms]', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Current [A]', fontsize=11)\n",
    "axes[0, 1].set_title('Electromagnet Current vs Time', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Voltage vs Time\n",
    "axes[1, 0].plot(benchmark.t_real * 1000, benchmark.u_real, 'g-', linewidth=1.5)\n",
    "axes[1, 0].set_xlabel('Time [ms]', fontsize=11)\n",
    "axes[1, 0].set_ylabel('Voltage [V]', fontsize=11)\n",
    "axes[1, 0].set_title('Input Voltage vs Time', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Phase portrait: Position vs Current\n",
    "axes[1, 1].scatter(benchmark.y_real * 1000, benchmark.i_real, c=benchmark.t_real, \n",
    "                   cmap='viridis', s=10, alpha=0.6)\n",
    "axes[1, 1].set_xlabel('Position [mm]', fontsize=11)\n",
    "axes[1, 1].set_ylabel('Current [A]', fontsize=11)\n",
    "axes[1, 1].set_title('Phase Portrait: Position vs Current', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "cbar = plt.colorbar(axes[1, 1].collections[0], ax=axes[1, 1])\n",
    "cbar.set_label('Time [s]', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcca Data Statistics:\")\n",
    "print(f\"Position range: [{benchmark.y_real.min()*1000:.2f}, {benchmark.y_real.max()*1000:.2f}] mm\")\n",
    "print(f\"Current range: [{benchmark.i_real.min():.2f}, {benchmark.i_real.max():.2f}] A\")\n",
    "print(f\"Voltage range: [{benchmark.u_real.min():.2f}, {benchmark.u_real.max():.2f}] V\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section-4'></a>\n",
    "## 4. \ud83d\udd2c Parameter Space Exploration\n",
    "\n",
    "Let's explore how different parameter values affect the fitness function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate random solutions in the parameter space\n",
    "print(\"Evaluating random solutions in parameter space...\")\n",
    "n_samples = 200\n",
    "solutions = []\n",
    "errors = []\n",
    "\n",
    "np.random.seed(42)\n",
    "for i in range(n_samples):\n",
    "    # Generate random solution within bounds\n",
    "    solution = [np.random.uniform(lb, ub) for lb, ub in benchmark.bounds]\n",
    "    error = benchmark.fitness_function(solution)\n",
    "    solutions.append(solution)\n",
    "    errors.append(error)\n",
    "    \n",
    "    if (i + 1) % 50 == 0:\n",
    "        print(f\"  Evaluated {i+1}/{n_samples} solutions\")\n",
    "\n",
    "solutions = np.array(solutions)\n",
    "errors = np.array(errors)\n",
    "\n",
    "# Filter out extreme errors for better visualization\n",
    "valid_mask = errors < np.percentile(errors, 95)\n",
    "solutions_filtered = solutions[valid_mask]\n",
    "errors_filtered = errors[valid_mask]\n",
    "\n",
    "print(f\"\\n\u2713 Completed {n_samples} evaluations\")\n",
    "print(f\"Best error found: {errors.min():.6e}\")\n",
    "print(f\"Worst error found: {errors.max():.6e}\")\n",
    "print(f\"Mean error: {errors.mean():.6e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize parameter space exploration\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "fig.suptitle('Parameter Space Exploration', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Create 3D scatter plot\n",
    "ax1 = fig.add_subplot(2, 3, 1, projection='3d')\n",
    "scatter = ax1.scatter(solutions_filtered[:, 0], solutions_filtered[:, 1], \n",
    "                      solutions_filtered[:, 2], c=np.log10(errors_filtered), \n",
    "                      cmap='jet', s=50, alpha=0.6)\n",
    "ax1.set_xlabel('k0 [H]', fontsize=10)\n",
    "ax1.set_ylabel('k [H]', fontsize=10)\n",
    "ax1.set_zlabel('a [m]', fontsize=10)\n",
    "ax1.set_title('3D Parameter Space\\n(color = log10(error))', fontsize=11, fontweight='bold')\n",
    "plt.colorbar(scatter, ax=ax1, label='log10(MSE)', shrink=0.7)\n",
    "\n",
    "# 2D projections with error as color\n",
    "param_names = ['k0 [H]', 'k [H]', 'a [m]']\n",
    "projections = [(0, 1), (0, 2), (1, 2)]\n",
    "\n",
    "for idx, (i, j) in enumerate(projections, start=2):\n",
    "    ax = fig.add_subplot(2, 3, idx)\n",
    "    scatter = ax.scatter(solutions_filtered[:, i], solutions_filtered[:, j], \n",
    "                        c=np.log10(errors_filtered), cmap='jet', s=30, alpha=0.6)\n",
    "    ax.set_xlabel(param_names[i], fontsize=10)\n",
    "    ax.set_ylabel(param_names[j], fontsize=10)\n",
    "    ax.set_title(f'{param_names[i]} vs {param_names[j]}', fontsize=11, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.colorbar(scatter, ax=ax, label='log10(MSE)')\n",
    "\n",
    "# Distribution of errors\n",
    "ax = fig.add_subplot(2, 3, 5)\n",
    "ax.hist(np.log10(errors_filtered), bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "ax.set_xlabel('log10(MSE)', fontsize=11)\n",
    "ax.set_ylabel('Frequency', fontsize=11)\n",
    "ax.set_title('Distribution of Fitness Errors', fontsize=11, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axvline(np.log10(errors.min()), color='red', linestyle='--', linewidth=2, label='Best')\n",
    "ax.legend()\n",
    "\n",
    "# Box plots for parameter distributions\n",
    "ax = fig.add_subplot(2, 3, 6)\n",
    "box_data = [solutions_filtered[:, i] for i in range(3)]\n",
    "bp = ax.boxplot(box_data, labels=['k0', 'k', 'a'], patch_artist=True)\n",
    "for patch, color in zip(bp['boxes'], ['lightblue', 'lightgreen', 'lightcoral']):\n",
    "    patch.set_facecolor(color)\n",
    "ax.set_ylabel('Parameter Value', fontsize=11)\n",
    "ax.set_title('Parameter Value Distributions', fontsize=11, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section-5'></a>\n",
    "## 5. \ud83d\uddfa\ufe0f Fitness Landscape Visualization\n",
    "\n",
    "Let's visualize 2D slices of the fitness landscape to understand the optimization challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2D fitness landscape slices\n",
    "print(\"Creating fitness landscape visualizations...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "# Use reference solution as center point\n",
    "ref_sol = benchmark.reference_solution\n",
    "\n",
    "# Define grid resolution\n",
    "n_points = 30\n",
    "\n",
    "# Create landscapes for each pair of parameters\n",
    "landscapes = []\n",
    "\n",
    "# k0 vs k (fixing a at reference)\n",
    "k0_range = np.linspace(benchmark.bounds[0][0], benchmark.bounds[0][1], n_points)\n",
    "k_range = np.linspace(benchmark.bounds[1][0], benchmark.bounds[1][1], n_points)\n",
    "K0, K = np.meshgrid(k0_range, k_range)\n",
    "Z1 = np.zeros_like(K0)\n",
    "\n",
    "print(\"  Computing k0-k landscape...\")\n",
    "for i in range(n_points):\n",
    "    for j in range(n_points):\n",
    "        Z1[i, j] = benchmark.fitness_function([K0[i, j], K[i, j], ref_sol[2]])\n",
    "landscapes.append((K0, K, Z1, 'k0', 'k'))\n",
    "\n",
    "# k0 vs a (fixing k at reference)\n",
    "a_range = np.linspace(benchmark.bounds[2][0], benchmark.bounds[2][1], n_points)\n",
    "K0_2, A = np.meshgrid(k0_range, a_range)\n",
    "Z2 = np.zeros_like(K0_2)\n",
    "\n",
    "print(\"  Computing k0-a landscape...\")\n",
    "for i in range(n_points):\n",
    "    for j in range(n_points):\n",
    "        Z2[i, j] = benchmark.fitness_function([K0_2[i, j], ref_sol[1], A[i, j]])\n",
    "landscapes.append((K0_2, A, Z2, 'k0', 'a'))\n",
    "\n",
    "# k vs a (fixing k0 at reference)\n",
    "K_2, A_2 = np.meshgrid(k_range, a_range)\n",
    "Z3 = np.zeros_like(K_2)\n",
    "\n",
    "print(\"  Computing k-a landscape...\")\n",
    "for i in range(n_points):\n",
    "    for j in range(n_points):\n",
    "        Z3[i, j] = benchmark.fitness_function([ref_sol[0], K_2[i, j], A_2[i, j]])\n",
    "landscapes.append((K_2, A_2, Z3, 'k', 'a'))\n",
    "\n",
    "print(\"\u2713 Landscapes computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fitness landscapes\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "fig.suptitle('Fitness Landscape Slices (fixing one parameter at reference value)', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "# 3D surface plots\n",
    "for idx, (X, Y, Z, xlabel, ylabel) in enumerate(landscapes):\n",
    "    ax = fig.add_subplot(2, 3, idx + 1, projection='3d')\n",
    "    \n",
    "    # Clip extreme values for better visualization\n",
    "    Z_clipped = np.clip(Z, 0, np.percentile(Z, 95))\n",
    "    \n",
    "    surf = ax.plot_surface(X, Y, np.log10(Z_clipped + 1e-10), cmap='viridis', \n",
    "                           alpha=0.9, edgecolor='none')\n",
    "    ax.set_xlabel(f'{xlabel} [H]' if xlabel != 'a' else f'{xlabel} [m]', fontsize=10)\n",
    "    ax.set_ylabel(f'{ylabel} [H]' if ylabel != 'a' else f'{ylabel} [m]', fontsize=10)\n",
    "    ax.set_zlabel('log10(MSE)', fontsize=10)\n",
    "    ax.set_title(f'{xlabel} vs {ylabel}', fontsize=11, fontweight='bold')\n",
    "    fig.colorbar(surf, ax=ax, shrink=0.5, label='log10(MSE)')\n",
    "\n",
    "# Contour plots\n",
    "for idx, (X, Y, Z, xlabel, ylabel) in enumerate(landscapes):\n",
    "    ax = fig.add_subplot(2, 3, idx + 4)\n",
    "    \n",
    "    Z_clipped = np.clip(Z, 0, np.percentile(Z, 95))\n",
    "    \n",
    "    contour = ax.contourf(X, Y, np.log10(Z_clipped + 1e-10), levels=20, cmap='viridis')\n",
    "    ax.contour(X, Y, np.log10(Z_clipped + 1e-10), levels=20, colors='black', \n",
    "               alpha=0.3, linewidths=0.5)\n",
    "    \n",
    "    # Mark reference solution\n",
    "    ref_idx_map = {'k0': 0, 'k': 1, 'a': 2}\n",
    "    ref_x = ref_sol[ref_idx_map[xlabel]]\n",
    "    ref_y = ref_sol[ref_idx_map[ylabel]]\n",
    "    ax.plot(ref_x, ref_y, 'r*', markersize=15, label='Reference', markeredgecolor='white', markeredgewidth=1)\n",
    "    \n",
    "    ax.set_xlabel(f'{xlabel} [H]' if xlabel != 'a' else f'{xlabel} [m]', fontsize=10)\n",
    "    ax.set_ylabel(f'{ylabel} [H]' if ylabel != 'a' else f'{ylabel} [m]', fontsize=10)\n",
    "    ax.set_title(f'Contour: {xlabel} vs {ylabel}', fontsize=11, fontweight='bold')\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "    fig.colorbar(contour, ax=ax, label='log10(MSE)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udca1 Observation:\")\n",
    "print(\"The fitness landscape shows the complexity of this optimization problem.\")\n",
    "print(\"Notice the valleys and ridges that make this a challenging problem for algorithms.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section-6'></a>\n",
    "## 6. \ud83d\udd04 Comparing Different Solutions\n",
    "\n",
    "Let's compare how different parameter sets perform by visualizing their simulation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different solutions to compare\n",
    "solutions_to_compare = {\n",
    "    'Reference': benchmark.reference_solution,\n",
    "    'Random 1': [np.random.uniform(lb, ub) for lb, ub in benchmark.bounds],\n",
    "    'Random 2': [np.random.uniform(lb, ub) for lb, ub in benchmark.bounds],\n",
    "    'Upper bounds': [ub for lb, ub in benchmark.bounds],\n",
    "    'Lower bounds': [lb for lb, ub in benchmark.bounds],\n",
    "    'Midpoint': [(lb + ub) / 2 for lb, ub in benchmark.bounds]\n",
    "}\n",
    "\n",
    "# Evaluate each solution\n",
    "print(\"Comparing different solutions:\\n\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Solution Name':<20} {'k0':>10} {'k':>10} {'a':>10} {'MSE':>15}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "solution_errors = {}\n",
    "for name, sol in solutions_to_compare.items():\n",
    "    error = benchmark.fitness_function(sol)\n",
    "    solution_errors[name] = error\n",
    "    print(f\"{name:<20} {sol[0]:>10.5f} {sol[1]:>10.5f} {sol[2]:>10.5f} {error:>15.6e}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison of solutions\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "fig.suptitle('Comparison of Different Parameter Solutions', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot ground truth in all subplots\n",
    "for idx, (name, sol) in enumerate(list(solutions_to_compare.items())[:6]):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    \n",
    "    # Plot experimental data\n",
    "    ax.plot(benchmark.t_real * 1000, benchmark.y_real * 1000, 'b-', \n",
    "            linewidth=2, label='Experimental', alpha=0.7)\n",
    "    \n",
    "    # Simulate with these parameters\n",
    "    k0, k, a = sol\n",
    "    y0 = benchmark.y_real[0]\n",
    "    try:\n",
    "        solution = odeint(benchmark._modelo_dinamico, [y0, 0, 0], \n",
    "                         benchmark.t_real, args=(k0, k, a))\n",
    "        y_sim = solution[:, 0]\n",
    "        \n",
    "        ax.plot(benchmark.t_real * 1000, y_sim * 1000, 'r--', \n",
    "                linewidth=2, label='Simulation', alpha=0.7)\n",
    "        \n",
    "        error = solution_errors[name]\n",
    "        ax.set_title(f'{name}\\nMSE: {error:.3e}', fontsize=11, fontweight='bold')\n",
    "    except:\n",
    "        ax.set_title(f'{name}\\n(Simulation failed)', fontsize=11, fontweight='bold', color='red')\n",
    "    \n",
    "    ax.set_xlabel('Time [ms]', fontsize=10)\n",
    "    ax.set_ylabel('Position [mm]', fontsize=10)\n",
    "    ax.legend(loc='best', fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Bar plot of errors\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "names = list(solution_errors.keys())\n",
    "errors_list = [solution_errors[name] for name in names]\n",
    "\n",
    "# Use log scale for better visualization\n",
    "colors = ['green' if name == 'Reference' else 'steelblue' for name in names]\n",
    "bars = ax.bar(names, np.log10(np.array(errors_list) + 1e-12), color=colors, edgecolor='black', alpha=0.7)\n",
    "ax.set_ylabel('log10(MSE)', fontsize=12)\n",
    "ax.set_title('Comparison of Solution Quality (lower is better)', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, error) in enumerate(zip(bars, errors_list)):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{error:.2e}',\n",
    "            ha='center', va='bottom', fontsize=9, rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section-7'></a>\n",
    "## 7. \ud83d\ude80 Running Optimization Examples\n",
    "\n",
    "Now let's run some optimization algorithms on the benchmark and visualize their convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Random Search (Baseline)\n",
    "print(\"Running Random Search...\")\n",
    "\n",
    "n_iterations = 100\n",
    "best_error = float('inf')\n",
    "best_solution = None\n",
    "error_history_random = []\n",
    "\n",
    "np.random.seed(42)\n",
    "for i in range(n_iterations):\n",
    "    solution = [np.random.uniform(lb, ub) for lb, ub in benchmark.bounds]\n",
    "    error = benchmark.fitness_function(solution)\n",
    "    \n",
    "    if error < best_error:\n",
    "        best_error = error\n",
    "        best_solution = solution\n",
    "    \n",
    "    error_history_random.append(best_error)\n",
    "\n",
    "print(f\"\\n\u2713 Random Search completed\")\n",
    "print(f\"Best solution: [{best_solution[0]:.5f}, {best_solution[1]:.5f}, {best_solution[2]:.5f}]\")\n",
    "print(f\"Best error: {best_error:.6e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Differential Evolution (SciPy)\n",
    "print(\"Running Differential Evolution...\")\n",
    "\n",
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "# Track convergence\n",
    "error_history_de = []\n",
    "\n",
    "def callback_de(xk, convergence):\n",
    "    error = benchmark.fitness_function(xk)\n",
    "    error_history_de.append(error)\n",
    "\n",
    "result = differential_evolution(\n",
    "    benchmark.fitness_function,\n",
    "    benchmark.bounds,\n",
    "    strategy='best1bin',\n",
    "    maxiter=50,\n",
    "    popsize=15,\n",
    "    seed=42,\n",
    "    callback=callback_de,\n",
    "    disp=False\n",
    ")\n",
    "\n",
    "print(f\"\\n\u2713 Differential Evolution completed\")\n",
    "print(f\"Best solution: [{result.x[0]:.5f}, {result.x[1]:.5f}, {result.x[2]:.5f}]\")\n",
    "print(f\"Best error: {result.fun:.6e}\")\n",
    "print(f\"Evaluations: {result.nfev}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize convergence comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.suptitle('Optimization Algorithm Convergence Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Linear scale\n",
    "axes[0].plot(error_history_random, 'b-', linewidth=2, label='Random Search', alpha=0.7)\n",
    "axes[0].plot(error_history_de, 'r-', linewidth=2, label='Differential Evolution', alpha=0.7)\n",
    "axes[0].axhline(y=benchmark.fitness_function(benchmark.reference_solution), \n",
    "                color='g', linestyle='--', linewidth=2, label='Reference Solution', alpha=0.7)\n",
    "axes[0].set_xlabel('Iteration', fontsize=12)\n",
    "axes[0].set_ylabel('Best MSE', fontsize=12)\n",
    "axes[0].set_title('Linear Scale', fontsize=12, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Log scale\n",
    "axes[1].semilogy(error_history_random, 'b-', linewidth=2, label='Random Search', alpha=0.7)\n",
    "axes[1].semilogy(error_history_de, 'r-', linewidth=2, label='Differential Evolution', alpha=0.7)\n",
    "axes[1].axhline(y=benchmark.fitness_function(benchmark.reference_solution), \n",
    "                color='g', linestyle='--', linewidth=2, label='Reference Solution', alpha=0.7)\n",
    "axes[1].set_xlabel('Iteration', fontsize=12)\n",
    "axes[1].set_ylabel('Best MSE (log scale)', fontsize=12)\n",
    "axes[1].set_title('Logarithmic Scale', fontsize=12, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3, which='both')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcca Performance Summary:\")\n",
    "print(f\"Random Search - Final Error: {error_history_random[-1]:.6e}\")\n",
    "print(f\"Differential Evolution - Final Error: {error_history_de[-1]:.6e}\")\n",
    "improvement = (error_history_random[-1] - error_history_de[-1]) / error_history_random[-1] * 100\n",
    "print(f\"\\nDE improvement over Random Search: {improvement:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section-8'></a>\n",
    "## 8. \ud83d\udcc8 Analyzing Results\n",
    "\n",
    "Let's analyze the best solution found and compare it visually with the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use benchmark's built-in visualization\n",
    "print(\"Visualizing the best solution from Differential Evolution:\")\n",
    "benchmark.visualize_solution(result.x)\n",
    "\n",
    "print(\"\\nVisualizing the reference solution:\")\n",
    "benchmark.visualize_solution(benchmark.reference_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed comparison: DE solution vs Reference\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Detailed Analysis: Best Found Solution vs Reference', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Simulate both solutions\n",
    "k0_de, k_de, a_de = result.x\n",
    "k0_ref, k_ref, a_ref = benchmark.reference_solution\n",
    "y0 = benchmark.y_real[0]\n",
    "\n",
    "sol_de = odeint(benchmark._modelo_dinamico, [y0, 0, 0], benchmark.t_real, args=(k0_de, k_de, a_de))\n",
    "sol_ref = odeint(benchmark._modelo_dinamico, [y0, 0, 0], benchmark.t_real, args=(k0_ref, k_ref, a_ref))\n",
    "\n",
    "y_sim_de = sol_de[:, 0]\n",
    "y_sim_ref = sol_ref[:, 0]\n",
    "\n",
    "# Position comparison\n",
    "axes[0, 0].plot(benchmark.t_real * 1000, benchmark.y_real * 1000, 'k-', \n",
    "                linewidth=2, label='Experimental', alpha=0.8)\n",
    "axes[0, 0].plot(benchmark.t_real * 1000, y_sim_de * 1000, 'r--', \n",
    "                linewidth=2, label='DE Solution', alpha=0.7)\n",
    "axes[0, 0].plot(benchmark.t_real * 1000, y_sim_ref * 1000, 'g:', \n",
    "                linewidth=2, label='Reference', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Time [ms]', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Position [mm]', fontsize=11)\n",
    "axes[0, 0].set_title('Position Trajectories', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].legend(fontsize=10)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Error over time for DE solution\n",
    "error_de = (benchmark.y_real - y_sim_de) * 1000  # in mm\n",
    "error_ref = (benchmark.y_real - y_sim_ref) * 1000\n",
    "\n",
    "axes[0, 1].plot(benchmark.t_real * 1000, error_de, 'r-', linewidth=1.5, label='DE Error', alpha=0.7)\n",
    "axes[0, 1].plot(benchmark.t_real * 1000, error_ref, 'g-', linewidth=1.5, label='Reference Error', alpha=0.7)\n",
    "axes[0, 1].axhline(y=0, color='k', linestyle='--', linewidth=1, alpha=0.5)\n",
    "axes[0, 1].set_xlabel('Time [ms]', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Error [mm]', fontsize=11)\n",
    "axes[0, 1].set_title('Tracking Error Over Time', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].legend(fontsize=10)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Parameter comparison bar chart\n",
    "param_names = ['k0', 'k', 'a']\n",
    "x_pos = np.arange(len(param_names))\n",
    "width = 0.35\n",
    "\n",
    "axes[1, 0].bar(x_pos - width/2, result.x, width, label='DE Solution', color='red', alpha=0.7)\n",
    "axes[1, 0].bar(x_pos + width/2, benchmark.reference_solution, width, label='Reference', color='green', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Parameters', fontsize=11)\n",
    "axes[1, 0].set_ylabel('Value', fontsize=11)\n",
    "axes[1, 0].set_title('Parameter Values Comparison', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xticks(x_pos)\n",
    "axes[1, 0].set_xticklabels(param_names)\n",
    "axes[1, 0].legend(fontsize=10)\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Error statistics\n",
    "stats_data = [\n",
    "    ['Metric', 'DE Solution', 'Reference'],\n",
    "    ['MSE', f'{result.fun:.6e}', f'{benchmark.fitness_function(benchmark.reference_solution):.6e}'],\n",
    "    ['MAE [mm]', f'{np.mean(np.abs(error_de)):.4f}', f'{np.mean(np.abs(error_ref)):.4f}'],\n",
    "    ['Max Error [mm]', f'{np.max(np.abs(error_de)):.4f}', f'{np.max(np.abs(error_ref)):.4f}'],\n",
    "    ['Std Error [mm]', f'{np.std(error_de):.4f}', f'{np.std(error_ref):.4f}']\n",
    "]\n",
    "\n",
    "axes[1, 1].axis('tight')\n",
    "axes[1, 1].axis('off')\n",
    "table = axes[1, 1].table(cellText=stats_data, cellLoc='center', loc='center',\n",
    "                         colWidths=[0.3, 0.35, 0.35])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1, 2)\n",
    "\n",
    "# Style header row\n",
    "for i in range(3):\n",
    "    cell = table[(0, i)]\n",
    "    cell.set_facecolor('#4CAF50')\n",
    "    cell.set_text_props(weight='bold', color='white')\n",
    "\n",
    "axes[1, 1].set_title('Error Statistics', fontsize=12, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcca Final Analysis:\")\n",
    "print(f\"DE Solution MSE: {result.fun:.6e}\")\n",
    "print(f\"Reference MSE: {benchmark.fitness_function(benchmark.reference_solution):.6e}\")\n",
    "print(f\"\\nDE Solution Parameters: k0={k0_de:.5f}, k={k_de:.5f}, a={a_de:.5f}\")\n",
    "print(f\"Reference Parameters: k0={k0_ref:.5f}, k={k_ref:.5f}, a={a_ref:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udf93 Summary and Next Steps\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "1. **Physical System**: The magnetic levitator is a real-world system with complex nonlinear dynamics\n",
    "2. **Benchmark Interface**: Simple to use with `fitness_function()` for any optimization algorithm\n",
    "3. **Challenge**: The fitness landscape is complex with multiple local optima\n",
    "4. **Visualization**: Critical for understanding algorithm behavior and solution quality\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Try Different Algorithms**: Test PSO, Genetic Algorithms, Grey Wolf, etc.\n",
    "2. **Tune Hyperparameters**: Experiment with population size, mutation rates, etc.\n",
    "3. **Compare Performance**: Run multiple trials and compute statistics\n",
    "4. **Use Real Data**: Load your own experimental data from the physical system\n",
    "\n",
    "### Resources\n",
    "\n",
    "- **Repository**: [github.com/JRavenelco/levitador-benchmark](https://github.com/JRavenelco/levitador-benchmark)\n",
    "- **Documentation**: See README.md for detailed information\n",
    "- **Examples**: Check `example_optimization.py` for more algorithm implementations\n",
    "- **Metaheuristics Tutorial**: See `tutorial_metaheuristicas.ipynb` for implementing your own algorithms\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Optimizing! \ud83d\ude80**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}