# ü§ù Gu√≠a de Contribuci√≥n

¬°Gracias por tu inter√©s en contribuir al **Levitador Magn√©tico Benchmark**! Este documento proporciona directrices para contribuir implementaciones de metaheur√≠sticas y mejoras al proyecto.

---

## üìã Tabla de Contenidos

1. [C√≥digo de Conducta](#c√≥digo-de-conducta)
2. [¬øC√≥mo Puedo Contribuir?](#c√≥mo-puedo-contribuir)
3. [Contribuir Metaheur√≠sticas](#contribuir-metaheur√≠sticas)
4. [Est√°ndares de C√≥digo](#est√°ndares-de-c√≥digo)
5. [Proceso de Pull Request](#proceso-de-pull-request)
6. [Reportar Bugs](#reportar-bugs)
7. [Sugerencias de Mejoras](#sugerencias-de-mejoras)

---

## C√≥digo de Conducta

Este proyecto se compromete a proporcionar un ambiente acogedor y respetuoso para todos los contribuyentes. Esperamos que todos los participantes:

- Usen lenguaje acogedor e inclusivo
- Respeten diferentes puntos de vista y experiencias
- Acepten cr√≠ticas constructivas con gracia
- Se enfoquen en lo que es mejor para la comunidad

---

## ¬øC√≥mo Puedo Contribuir?

Hay varias formas de contribuir a este proyecto:

### 1. üß¨ Implementar Nuevas Metaheur√≠sticas

La contribuci√≥n m√°s valiosa es agregar implementaciones de nuevos algoritmos bio-inspirados y metaheur√≠sticas. Ver la secci√≥n [Contribuir Metaheur√≠sticas](#contribuir-metaheur√≠sticas) m√°s abajo.

### 2. üìä Compartir Resultados

- Reporta resultados de tus experimentos con diferentes algoritmos
- Comparte configuraciones de par√°metros que funcionan bien
- Documenta casos de uso interesantes del benchmark

### 3. üêõ Reportar Bugs

- Revisa primero los issues existentes para evitar duplicados
- Proporciona pasos claros para reproducir el problema
- Incluye informaci√≥n del sistema (Python version, OS, dependencias)

### 4. üìö Mejorar Documentaci√≥n

- Corregir errores tipogr√°ficos o gramaticales
- Mejorar explicaciones existentes
- Agregar ejemplos adicionales
- Traducir documentaci√≥n a otros idiomas

### 5. ‚ú® Proponer Mejoras

- Nuevas caracter√≠sticas para el benchmark
- Mejoras en la API
- Herramientas de visualizaci√≥n
- Utilidades de an√°lisis

---

## Contribuir Metaheur√≠sticas

Esta secci√≥n proporciona una gu√≠a completa para contribuir implementaciones de algoritmos metaheur√≠sticos.

### Estructura de un Algoritmo

Todos los algoritmos deben heredar de la clase `BaseOptimizer` y seguir esta estructura:

```python
from example_optimization import BaseOptimizer
from levitador_benchmark import LevitadorBenchmark
from typing import Tuple, Optional
import numpy as np

class MiAlgoritmo(BaseOptimizer):
    """
    Nombre del Algoritmo (Acr√≥nimo).
    
    Descripci√≥n breve del algoritmo y su inspiraci√≥n biol√≥gica o f√≠sica.
    
    Referencia: Autor, A. et al. (a√±o). "T√≠tulo del paper."
    Nombre de la revista/conferencia, volumen, p√°ginas.
    
    Pseudoc√≥digo:
    1. Inicializar poblaci√≥n
    2. Para cada iteraci√≥n:
       a. Paso de exploraci√≥n
       b. Paso de explotaci√≥n
       c. Actualizar mejor soluci√≥n
    3. Retornar mejor soluci√≥n encontrada
    """
    
    def __init__(self, problema: LevitadorBenchmark, 
                 pop_size: int = 30,
                 max_iter: int = 100,
                 random_seed: Optional[int] = None,
                 verbose: bool = True,
                 **kwargs):
        """
        Inicializa el algoritmo.
        
        Args:
            problema: Instancia de LevitadorBenchmark
            pop_size: Tama√±o de la poblaci√≥n
            max_iter: N√∫mero m√°ximo de iteraciones
            random_seed: Semilla para reproducibilidad
            verbose: Si True, muestra mensajes de progreso
            **kwargs: Par√°metros espec√≠ficos del algoritmo
        """
        super().__init__(problema, random_seed)
        self.pop_size = pop_size
        self.max_iter = max_iter
        self.verbose = verbose
        # Agregar par√°metros espec√≠ficos del algoritmo
    
    def optimize(self) -> Tuple[np.ndarray, float]:
        """
        Ejecuta el algoritmo de optimizaci√≥n.
        
        Returns:
            Tuple[mejor_solucion, mejor_fitness]
        """
        # Inicializar poblaci√≥n
        population = self._rng.uniform(self.lb, self.ub, (self.pop_size, self.dim))
        fitness = np.array([self._evaluate(ind) for ind in population])
        
        best_idx = np.argmin(fitness)
        best_solution = population[best_idx].copy()
        best_fitness = fitness[best_idx]
        
        # Ciclo principal
        for t in range(self.max_iter):
            # Implementar l√≥gica del algoritmo aqu√≠
            
            # Actualizar mejor soluci√≥n
            if fitness[best_idx] < best_fitness:
                best_solution = population[best_idx].copy()
                best_fitness = fitness[best_idx]
            
            # Registrar historial
            self.history.append(best_fitness)
            
            # Mostrar progreso
            if self.verbose and t % 10 == 0:
                print(f"  Iter {t:3d}: Mejor = {best_fitness:.6e}")
        
        return best_solution, best_fitness
```

### Requisitos para Implementaciones

#### 1. **Herencia de BaseOptimizer**

Tu algoritmo DEBE heredar de `BaseOptimizer`, que proporciona:
- `self.problema`: Instancia del problema
- `self.dim`: Dimensi√≥n del problema (3 para levitador)
- `self.bounds`: L√≠mites del espacio de b√∫squeda
- `self.lb`, `self.ub`: L√≠mites inferior y superior como arrays
- `self._rng`: Generador de n√∫meros aleatorios (para reproducibilidad)
- `self._evaluate()`: M√©todo para evaluar soluciones
- `self.evaluations`: Contador de evaluaciones
- `self.history`: Lista para registrar evoluci√≥n del fitness

#### 2. **Documentaci√≥n Completa**

Cada algoritmo DEBE incluir:

- **Docstring de clase** con:
  - Nombre completo y acr√≥nimo del algoritmo
  - Descripci√≥n de la inspiraci√≥n (biol√≥gica, f√≠sica, etc.)
  - Referencia bibliogr√°fica completa
  - Pseudoc√≥digo simplificado del algoritmo
  
- **Docstring de `__init__`** con:
  - Descripci√≥n de cada par√°metro
  - Valores por defecto recomendados
  
- **Docstring de `optimize`** con:
  - Descripci√≥n del proceso
  - Tipo de retorno

#### 3. **Reproducibilidad**

- Usar `self._rng` en lugar de `np.random` para todas las operaciones aleatorias
- Permitir `random_seed` como par√°metro en `__init__`
- Ejemplo:
  ```python
  # ‚úÖ CORRECTO
  value = self._rng.random()
  indices = self._rng.choice(n, size=k, replace=False)
  
  # ‚ùå INCORRECTO
  value = np.random.random()
  indices = np.random.choice(n, size=k, replace=False)
  ```

#### 4. **L√≠mites del Espacio de B√∫squeda**

- Respetar `self.lb` y `self.ub` en todo momento
- Usar `np.clip()` para mantener soluciones dentro de l√≠mites
- Ejemplo:
  ```python
  new_solution = current_solution + perturbation
  new_solution = np.clip(new_solution, self.lb, self.ub)
  ```

#### 5. **Evaluaci√≥n de Fitness**

- Usar SIEMPRE `self._evaluate(solution)` en lugar de `self.problema.fitness_function()`
- Esto permite el conteo autom√°tico de evaluaciones
- Ejemplo:
  ```python
  # ‚úÖ CORRECTO
  fitness = self._evaluate(individual)
  
  # ‚ùå INCORRECTO
  fitness = self.problema.fitness_function(individual)
  ```

#### 6. **Registro de Historial**

- Agregar el mejor fitness de cada iteraci√≥n a `self.history`
- Esto permite an√°lisis de convergencia
- Ejemplo:
  ```python
  for t in range(self.max_iter):
      # ... l√≥gica del algoritmo ...
      self.history.append(best_fitness)
  ```

#### 7. **Mensajes de Progreso**

- Proporcionar par√°metro `verbose` (default: `True`)
- Mostrar progreso cada 10 iteraciones
- Formato consistente:
  ```python
  if self.verbose and t % 10 == 0:
      print(f"  Iter {t:3d}: Mejor = {best_fitness:.6e}")
  ```

### Ejemplo Completo: Particle Swarm Optimization

```python
class ParticleSwarmOptimization(BaseOptimizer):
    """
    Particle Swarm Optimization (PSO) - Optimizaci√≥n por Enjambre de Part√≠culas.
    
    Inspirado en el comportamiento social de bandadas de aves y card√∫menes de peces.
    Cada part√≠cula ajusta su velocidad bas√°ndose en su mejor posici√≥n personal
    (pbest) y la mejor posici√≥n global del enjambre (gbest).
    
    Referencia: Kennedy, J., & Eberhart, R. (1995). "Particle swarm optimization."
    Proceedings of ICNN'95 - International Conference on Neural Networks, 4, 1942-1948.
    
    Pseudoc√≥digo:
    1. Inicializar posiciones y velocidades de part√≠culas
    2. Para cada iteraci√≥n:
       a. Evaluar fitness de cada part√≠cula
       b. Actualizar pbest de cada part√≠cula
       c. Actualizar gbest del enjambre
       d. Actualizar velocidades: v = w*v + c1*r1*(pbest-x) + c2*r2*(gbest-x)
       e. Actualizar posiciones: x = x + v
    3. Retornar gbest
    """
    
    def __init__(self, problema: LevitadorBenchmark,
                 n_particles: int = 30,
                 max_iter: int = 100,
                 w: float = 0.7,
                 c1: float = 1.5,
                 c2: float = 1.5,
                 random_seed: Optional[int] = None,
                 verbose: bool = True):
        """
        Inicializa PSO.
        
        Args:
            problema: Instancia de LevitadorBenchmark
            n_particles: N√∫mero de part√≠culas en el enjambre
            max_iter: N√∫mero m√°ximo de iteraciones
            w: Inercia (peso de la velocidad anterior)
            c1: Coeficiente cognitivo (atracci√≥n a pbest)
            c2: Coeficiente social (atracci√≥n a gbest)
            random_seed: Semilla para reproducibilidad
            verbose: Si True, muestra progreso
        """
        super().__init__(problema, random_seed)
        self.n_particles = n_particles
        self.max_iter = max_iter
        self.w = w
        self.c1 = c1
        self.c2 = c2
        self.verbose = verbose
    
    def optimize(self) -> Tuple[np.ndarray, float]:
        """Ejecuta PSO."""
        # Inicializar posiciones y velocidades
        positions = self._rng.uniform(self.lb, self.ub, (self.n_particles, self.dim))
        velocities = self._rng.uniform(-1, 1, (self.n_particles, self.dim))
        
        # Evaluar fitness inicial
        fitness = np.array([self._evaluate(p) for p in positions])
        
        # Inicializar pbest y gbest
        pbest_positions = positions.copy()
        pbest_fitness = fitness.copy()
        
        gbest_idx = np.argmin(fitness)
        gbest_position = positions[gbest_idx].copy()
        gbest_fitness = fitness[gbest_idx]
        
        # Ciclo principal
        for t in range(self.max_iter):
            for i in range(self.n_particles):
                # Actualizar velocidad
                r1 = self._rng.random(self.dim)
                r2 = self._rng.random(self.dim)
                
                cognitive = self.c1 * r1 * (pbest_positions[i] - positions[i])
                social = self.c2 * r2 * (gbest_position - positions[i])
                velocities[i] = self.w * velocities[i] + cognitive + social
                
                # Actualizar posici√≥n
                positions[i] = positions[i] + velocities[i]
                positions[i] = np.clip(positions[i], self.lb, self.ub)
                
                # Evaluar nueva posici√≥n
                fitness[i] = self._evaluate(positions[i])
                
                # Actualizar pbest
                if fitness[i] < pbest_fitness[i]:
                    pbest_positions[i] = positions[i].copy()
                    pbest_fitness[i] = fitness[i]
                    
                    # Actualizar gbest
                    if fitness[i] < gbest_fitness:
                        gbest_position = positions[i].copy()
                        gbest_fitness = fitness[i]
            
            self.history.append(gbest_fitness)
            
            if self.verbose and t % 10 == 0:
                print(f"  Iter {t:3d}: Mejor = {gbest_fitness:.6e}")
        
        return gbest_position, gbest_fitness
```

### D√≥nde Agregar tu Implementaci√≥n

Agrega tu algoritmo en el archivo `example_optimization.py` siguiendo estos pasos:

1. **Ubicaci√≥n:** Agregar despu√©s de las implementaciones existentes
2. **Orden:** Mantener orden alfab√©tico por nombre del algoritmo
3. **Separaci√≥n:** Usar el separador est√°ndar:
   ```python
   # =============================================================================
   # NOMBRE DEL ALGORITMO
   # =============================================================================
   ```

### Ejemplo de Uso

Despu√©s de implementar tu algoritmo, agrega un ejemplo de uso al final de `example_optimization.py`:

```python
def ejemplo_mi_algoritmo():
    """Ejemplo de uso de Mi Algoritmo."""
    print("\n" + "="*60)
    print("EJEMPLO: Mi Algoritmo")
    print("="*60)
    
    problema = LevitadorBenchmark(random_seed=42, verbose=False)
    
    algo = MiAlgoritmo(
        problema, 
        pop_size=30, 
        max_iter=100,
        random_seed=42
    )
    
    print("\nEjecutando optimizaci√≥n...")
    mejor_sol, mejor_error = algo.optimize()
    
    print("\nüèÜ Resultado:")
    print(f"  k0 = {mejor_sol[0]:.6f} H")
    print(f"  k  = {mejor_sol[1]:.6f} H")
    print(f"  a  = {mejor_sol[2]:.6f} m")
    print(f"  Error: {mejor_error:.6e}")
    print(f"  Evaluaciones: {algo.evaluations}")
    
    return mejor_sol
```

### Testing

Aunque no es obligatorio para la contribuci√≥n inicial, es recomendable probar tu algoritmo:

```python
# Test b√°sico
def test_mi_algoritmo():
    problema = LevitadorBenchmark(random_seed=42, verbose=False)
    algo = MiAlgoritmo(problema, pop_size=10, max_iter=5, random_seed=42)
    
    mejor_sol, mejor_error = algo.optimize()
    
    # Verificaciones b√°sicas
    assert len(mejor_sol) == 3
    assert mejor_error > 0
    assert all(lb <= x <= ub for x, (lb, ub) in zip(mejor_sol, problema.bounds))
    assert len(algo.history) == 5  # max_iter
    
    print("‚úÖ Test pasado")
```

### Checklist de Contribuci√≥n

Antes de enviar tu Pull Request, verifica que tu implementaci√≥n cumple con:

- [ ] Hereda de `BaseOptimizer`
- [ ] Incluye docstring completo con referencia bibliogr√°fica
- [ ] Usa `self._rng` para todas las operaciones aleatorias
- [ ] Respeta `self.lb` y `self.ub` con `np.clip()`
- [ ] Usa `self._evaluate()` para evaluar fitness
- [ ] Registra `self.history` en cada iteraci√≥n
- [ ] Incluye par√°metro `verbose` con mensajes de progreso
- [ ] Proporciona ejemplo de uso
- [ ] Los nombres de variables y comentarios son claros
- [ ] El c√≥digo sigue el estilo PEP 8
- [ ] Has probado el algoritmo con el benchmark

---

## Est√°ndares de C√≥digo

### Estilo de C√≥digo

- Seguir [PEP 8](https://www.python.org/dev/peps/pep-0008/) para Python
- Usar nombres descriptivos para variables y funciones
- L√≠mite de 100 caracteres por l√≠nea (preferible 80)
- Usar comillas simples `'` para strings (excepto docstrings)

### Comentarios y Documentaci√≥n

```python
# ‚úÖ BUEN ESTILO
def update_velocity(self, particle_idx: int) -> np.ndarray:
    """
    Actualiza la velocidad de una part√≠cula seg√∫n PSO.
    
    Args:
        particle_idx: √çndice de la part√≠cula
        
    Returns:
        Nueva velocidad como array numpy
    """
    # Componente cognitiva (atracci√≥n a pbest)
    r1 = self._rng.random(self.dim)
    cognitive = self.c1 * r1 * (self.pbest[particle_idx] - self.positions[particle_idx])
    
    # Componente social (atracci√≥n a gbest)
    r2 = self._rng.random(self.dim)
    social = self.c2 * r2 * (self.gbest - self.positions[particle_idx])
    
    return self.w * self.velocities[particle_idx] + cognitive + social
```

### Imports

Orden de imports:
1. Biblioteca est√°ndar de Python
2. Bibliotecas de terceros
3. Imports locales del proyecto

```python
# Biblioteca est√°ndar
from typing import Tuple, Optional
import logging

# Terceros
import numpy as np
from scipy.optimize import minimize

# Locales
from levitador_benchmark import LevitadorBenchmark
from example_optimization import BaseOptimizer
```

### Type Hints

Usar type hints para claridad:

```python
def optimize(self) -> Tuple[np.ndarray, float]:
    """..."""
    pass

def __init__(self, problema: LevitadorBenchmark, 
             pop_size: int = 30,
             max_iter: int = 100,
             random_seed: Optional[int] = None) -> None:
    """..."""
    pass
```

---

## Proceso de Pull Request

### 1. Fork y Clone

```bash
# Fork el repositorio en GitHub
# Luego clona tu fork
git clone https://github.com/TU_USUARIO/levitador-benchmark.git
cd levitador-benchmark
```

### 2. Crear Branch

```bash
# Crear branch con nombre descriptivo
git checkout -b add-particle-swarm-algorithm

# O para correcciones
git checkout -b fix-differential-evolution-bounds
```

### 3. Hacer Cambios

- Implementa tu algoritmo siguiendo las gu√≠as anteriores
- Prueba tu implementaci√≥n localmente
- Aseg√∫rate de que todo funciona correctamente

### 4. Commit

Usa mensajes de commit claros y descriptivos:

```bash
# ‚úÖ BUENOS mensajes
git commit -m "Add Particle Swarm Optimization implementation"
git commit -m "Fix bounds checking in Differential Evolution"
git commit -m "Add documentation for Grey Wolf Optimizer"

# ‚ùå MALOS mensajes
git commit -m "Update code"
git commit -m "Fix bug"
git commit -m "Changes"
```

### 5. Push y Pull Request

```bash
# Push tu branch
git push origin add-particle-swarm-algorithm
```

Luego en GitHub:
1. Navega a tu fork
2. Click en "New Pull Request"
3. Selecciona tu branch
4. Completa la descripci√≥n del PR

### Plantilla de Pull Request

```markdown
## Descripci√≥n

Implementaci√≥n de [Nombre del Algoritmo] basado en [breve descripci√≥n de la inspiraci√≥n].

## Tipo de cambio

- [ ] Nueva metaheur√≠stica
- [ ] Correcci√≥n de bug
- [ ] Mejora de documentaci√≥n
- [ ] Otra (especificar): _____

## Algoritmo

**Nombre:** Particle Swarm Optimization (PSO)
**Referencia:** Kennedy, J., & Eberhart, R. (1995)
**Caracter√≠sticas:**
- Tama√±o de poblaci√≥n configurable
- Par√°metros: w, c1, c2
- Soporta reproducibilidad con random_seed

## Testing

- [x] Probado con datos sint√©ticos
- [ ] Probado con datos experimentales
- [x] Ejemplo de uso incluido
- [x] Documentaci√≥n completa

## Resultados

Resultados en 100 iteraciones con pop_size=30:
- Mejor MSE: 1.23e-08
- Evaluaciones: 3000
- Tiempo: ~45 segundos

## Checklist

- [x] El c√≥digo sigue las gu√≠as de estilo del proyecto
- [x] He revisado mi propio c√≥digo
- [x] He comentado √°reas complejas
- [x] Incluye documentaci√≥n completa
- [x] No introduce warnings
- [x] He probado que funciona correctamente
```

---

## Reportar Bugs

### Antes de Reportar

1. Revisa los [issues existentes](https://github.com/JRavenelco/levitador-benchmark/issues)
2. Verifica que usas la √∫ltima versi√≥n del c√≥digo
3. Prueba con un ambiente limpio (virtualenv nuevo)

### Informaci√≥n a Incluir

Usa esta plantilla:

```markdown
## Descripci√≥n del Bug

Descripci√≥n clara y concisa del problema.

## Pasos para Reproducir

1. Importar m√≥dulo X
2. Ejecutar funci√≥n Y con par√°metros Z
3. Observar error

## Comportamiento Esperado

Descripci√≥n de lo que deber√≠a suceder.

## Comportamiento Actual

Descripci√≥n de lo que realmente sucede.

## C√≥digo M√≠nimo Reproducible

```python
from levitador_benchmark import LevitadorBenchmark
problema = LevitadorBenchmark()
# ... c√≥digo que causa el error
```

## Error/Traceback

```
Traceback completo aqu√≠
```

## Entorno

- OS: [e.g., Ubuntu 22.04, Windows 11, macOS 13]
- Python: [e.g., 3.9.7]
- NumPy: [e.g., 1.21.0]
- SciPy: [e.g., 1.7.0]

## Informaci√≥n Adicional

Cualquier otra informaci√≥n relevante.
```

---

## Sugerencias de Mejoras

### Proponer Nuevas Caracter√≠sticas

Para proponer mejoras o nuevas caracter√≠sticas:

1. Abre un Issue con label "enhancement"
2. Describe claramente la mejora propuesta
3. Explica el caso de uso
4. Sugiere una posible implementaci√≥n (opcional)

### Ejemplo

```markdown
## T√≠tulo: Agregar soporte para optimizaci√≥n multiobjetivo

### Motivaci√≥n

Muchos problemas reales tienen m√∫ltiples objetivos a optimizar simult√°neamente.

### Propuesta

Extender `LevitadorBenchmark` para soportar:
1. M√∫ltiples funciones objetivo
2. Frente de Pareto
3. M√©tricas de evaluaci√≥n (IGD, hypervolume, etc.)

### Casos de Uso

- Minimizar MSE y tiempo de convergencia simult√°neamente
- Balance entre precisi√≥n y robustez

### Implementaci√≥n Sugerida

```python
class MultiObjectiveBenchmark(LevitadorBenchmark):
    def fitness_function(self, individuo):
        mse = super().fitness_function(individuo)
        # Implementar evaluaci√≥n de robustez aqu√≠
        robustness = self._evaluate_robustness(individuo)
        return [mse, robustness]
    
    def _evaluate_robustness(self, individuo):
        """
        Eval√∫a la robustez de la soluci√≥n ante perturbaciones.
        
        Returns:
            float: M√©trica de robustez (placeholder)
        """
        # Ejemplo: evaluar con ruido en los par√°metros
        perturbations = []
        for _ in range(5):
            perturbed = individuo + np.random.normal(0, 0.01, len(individuo))
            perturbations.append(super().fitness_function(perturbed))
        return np.std(perturbations)  # Variabilidad como medida de robustez
```

### Alternativas Consideradas

- Usar biblioteca existente (pymoo, deap)
- Implementaci√≥n desde cero
```

---

## Recursos Adicionales

### Algoritmos Metaheur√≠sticos Populares

Si buscas ideas de algoritmos para implementar:

**Basados en Evoluci√≥n:**
- Genetic Algorithm (GA) ‚úÖ *Ya implementado*
- Differential Evolution (DE) ‚úÖ *Ya implementado*
- Evolution Strategies (ES)
- Covariance Matrix Adaptation (CMA-ES)

**Basados en Enjambres:**
- Particle Swarm Optimization (PSO)
- Ant Colony Optimization (ACO)
- Artificial Bee Colony (ABC) ‚úÖ *Ya implementado*
- Firefly Algorithm (FA)

**Basados en F√≠sica:**
- Simulated Annealing (SA)
- Gravitational Search Algorithm (GSA)
- Black Hole Algorithm (BHA)

**Inspirados en Animales:**
- Grey Wolf Optimizer (GWO) ‚úÖ *Ya implementado*
- Whale Optimization Algorithm (WOA)
- Bat Algorithm (BA)
- Cuckoo Search (CS)

**Algoritmos Recientes (2020+):**
- Honey Badger Algorithm (HBA) ‚úÖ *Ya implementado*
- Arithmetic Optimization Algorithm (AOA)
- Aquila Optimizer (AO)
- Reptile Search Algorithm (RSA)

### Referencias

**Libros:**
- Yang, X. S. (2014). *Nature-Inspired Optimization Algorithms*. Elsevier.
- Talbi, E. G. (2009). *Metaheuristics: From Design to Implementation*. Wiley.

**Reviews:**
- Slowik, A., & Kwasnicka, H. (2020). "Evolutionary algorithms and their applications to engineering problems." *Neural Computing and Applications*, 32, 12363-12379.

**Benchmarks Relacionados:**
- CEC Competitions: https://www3.ntu.edu.sg/home/epnsugan/
- BBOB: https://numbbo.github.io/coco/

---

## Preguntas Frecuentes

### ¬øPuedo usar bibliotecas externas en mi implementaci√≥n?

**Preferiblemente no.** Las implementaciones deben usar solo NumPy y SciPy para mantener el proyecto ligero. Si tu algoritmo requiere una biblioteca espec√≠fica, disc√∫telo primero en un Issue.

### ¬øQu√© tan optimizado debe estar mi c√≥digo?

No necesita ser extremadamente optimizado, pero debe ser **razonablemente eficiente**. Evita operaciones O(n¬≥) innecesarias o bucles que puedan vectorizarse.

### ¬øPuedo implementar variantes de algoritmos existentes?

¬°S√≠! Puedes agregar variantes (e.g., "PSO con coeficientes adaptativos") como clases separadas. Aseg√∫rate de documentar claramente las diferencias con la versi√≥n original.

### ¬øNecesito tests unitarios?

No son obligatorios para la contribuci√≥n inicial, pero son bienvenidos. El proyecto eventualmente a√±adir√° tests para todos los algoritmos.

### ¬øEn qu√© idioma debo documentar?

El proyecto usa **espa√±ol** para comentarios y documentaci√≥n. Los nombres de variables/funciones pueden estar en ingl√©s si es convenci√≥n en el campo (e.g., `fitness`, `crossover`).

---

## Contacto

- **Issues:** https://github.com/JRavenelco/levitador-benchmark/issues
- **Email:** jesus.santana@uaq.mx
- **ORCID:** [0000-0002-6183-7379](https://orcid.org/0000-0002-6183-7379)

---

## Reconocimientos

Gracias a todos los contribuyentes que ayudan a mejorar este benchmark:

<!-- Se actualizar√° autom√°ticamente -->

---

**¬°Gracias por contribuir al Levitador Magn√©tico Benchmark!** üß≤

Tu aporte ayuda a la comunidad de investigaci√≥n en optimizaci√≥n y metaheur√≠sticas.
